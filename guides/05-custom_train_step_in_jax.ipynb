{"cells":[{"cell_type":"markdown","source":["# JAX에서 `fit()`의 동작을 커스터마이즈하기"],"metadata":{"id":"fc2KjNaZyFSP"}},{"cell_type":"markdown","source":["**저자:** [fchollet](https://twitter.com/fchollet)  \n","**생성일:** 2023/06/27  \n","**최종편집일:** 2023/06/27  \n","**설명:** JAX를 사용하여 모델 클래스의 트레이닝 단계를 재정의합니다."],"metadata":{"id":"KErTOO6uyNEG"}},{"cell_type":"code","source":["# 이 노트북은 Keras 3이 설치되어 있다는 가정 하에 진행됩니다.\n","#\n","# !pip install keras --upgrade --quiet"],"metadata":{"id":"-4LZ9HnSiZ3C","executionInfo":{"status":"ok","timestamp":1726959251603,"user_tz":-540,"elapsed":2,"user":{"displayName":"Tae Kyu Lee","userId":"00886399863979660459"}}},"execution_count":1,"outputs":[]},{"cell_type":"markdown","source":["## 소개"],"metadata":{"id":"VhHcE5eXyOYI"}},{"cell_type":"markdown","source":["지도 학습을 할 때는 `fit()`을 사용하면, 모든 것이 매끄럽게 작동합니다.\n","\n","하지만 모든 세부 사항을 완전히 제어해야 할 경우, 처음부터 끝까지 직접 트레이닝 루프를 작성할 수 있습니다.\n","\n","그렇지만 맞춤형 트레이닝 알고리즘이 필요하면서도,\n","콜백, 빌트인 분산 지원, 스텝 퓨징(step fusing)과 같은,\n","`fit()`의 편리한 기능을 그대로 활용하고 싶다면 어떻게 해야 할까요?\n","\n","Keras의 핵심 원칙 중 하나는 **점진적인 복잡성 공개**입니다.\n","항상 점진적으로 더 낮은 레벨의 워크플로로 진입할 수 있어야 합니다.\n","높은 레벨의 기능이 정확히 사용 사례에 맞지 않더라도, 갑작스럽게 어려움에 부딪혀서는 안 됩니다.\n","높은 레벨의 편리함을 유지하면서, 작은 세부 사항에 대한 제어 권한을 더 많이 가질 수 있어야 합니다.\n","\n","`fit()`이 수행하는 작업을 커스터마이즈해야 할 때는,\n","**`Model` 클래스의 트레이닝 스텝 함수를 재정의(override)해야** 합니다.\n","이 함수는 `fit()`이 각 데이터 배치마다 호출하는 함수입니다.\n","이렇게 하면, 평소와 같이 `fit()`을 호출할 수 있으며,\n","그 안에서 사용자가 정의한 트레이닝 알고리즘이 실행됩니다.\n","\n","이 패턴은 Functional API로 모델을 만드는 것을 방해하지 않는다는 점에 주의하세요.\n","`Sequential` 모델, Functional API 모델, 또는 서브클래싱한 모델을 만들 때도 이 방법을 사용할 수 있습니다.\n","\n","이제 그 방법을 살펴보겠습니다."],"metadata":{"id":"6rjadEGNyQbJ"}},{"cell_type":"markdown","metadata":{"id":"Q9vThnWVxm8Z"},"source":["## 셋업"]},{"cell_type":"code","execution_count":2,"metadata":{"id":"5XV3XWYSxm8Z","executionInfo":{"status":"ok","timestamp":1726959253905,"user_tz":-540,"elapsed":585,"user":{"displayName":"Tae Kyu Lee","userId":"00886399863979660459"}}},"outputs":[],"source":["import os\n","\n","# 이 가이드는 JAX 백엔드에서만 실행할 수 있습니다.\n","os.environ[\"KERAS_BACKEND\"] = \"jax\"\n","\n","import jax\n","import keras\n","import numpy as np"]},{"cell_type":"code","source":["from keras import backend\n","print(backend.backend())"],"metadata":{"id":"yKsLIMeizSTI","executionInfo":{"status":"ok","timestamp":1726959397090,"user_tz":-540,"elapsed":8,"user":{"displayName":"Tae Kyu Lee","userId":"00886399863979660459"}},"outputId":"7cd08326-60b5-4439-aa6f-6c7386357063","colab":{"base_uri":"https://localhost:8080/"}},"execution_count":7,"outputs":[{"output_type":"stream","name":"stdout","text":["jax\n"]}]},{"cell_type":"markdown","source":["## 첫 번째 간단한 예제"],"metadata":{"id":"yMohqAS3yxGC"}},{"cell_type":"markdown","source":["간단한 예제부터 시작해봅시다:\n","\n","- [`keras.Model`](https://codecompose7.github.io/keras-doc-kr.github.io/api/models/model#model-class)을 서브클래스화하는 새로운 클래스를 만듭니다.\n","- 손실을 계산하고 모델의 트레이닝 가능하지 않은(non-trainable) 변수의 업데이트된 값을 계산하는,\n","  완전히 상태가 없는 `compute_loss_and_updates()` 메서드를 구현합니다.\n","  내부적으로는, `stateless_call()`과 빌트인 `compute_loss()`를 호출합니다.\n","- 현재의 메트릭 값(손실 포함)과 트레이닝 가능한 변수, 옵티마이저 변수, 메트릭 변수의 업데이트된 값을 계산하기 위한,\n","  완전히 상태가 없는 `train_step()` 메서드를 구현합니다.\n","\n","또한 `sample_weight` 인자를 다음과 같은 방법으로 고려할 수 있습니다:\n","\n","- 데이터를 `x, y, sample_weight = data`로 언패킹하기\n","- `sample_weight`를 `compute_loss()`에 전달하기\n","- `sample_weight`를 `y`와 `y_pred`와 함께 `stateless_update_state()`의 메트릭에 전달하기\n"],"metadata":{"id":"3YvjBvz3yzHR"}},{"cell_type":"code","execution_count":3,"metadata":{"id":"g-xyd9foxm8a","executionInfo":{"status":"ok","timestamp":1726959311447,"user_tz":-540,"elapsed":3,"user":{"displayName":"Tae Kyu Lee","userId":"00886399863979660459"}}},"outputs":[],"source":["class CustomModel(keras.Model):\n","    def compute_loss_and_updates(\n","        self,\n","        trainable_variables,\n","        non_trainable_variables,\n","        x,\n","        y,\n","        training=False,\n","    ):\n","        y_pred, non_trainable_variables = self.stateless_call(\n","            trainable_variables,\n","            non_trainable_variables,\n","            x,\n","            training=training,\n","        )\n","        loss = self.compute_loss(x, y, y_pred)\n","        return loss, (y_pred, non_trainable_variables)\n","\n","    def train_step(self, state, data):\n","        (\n","            trainable_variables,\n","            non_trainable_variables,\n","            optimizer_variables,\n","            metrics_variables,\n","        ) = state\n","        x, y = data\n","\n","        # 그래디언트 함수 가져오기\n","        grad_fn = jax.value_and_grad(self.compute_loss_and_updates, has_aux=True)\n","\n","        # 그래디언트를 계산합니다.\n","        (loss, (y_pred, non_trainable_variables)), grads = grad_fn(\n","            trainable_variables,\n","            non_trainable_variables,\n","            x,\n","            y,\n","            training=True,\n","        )\n","\n","        # 트레이닝 가능한 변수와 옵티마이저 변수를 업데이트합니다.\n","        (\n","            trainable_variables,\n","            optimizer_variables,\n","        ) = self.optimizer.stateless_apply(\n","            optimizer_variables, grads, trainable_variables\n","        )\n","\n","        # 메트릭을 업데이트합니다.\n","        new_metrics_vars = []\n","        logs = {}\n","        for metric in self.metrics:\n","            this_metric_vars = metrics_variables[\n","                len(new_metrics_vars) : len(new_metrics_vars) + len(metric.variables)\n","            ]\n","            if metric.name == \"loss\":\n","                this_metric_vars = metric.stateless_update_state(this_metric_vars, loss)\n","            else:\n","                this_metric_vars = metric.stateless_update_state(\n","                    this_metric_vars, y, y_pred\n","                )\n","            logs[metric.name] = metric.stateless_result(this_metric_vars)\n","            new_metrics_vars += this_metric_vars\n","\n","        # 메트릭 로그와 업데이트된 상태 변수를 반환합니다.\n","        state = (\n","            trainable_variables,\n","            non_trainable_variables,\n","            optimizer_variables,\n","            new_metrics_vars,\n","        )\n","        return logs, state"]},{"cell_type":"markdown","metadata":{"id":"vJMfTOLYxm8b"},"source":["이제 시도해봅시다:"]},{"cell_type":"code","execution_count":4,"metadata":{"id":"0r2bYd4rxm8b","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1726959321798,"user_tz":-540,"elapsed":924,"user":{"displayName":"Tae Kyu Lee","userId":"00886399863979660459"}},"outputId":"b9f117d9-2f91-4d70-d300-b01d7dfdc4ab"},"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/3\n","\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - mae: 0.3736 - loss: 0.2084\n","Epoch 2/3\n","\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 471us/step - mae: 0.3578 - loss: 0.1959\n","Epoch 3/3\n","\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 457us/step - mae: 0.3463 - loss: 0.1839\n"]},{"output_type":"execute_result","data":{"text/plain":["<keras.src.callbacks.history.History at 0x7371bebbc550>"]},"metadata":{},"execution_count":4}],"source":["# `CustomModel` 인스턴스를 생성하고 컴파일합니다.\n","inputs = keras.Input(shape=(32,))\n","outputs = keras.layers.Dense(1)(inputs)\n","model = CustomModel(inputs, outputs)\n","model.compile(optimizer=\"adam\", loss=\"mse\", metrics=[\"mae\"])\n","\n","# 평소처럼 `fit`을 사용하세요.\n","x = np.random.random((1000, 32))\n","y = np.random.random((1000, 1))\n","model.fit(x, y, epochs=3)"]},{"cell_type":"markdown","source":["## 더 낮은 레벨로 내려가기"],"metadata":{"id":"9RKnPqOlzDJ4"}},{"cell_type":"markdown","source":["물론, `compile()`에서 손실 함수를 전달하지 않고,\n","대신 `train_step`에서 모든 작업을 *수동으로* 수행할 수도 있습니다.\n","메트릭도 마찬가지입니다.\n","\n","다음은 옵티마이저를 설정하기 위해서만 `compile()`을 사용하는, 더 낮은 레벨의 예제입니다:"],"metadata":{"id":"-uP2HR0pzEpd"}},{"cell_type":"code","execution_count":5,"metadata":{"id":"RXoG2Ue8xm8b","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1726959354808,"user_tz":-540,"elapsed":335,"user":{"displayName":"Tae Kyu Lee","userId":"00886399863979660459"}},"outputId":"6c3d9aa2-bd76-468d-9fec-77a83ca003c8"},"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/5\n","\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.3641 - mae: 0.4965\n","Epoch 2/5\n","\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 466us/step - loss: 0.2838 - mae: 0.4268\n","Epoch 3/5\n","\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 458us/step - loss: 0.2486 - mae: 0.4043\n","Epoch 4/5\n","\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 472us/step - loss: 0.2275 - mae: 0.3799\n","Epoch 5/5\n","\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 495us/step - loss: 0.2180 - mae: 0.3793\n"]},{"output_type":"execute_result","data":{"text/plain":["<keras.src.callbacks.history.History at 0x7371beba7fd0>"]},"metadata":{},"execution_count":5}],"source":["class CustomModel(keras.Model):\n","    def __init__(self, *args, **kwargs):\n","        super().__init__(*args, **kwargs)\n","        self.loss_tracker = keras.metrics.Mean(name=\"loss\")\n","        self.mae_metric = keras.metrics.MeanAbsoluteError(name=\"mae\")\n","        self.loss_fn = keras.losses.MeanSquaredError()\n","\n","    def compute_loss_and_updates(\n","        self,\n","        trainable_variables,\n","        non_trainable_variables,\n","        x,\n","        y,\n","        training=False,\n","    ):\n","        y_pred, non_trainable_variables = self.stateless_call(\n","            trainable_variables,\n","            non_trainable_variables,\n","            x,\n","            training=training,\n","        )\n","        loss = self.loss_fn(y, y_pred)\n","        return loss, (y_pred, non_trainable_variables)\n","\n","    def train_step(self, state, data):\n","        (\n","            trainable_variables,\n","            non_trainable_variables,\n","            optimizer_variables,\n","            metrics_variables,\n","        ) = state\n","        x, y = data\n","\n","        # 그래디언트 함수를 가져옵니다.\n","        grad_fn = jax.value_and_grad(self.compute_loss_and_updates, has_aux=True)\n","\n","        # 그래디언트를 계산합니다.\n","        (loss, (y_pred, non_trainable_variables)), grads = grad_fn(\n","            trainable_variables,\n","            non_trainable_variables,\n","            x,\n","            y,\n","            training=True,\n","        )\n","\n","        # 트레이닝 가능한 변수와 옵티마이저 변수를 업데이트합니다.\n","        (\n","            trainable_variables,\n","            optimizer_variables,\n","        ) = self.optimizer.stateless_apply(\n","            optimizer_variables, grads, trainable_variables\n","        )\n","\n","        # 메트릭을 업데이트합니다.\n","        loss_tracker_vars = metrics_variables[: len(self.loss_tracker.variables)]\n","        mae_metric_vars = metrics_variables[len(self.loss_tracker.variables) :]\n","\n","        loss_tracker_vars = self.loss_tracker.stateless_update_state(\n","            loss_tracker_vars, loss\n","        )\n","        mae_metric_vars = self.mae_metric.stateless_update_state(\n","            mae_metric_vars, y, y_pred\n","        )\n","\n","        logs = {}\n","        logs[self.loss_tracker.name] = self.loss_tracker.stateless_result(\n","            loss_tracker_vars\n","        )\n","        logs[self.mae_metric.name] = self.mae_metric.stateless_result(mae_metric_vars)\n","\n","        new_metrics_vars = loss_tracker_vars + mae_metric_vars\n","\n","        # 메트릭 로그와 업데이트된 상태 변수를 반환합니다.\n","        state = (\n","            trainable_variables,\n","            non_trainable_variables,\n","            optimizer_variables,\n","            new_metrics_vars,\n","        )\n","        return logs, state\n","\n","    @property\n","    def metrics(self):\n","        # `Metric` 객체들을 여기에 나열하여,\n","        # 각 에포크의 시작이나 `evaluate()`의 시작 시에,\n","        # `reset_states()`가 자동으로 호출될 수 있도록 합니다.\n","        return [self.loss_tracker, self.mae_metric]\n","\n","\n","# `CustomModel` 인스턴스를 생성하고 컴파일합니다.\n","inputs = keras.Input(shape=(32,))\n","outputs = keras.layers.Dense(1)(inputs)\n","model = CustomModel(inputs, outputs)\n","\n","# 여기에서는 손실 함수나 메트릭을 전달하지 않습니다.\n","model.compile(optimizer=\"adam\")\n","\n","# 평소처럼 `fit`을 사용하세요 — 콜백 등을 사용할 수 있습니다.\n","x = np.random.random((1000, 32))\n","y = np.random.random((1000, 1))\n","model.fit(x, y, epochs=5)"]},{"cell_type":"markdown","source":["## 사용자 정의 평가 스텝 제공"],"metadata":{"id":"aHB9uOqVzKnI"}},{"cell_type":"markdown","source":["`model.evaluate()` 호출에 대해서도 동일한 작업을 수행하고 싶다면 어떻게 해야 할까요?\n","그러면 정확히 같은 방식으로 `test_step`을 재정의하면 됩니다.\n","다음은 그 예시입니다:"],"metadata":{"id":"uDynQ_5nzMF1"}},{"cell_type":"code","execution_count":6,"metadata":{"id":"5sKTZrjSxm8c","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1726959380214,"user_tz":-540,"elapsed":168,"user":{"displayName":"Tae Kyu Lee","userId":"00886399863979660459"}},"outputId":"9d264893-2ced-4146-fb6a-9ec939de66ab"},"outputs":[{"output_type":"stream","name":"stdout","text":["\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - mae: 0.3526\n"]},{"output_type":"execute_result","data":{"text/plain":["0.3568970263004303"]},"metadata":{},"execution_count":6}],"source":["class CustomModel(keras.Model):\n","    def test_step(self, state, data):\n","        # 데이터를 언패킹합니다.\n","        x, y = data\n","        (\n","            trainable_variables,\n","            non_trainable_variables,\n","            metrics_variables,\n","        ) = state\n","\n","        # 예측값과 손실을 계산합니다.\n","        y_pred, non_trainable_variables = self.stateless_call(\n","            trainable_variables,\n","            non_trainable_variables,\n","            x,\n","            training=False,\n","        )\n","        loss = self.compute_loss(x, y, y_pred)\n","\n","        # 메트릭을 업데이트합니다.\n","        new_metrics_vars = []\n","        for metric in self.metrics:\n","            this_metric_vars = metrics_variables[\n","                len(new_metrics_vars) : len(new_metrics_vars) + len(metric.variables)\n","            ]\n","            if metric.name == \"loss\":\n","                this_metric_vars = metric.stateless_update_state(this_metric_vars, loss)\n","            else:\n","                this_metric_vars = metric.stateless_update_state(\n","                    this_metric_vars, y, y_pred\n","                )\n","            logs = metric.stateless_result(this_metric_vars)\n","            new_metrics_vars += this_metric_vars\n","\n","        # 메트릭 로그와 업데이트된 상태 변수를 반환합니다.\n","        state = (\n","            trainable_variables,\n","            non_trainable_variables,\n","            new_metrics_vars,\n","        )\n","        return logs, state\n","\n","\n","# `CustomModel` 인스턴스를 생성합니다.\n","inputs = keras.Input(shape=(32,))\n","outputs = keras.layers.Dense(1)(inputs)\n","model = CustomModel(inputs, outputs)\n","model.compile(loss=\"mse\", metrics=[\"mae\"])\n","\n","# 커스텀 `test_step`으로 평가합니다.\n","x = np.random.random((1000, 32))\n","y = np.random.random((1000, 1))\n","model.evaluate(x, y)"]},{"cell_type":"markdown","metadata":{"id":"Cjz9Jl8Rxm8c"},"source":["이것으로 끝입니다!"]}],"metadata":{"accelerator":"GPU","colab":{"provenance":[{"file_id":"https://github.com/keras-team/keras-io/blob/master/guides/ipynb/custom_train_step_in_jax.ipynb","timestamp":1726958964045}],"toc_visible":true},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.0"}},"nbformat":4,"nbformat_minor":0}