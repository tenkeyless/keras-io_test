{"cells":[{"cell_type":"markdown","source":["# TensorFlow에서 처음부터 트레이닝 루프 작성하기"],"metadata":{"id":"Gm97wI8P8f6P"}},{"cell_type":"markdown","source":["**저자:** [fchollet](https://twitter.com/fchollet)  \n","**생성일:** 2019/03/01  \n","**최종편집일:** 2023/06/25  \n","**설명:** TensorFlow에서 낮은 레벨의 트레이닝 및 평가 루프 작성하기."],"metadata":{"id":"UixI3ian8hUb"}},{"cell_type":"code","execution_count":7,"metadata":{"id":"uwULF2xb8SCB","executionInfo":{"status":"ok","timestamp":1726962990040,"user_tz":-540,"elapsed":9,"user":{"displayName":"Tae Kyu Lee","userId":"00886399863979660459"}}},"outputs":[],"source":["# !pip install keras --upgrade --quiet"]},{"cell_type":"markdown","metadata":{"id":"8ORF42JG8SCC"},"source":["## 셋업"]},{"cell_type":"code","execution_count":8,"metadata":{"id":"wfbliiNX8SCC","executionInfo":{"status":"ok","timestamp":1726962990052,"user_tz":-540,"elapsed":13,"user":{"displayName":"Tae Kyu Lee","userId":"00886399863979660459"}}},"outputs":[],"source":["import time\n","import os\n","\n","# 이 가이드는 TensorFlow 백엔드에서만 실행할 수 있습니다.\n","os.environ[\"KERAS_BACKEND\"] = \"tensorflow\"\n","\n","import tensorflow as tf\n","import keras\n","import numpy as np"]},{"cell_type":"code","source":["from keras import backend\n","print(backend.backend())"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"H7_GkXM_8j2E","executionInfo":{"status":"ok","timestamp":1726962990058,"user_tz":-540,"elapsed":4,"user":{"displayName":"Tae Kyu Lee","userId":"00886399863979660459"}},"outputId":"81a2e862-2f98-4e4a-abcd-d7876e642413"},"execution_count":9,"outputs":[{"output_type":"stream","name":"stdout","text":["tensorflow\n"]}]},{"cell_type":"markdown","source":["## 소개"],"metadata":{"id":"8WYba1sT8sdS"}},{"cell_type":"markdown","source":["Keras는 기본 트레이닝 및 평가 루프인 `fit()`과 `evaluate()`를 제공합니다.\n","이러한 사용 방법은 [빌트인 메서드를 사용한 트레이닝 및 평가](https://codecompose7.github.io/keras-doc-kr.github.io/guides/training_with_built_in_methods/) 가이드에서 다룹니다.\n","\n","모델의 학습 알고리즘을 커스터마이즈하면서도 `fit()`의 편리함을 활용하고 싶다면\n","(예를 들어, `fit()`을 사용해 GAN을 트레이닝하려는 경우),\n","`Model` 클래스를 서브클래싱하고,\n","`fit()` 동안 반복적으로 호출되는 자체 `train_step()` 메서드를 구현할 수 있습니다.\n","\n","이제, 트레이닝 및 평가에 대해 매우 낮은 레벨의 제어를 원한다면,\n","처음부터 직접 트레이닝 및 평가 루프를 작성해야 합니다.\n","이 가이드는 그것에 관한 것입니다."],"metadata":{"id":"DcarwV7o8uS4"}},{"cell_type":"markdown","source":["## 첫 번째 엔드 투 엔드 예제"],"metadata":{"id":"lD7a-bg080Cj"}},{"cell_type":"markdown","source":["간단한 MNIST 모델을 살펴봅시다:"],"metadata":{"id":"4sdNo9BD81Wz"}},{"cell_type":"code","execution_count":10,"metadata":{"id":"O61zj-8S8SCD","executionInfo":{"status":"ok","timestamp":1726962990101,"user_tz":-540,"elapsed":5,"user":{"displayName":"Tae Kyu Lee","userId":"00886399863979660459"}}},"outputs":[],"source":["def get_model():\n","    inputs = keras.Input(shape=(784,), name=\"digits\")\n","    x1 = keras.layers.Dense(64, activation=\"relu\")(inputs)\n","    x2 = keras.layers.Dense(64, activation=\"relu\")(x1)\n","    outputs = keras.layers.Dense(10, name=\"predictions\")(x2)\n","    model = keras.Model(inputs=inputs, outputs=outputs)\n","    return model\n","\n","\n","model = get_model()"]},{"cell_type":"markdown","metadata":{"id":"TCjFNfRf8SCE"},"source":["커스텀 트레이닝 루프를 사용하여, 미니 배치 그래디언트로 모델을 트레이닝해 봅시다.\n","\n","먼저, 옵티마이저, 손실 함수, 데이터셋이 필요합니다:"]},{"cell_type":"code","execution_count":11,"metadata":{"id":"fNF26la_8SCE","executionInfo":{"status":"ok","timestamp":1726962990103,"user_tz":-540,"elapsed":1,"user":{"displayName":"Tae Kyu Lee","userId":"00886399863979660459"}}},"outputs":[],"source":["# # 옵티마이저 인스턴스화\n","# optimizer = keras.optimizers.Adam(learning_rate=1e-3)\n","# # 손실 함수 인스턴스화\n","# loss_fn = keras.losses.SparseCategoricalCrossentropy(from_logits=True)\n","\n","# # 트레이닝 데이터셋 준비\n","# batch_size = 32\n","# (x_train, y_train), (x_test, y_test) = keras.datasets.mnist.load_data()\n","# x_train = np.reshape(x_train, (-1, 784))\n","# x_test = np.reshape(x_test, (-1, 784))\n","\n","# # 검증을 위해 10,000개의 샘플을 예약합니다.\n","# x_val = x_train[-10000:]\n","# y_val = y_train[-10000:]\n","# x_train = x_train[:-10000]\n","# y_train = y_train[:-10000]\n","\n","# # 트레이닝 데이터셋 준비\n","# train_dataset = tf.data.Dataset.from_tensor_slices((x_train, y_train))\n","# train_dataset = train_dataset.shuffle(buffer_size=1024).batch(batch_size)\n","\n","# # 검증 데이터셋 준비\n","# val_dataset = tf.data.Dataset.from_tensor_slices((x_val, y_val))\n","# val_dataset = val_dataset.batch(batch_size)"]},{"cell_type":"code","source":["# 옵티마이저 인스턴스화\n","optimizer = keras.optimizers.Adam(learning_rate=1e-3)\n","# 손실 함수 인스턴스화\n","loss_fn = keras.losses.SparseCategoricalCrossentropy(from_logits=True)\n","\n","# 트레이닝 데이터셋 준비\n","batch_size = 32\n","(x_train, y_train), (x_test, y_test) = keras.datasets.mnist.load_data()\n","x_train = np.reshape(x_train, (-1, 784))\n","x_test = np.reshape(x_test, (-1, 784))\n","\n","# 검증을 위해 10,000개의 샘플을 예약합니다.\n","x_val = x_train[-10000:]\n","y_val = y_train[-10000:]\n","x_train = x_train[:-10000]\n","y_train = y_train[:-10000]\n","\n","# GPU 사용 설정을 제어하여 텐서플로가 CPU에서만 연산하도록 설정\n","with tf.device('/CPU:0'):\n","    train_dataset = tf.data.Dataset.from_tensor_slices((x_train, y_train))\n","    train_dataset = train_dataset.shuffle(buffer_size=1024).batch(batch_size)\n","\n","    val_dataset = tf.data.Dataset.from_tensor_slices((x_val, y_val))\n","    val_dataset = val_dataset.batch(batch_size)"],"metadata":{"id":"30xRGLBw9AYS","executionInfo":{"status":"ok","timestamp":1726962990311,"user_tz":-540,"elapsed":208,"user":{"displayName":"Tae Kyu Lee","userId":"00886399863979660459"}}},"execution_count":12,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"w_ioCk1O8SCE"},"source":["`GradientTape` scope 내에서 모델을 호출하면,\n","손실 값에 대해 레이어의 트레이닝 가능한 가중치의 그래디언트를 가져올 수 있습니다.\n","옵티마이저 인스턴스를 사용하여,\n","이 그래디언트를 사용해 (`model.trainable_weights`로 가져온) 이러한 변수를\n","업데이트할 수 있습니다.\n","\n","다음은 단계별 트레이닝 루프입니다:\n","\n","-   에포크를 반복하는 `for` 루프를 엽니다.\n","-   각 에포크에 대해, 데이터셋을 배치 단위로 반복하는 `for` 루프를 엽니다.\n","-   각 배치에 대해, `GradientTape()` scope를 엽니다.\n","-   이 scope 내에서, 모델을 호출(순전파)하고 손실을 계산합니다.\n","-   scope 외부에서, 손실에 대한 모델 가중치의 그래디언트를 가져옵니다.\n","-   마지막으로, 옵티마이저를 사용해 그래디언트를 기반으로 모델의 가중치를 업데이트합니다."]},{"cell_type":"code","execution_count":13,"metadata":{"id":"TPnvU6H18SCE","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1726963079358,"user_tz":-540,"elapsed":89048,"user":{"displayName":"Tae Kyu Lee","userId":"00886399863979660459"}},"outputId":"84c6ae00-2334-4a1f-de9a-d03560076257"},"outputs":[{"output_type":"stream","name":"stdout","text":["\n","에포크 0 시작\n","스텝 0에서의 트레이닝 손실 (1 배치 기준): 85.2381\n","지금까지 본 샘플 수: 32\n","스텝 100에서의 트레이닝 손실 (1 배치 기준): 2.7344\n","지금까지 본 샘플 수: 3232\n","스텝 200에서의 트레이닝 손실 (1 배치 기준): 2.3941\n","지금까지 본 샘플 수: 6432\n","스텝 300에서의 트레이닝 손실 (1 배치 기준): 1.4115\n","지금까지 본 샘플 수: 9632\n","스텝 400에서의 트레이닝 손실 (1 배치 기준): 0.7644\n","지금까지 본 샘플 수: 12832\n","스텝 500에서의 트레이닝 손실 (1 배치 기준): 0.8883\n","지금까지 본 샘플 수: 16032\n","스텝 600에서의 트레이닝 손실 (1 배치 기준): 0.5903\n","지금까지 본 샘플 수: 19232\n","스텝 700에서의 트레이닝 손실 (1 배치 기준): 0.4929\n","지금까지 본 샘플 수: 22432\n","스텝 800에서의 트레이닝 손실 (1 배치 기준): 0.8970\n","지금까지 본 샘플 수: 25632\n","스텝 900에서의 트레이닝 손실 (1 배치 기준): 0.5165\n","지금까지 본 샘플 수: 28832\n","스텝 1000에서의 트레이닝 손실 (1 배치 기준): 0.6004\n","지금까지 본 샘플 수: 32032\n","스텝 1100에서의 트레이닝 손실 (1 배치 기준): 0.4065\n","지금까지 본 샘플 수: 35232\n","스텝 1200에서의 트레이닝 손실 (1 배치 기준): 0.8322\n","지금까지 본 샘플 수: 38432\n","스텝 1300에서의 트레이닝 손실 (1 배치 기준): 1.2376\n","지금까지 본 샘플 수: 41632\n","스텝 1400에서의 트레이닝 손실 (1 배치 기준): 0.3002\n","지금까지 본 샘플 수: 44832\n","스텝 1500에서의 트레이닝 손실 (1 배치 기준): 0.5256\n","지금까지 본 샘플 수: 48032\n","\n","에포크 1 시작\n","스텝 0에서의 트레이닝 손실 (1 배치 기준): 0.3518\n","지금까지 본 샘플 수: 32\n","스텝 100에서의 트레이닝 손실 (1 배치 기준): 0.6948\n","지금까지 본 샘플 수: 3232\n","스텝 200에서의 트레이닝 손실 (1 배치 기준): 0.4988\n","지금까지 본 샘플 수: 6432\n","스텝 300에서의 트레이닝 손실 (1 배치 기준): 0.2827\n","지금까지 본 샘플 수: 9632\n","스텝 400에서의 트레이닝 손실 (1 배치 기준): 1.0195\n","지금까지 본 샘플 수: 12832\n","스텝 500에서의 트레이닝 손실 (1 배치 기준): 1.1347\n","지금까지 본 샘플 수: 16032\n","스텝 600에서의 트레이닝 손실 (1 배치 기준): 0.2244\n","지금까지 본 샘플 수: 19232\n","스텝 700에서의 트레이닝 손실 (1 배치 기준): 0.1890\n","지금까지 본 샘플 수: 22432\n","스텝 800에서의 트레이닝 손실 (1 배치 기준): 0.2486\n","지금까지 본 샘플 수: 25632\n","스텝 900에서의 트레이닝 손실 (1 배치 기준): 0.3406\n","지금까지 본 샘플 수: 28832\n","스텝 1000에서의 트레이닝 손실 (1 배치 기준): 0.8040\n","지금까지 본 샘플 수: 32032\n","스텝 1100에서의 트레이닝 손실 (1 배치 기준): 0.4573\n","지금까지 본 샘플 수: 35232\n","스텝 1200에서의 트레이닝 손실 (1 배치 기준): 0.4201\n","지금까지 본 샘플 수: 38432\n","스텝 1300에서의 트레이닝 손실 (1 배치 기준): 0.9607\n","지금까지 본 샘플 수: 41632\n","스텝 1400에서의 트레이닝 손실 (1 배치 기준): 0.9819\n","지금까지 본 샘플 수: 44832\n","스텝 1500에서의 트레이닝 손실 (1 배치 기준): 0.4932\n","지금까지 본 샘플 수: 48032\n","\n","에포크 2 시작\n","스텝 0에서의 트레이닝 손실 (1 배치 기준): 0.2342\n","지금까지 본 샘플 수: 32\n","스텝 100에서의 트레이닝 손실 (1 배치 기준): 0.1972\n","지금까지 본 샘플 수: 3232\n","스텝 200에서의 트레이닝 손실 (1 배치 기준): 0.2776\n","지금까지 본 샘플 수: 6432\n","스텝 300에서의 트레이닝 손실 (1 배치 기준): 0.2523\n","지금까지 본 샘플 수: 9632\n","스텝 400에서의 트레이닝 손실 (1 배치 기준): 0.2360\n","지금까지 본 샘플 수: 12832\n","스텝 500에서의 트레이닝 손실 (1 배치 기준): 0.2056\n","지금까지 본 샘플 수: 16032\n","스텝 600에서의 트레이닝 손실 (1 배치 기준): 0.1832\n","지금까지 본 샘플 수: 19232\n","스텝 700에서의 트레이닝 손실 (1 배치 기준): 0.7250\n","지금까지 본 샘플 수: 22432\n","스텝 800에서의 트레이닝 손실 (1 배치 기준): 0.3159\n","지금까지 본 샘플 수: 25632\n","스텝 900에서의 트레이닝 손실 (1 배치 기준): 0.3523\n","지금까지 본 샘플 수: 28832\n","스텝 1000에서의 트레이닝 손실 (1 배치 기준): 0.1127\n","지금까지 본 샘플 수: 32032\n","스텝 1100에서의 트레이닝 손실 (1 배치 기준): 0.3419\n","지금까지 본 샘플 수: 35232\n","스텝 1200에서의 트레이닝 손실 (1 배치 기준): 0.1641\n","지금까지 본 샘플 수: 38432\n","스텝 1300에서의 트레이닝 손실 (1 배치 기준): 0.4483\n","지금까지 본 샘플 수: 41632\n","스텝 1400에서의 트레이닝 손실 (1 배치 기준): 0.3672\n","지금까지 본 샘플 수: 44832\n","스텝 1500에서의 트레이닝 손실 (1 배치 기준): 0.3081\n","지금까지 본 샘플 수: 48032\n"]}],"source":["epochs = 3\n","for epoch in range(epochs):\n","    print(f\"\\n에포크 {epoch} 시작\")\n","\n","    # 데이터셋의 배치를 반복합니다.\n","    for step, (x_batch_train, y_batch_train) in enumerate(train_dataset):\n","        # 순전파 동안 실행된 연산을 기록하기 위해, GradientTape를 엽니다.\n","        # 이를 통해 자동 미분이 가능합니다.\n","        with tf.GradientTape() as tape:\n","            # 레이어의 순전파를 실행합니다.\n","            # 레이어가 입력에 적용하는 연산은 GradientTape에 기록됩니다.\n","            logits = model(x_batch_train, training=True)  # 이 미니배치에 대한 로짓\n","\n","            # 이 미니배치에 대한 손실 값을 계산합니다.\n","            loss_value = loss_fn(y_batch_train, logits)\n","\n","        # 그레디언트 테이프를 사용해 손실에 대한\n","        # 트레이닝 가능한 변수의 그래디언트를 자동으로 가져옵니다.\n","        grads = tape.gradient(loss_value, model.trainable_weights)\n","\n","        # 그래디언트 하강법의 한 단계를 실행하여\n","        # 손실을 최소화하기 위해 변수의 값을 업데이트합니다.\n","        optimizer.apply(grads, model.trainable_weights)\n","\n","        # 100 배치마다 로그를 출력합니다.\n","        if step % 100 == 0:\n","            print(\n","                f\"스텝 {step}에서의 트레이닝 손실 (1 배치 기준): {float(loss_value):.4f}\"\n","            )\n","            print(f\"지금까지 본 샘플 수: {(step + 1) * batch_size}\")"]},{"cell_type":"markdown","source":["## 메트릭의 낮은 레벨 처리"],"metadata":{"id":"yNYLhGw19JAd"}},{"cell_type":"markdown","source":["이 기본 루프에 메트릭 모니터링을 추가해 봅시다.\n","\n","이렇게 처음부터 작성한 트레이닝 루프에서도,\n","빌트인 메트릭(또는 당신이 작성한 커스텀 메트릭)을 쉽게 재사용할 수 있습니다.\n","흐름은 다음과 같습니다:\n","\n","-   루프 시작 시 메트릭을 인스턴스화합니다.\n","-   각 배치 후에 `metric.update_state()`를 호출합니다.\n","-   메트릭의 현재 값을 표시해야 할 때, `metric.result()`를 호출합니다.\n","-   메트릭의 상태를 초기화해야 할 때(일반적으로 에포크가 끝날 때),\n","    `metric.reset_state()`를 호출합니다.\n","\n","이 지식을 사용하여,\n","각 에포크가 끝날 때 트레이닝 및 검증 데이터에 대한 `SparseCategoricalAccuracy`를 계산해 보겠습니다:"],"metadata":{"id":"HtR7Rn3s9Nqt"}},{"cell_type":"code","execution_count":14,"metadata":{"id":"VGxvKgck8SCF","executionInfo":{"status":"ok","timestamp":1726963079415,"user_tz":-540,"elapsed":56,"user":{"displayName":"Tae Kyu Lee","userId":"00886399863979660459"}}},"outputs":[],"source":["# 새로운 모델 가져오기\n","model = get_model()\n","\n","# 모델을 트레이닝할 옵티마이저 인스턴스화\n","optimizer = keras.optimizers.Adam(learning_rate=1e-3)\n","# 손실 함수 인스턴스화\n","loss_fn = keras.losses.SparseCategoricalCrossentropy(from_logits=True)\n","\n","# 메트릭 준비\n","train_acc_metric = keras.metrics.SparseCategoricalAccuracy()\n","val_acc_metric = keras.metrics.SparseCategoricalAccuracy()"]},{"cell_type":"markdown","metadata":{"id":"913uCTpV8SCF"},"source":["트레이닝 및 평가 루프는 다음과 같습니다."]},{"cell_type":"code","execution_count":15,"metadata":{"id":"3BiZe1Xw8SCF","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1726963144622,"user_tz":-540,"elapsed":65206,"user":{"displayName":"Tae Kyu Lee","userId":"00886399863979660459"}},"outputId":"4acdef11-5407-4caa-e161-22328675e9a2"},"outputs":[{"output_type":"stream","name":"stdout","text":["\n","에포크 0 시작\n","스텝 0에서의 트레이닝 손실 (1 배치 기준): 162.6480\n","지금까지 본 샘플 수: 32\n","스텝 100에서의 트레이닝 손실 (1 배치 기준): 3.1124\n","지금까지 본 샘플 수: 3232\n","스텝 200에서의 트레이닝 손실 (1 배치 기준): 4.3715\n","지금까지 본 샘플 수: 6432\n","스텝 300에서의 트레이닝 손실 (1 배치 기준): 1.1864\n","지금까지 본 샘플 수: 9632\n","스텝 400에서의 트레이닝 손실 (1 배치 기준): 0.3606\n","지금까지 본 샘플 수: 12832\n","스텝 500에서의 트레이닝 손실 (1 배치 기준): 0.7929\n","지금까지 본 샘플 수: 16032\n","스텝 600에서의 트레이닝 손실 (1 배치 기준): 1.0190\n","지금까지 본 샘플 수: 19232\n","스텝 700에서의 트레이닝 손실 (1 배치 기준): 1.0366\n","지금까지 본 샘플 수: 22432\n","스텝 800에서의 트레이닝 손실 (1 배치 기준): 0.5251\n","지금까지 본 샘플 수: 25632\n","스텝 900에서의 트레이닝 손실 (1 배치 기준): 0.1788\n","지금까지 본 샘플 수: 28832\n","스텝 1000에서의 트레이닝 손실 (1 배치 기준): 0.5391\n","지금까지 본 샘플 수: 32032\n","스텝 1100에서의 트레이닝 손실 (1 배치 기준): 0.4671\n","지금까지 본 샘플 수: 35232\n","스텝 1200에서의 트레이닝 손실 (1 배치 기준): 0.3144\n","지금까지 본 샘플 수: 38432\n","스텝 1300에서의 트레이닝 손실 (1 배치 기준): 0.0491\n","지금까지 본 샘플 수: 41632\n","스텝 1400에서의 트레이닝 손실 (1 배치 기준): 0.3959\n","지금까지 본 샘플 수: 44832\n","스텝 1500에서의 트레이닝 손실 (1 배치 기준): 0.8089\n","지금까지 본 샘플 수: 48032\n","에포크 동안의 트레이닝 정확도: 0.8034\n","검증 정확도: 0.8831\n","소요 시간: 32.72초\n","\n","에포크 1 시작\n","스텝 0에서의 트레이닝 손실 (1 배치 기준): 0.5400\n","지금까지 본 샘플 수: 32\n","스텝 100에서의 트레이닝 손실 (1 배치 기준): 0.2436\n","지금까지 본 샘플 수: 3232\n","스텝 200에서의 트레이닝 손실 (1 배치 기준): 0.5178\n","지금까지 본 샘플 수: 6432\n","스텝 300에서의 트레이닝 손실 (1 배치 기준): 0.0625\n","지금까지 본 샘플 수: 9632\n","스텝 400에서의 트레이닝 손실 (1 배치 기준): 0.8117\n","지금까지 본 샘플 수: 12832\n","스텝 500에서의 트레이닝 손실 (1 배치 기준): 0.3537\n","지금까지 본 샘플 수: 16032\n","스텝 600에서의 트레이닝 손실 (1 배치 기준): 0.3666\n","지금까지 본 샘플 수: 19232\n","스텝 700에서의 트레이닝 손실 (1 배치 기준): 1.0308\n","지금까지 본 샘플 수: 22432\n","스텝 800에서의 트레이닝 손실 (1 배치 기준): 0.2606\n","지금까지 본 샘플 수: 25632\n","스텝 900에서의 트레이닝 손실 (1 배치 기준): 1.0096\n","지금까지 본 샘플 수: 28832\n","스텝 1000에서의 트레이닝 손실 (1 배치 기준): 0.3964\n","지금까지 본 샘플 수: 32032\n","스텝 1100에서의 트레이닝 손실 (1 배치 기준): 0.4486\n","지금까지 본 샘플 수: 35232\n","스텝 1200에서의 트레이닝 손실 (1 배치 기준): 0.5654\n","지금까지 본 샘플 수: 38432\n","스텝 1300에서의 트레이닝 손실 (1 배치 기준): 0.5196\n","지금까지 본 샘플 수: 41632\n","스텝 1400에서의 트레이닝 손실 (1 배치 기준): 0.2831\n","지금까지 본 샘플 수: 44832\n","스텝 1500에서의 트레이닝 손실 (1 배치 기준): 0.3548\n","지금까지 본 샘플 수: 48032\n","에포크 동안의 트레이닝 정확도: 0.8938\n","검증 정확도: 0.9059\n","소요 시간: 32.60초\n"]}],"source":["epochs = 2\n","for epoch in range(epochs):\n","    print(f\"\\n에포크 {epoch} 시작\")\n","    start_time = time.time()\n","\n","    # 데이터셋의 배치를 반복합니다.\n","    for step, (x_batch_train, y_batch_train) in enumerate(train_dataset):\n","        with tf.GradientTape() as tape:\n","            logits = model(x_batch_train, training=True)\n","            loss_value = loss_fn(y_batch_train, logits)\n","        grads = tape.gradient(loss_value, model.trainable_weights)\n","        optimizer.apply(grads, model.trainable_weights)\n","\n","        # 트레이닝 메트릭 업데이트\n","        train_acc_metric.update_state(y_batch_train, logits)\n","\n","        # 100 배치마다 로그를 출력합니다.\n","        if step % 100 == 0:\n","            print(\n","                f\"스텝 {step}에서의 트레이닝 손실 (1 배치 기준): {float(loss_value):.4f}\"\n","            )\n","            print(f\"지금까지 본 샘플 수: {(step + 1) * batch_size}\")\n","\n","    # 각 에포크가 끝날 때 메트릭을 표시합니다.\n","    train_acc = train_acc_metric.result()\n","    print(f\"에포크 동안의 트레이닝 정확도: {float(train_acc):.4f}\")\n","\n","    # 각 에포크가 끝날 때 트레이닝 메트릭을 초기화합니다.\n","    train_acc_metric.reset_state()\n","\n","    # 각 에포크가 끝날 때 검증 루프를 실행합니다.\n","    for x_batch_val, y_batch_val in val_dataset:\n","        val_logits = model(x_batch_val, training=False)\n","        # 검증 메트릭 업데이트\n","        val_acc_metric.update_state(y_batch_val, val_logits)\n","    val_acc = val_acc_metric.result()\n","    val_acc_metric.reset_state()\n","    print(f\"검증 정확도: {float(val_acc):.4f}\")\n","    print(f\"소요 시간: {time.time() - start_time:.2f}초\")"]},{"cell_type":"markdown","source":["## [`tf.function`](https://www.tensorflow.org/api_docs/python/tf/function)으로 트레이닝 스텝 속도 향상시키기"],"metadata":{"id":"Bbptw3YV9gDW"}},{"cell_type":"markdown","source":["TensorFlow의 기본 런타임은 즉시 실행 모드(eager execution)입니다.\n","따라서, 위의 트레이닝 루프는 즉시(eagerly) 실행됩니다.\n","\n","이는 디버깅에 유용하지만, 그래프 컴파일은 명확한 성능상의 이점을 가지고 있습니다.\n","계산을 정적 그래프로 설명하면, 프레임워크가 전역 성능 최적화를 적용할 수 있습니다.\n","프레임워크가 무엇이 다음에 올지 모르는 채로,\n","하나의 연산을 욕심껏 실행해야 하는 경우에는 불가능합니다.\n","\n","텐서를 입력으로 받는 모든 함수는 정적 그래프로 컴파일할 수 있습니다.\n","다음과 같이 `@tf.function` 데코레이터를 추가하기만 하면 됩니다:"],"metadata":{"id":"EgGrhlo19i9S"}},{"cell_type":"code","execution_count":16,"metadata":{"id":"TDQxczOl8SCF","executionInfo":{"status":"ok","timestamp":1726963144646,"user_tz":-540,"elapsed":10,"user":{"displayName":"Tae Kyu Lee","userId":"00886399863979660459"}}},"outputs":[],"source":["@tf.function\n","def train_step(x, y):\n","    with tf.GradientTape() as tape:\n","        logits = model(x, training=True)\n","        loss_value = loss_fn(y, logits)\n","    grads = tape.gradient(loss_value, model.trainable_weights)\n","    optimizer.apply(grads, model.trainable_weights)\n","    train_acc_metric.update_state(y, logits)\n","    return loss_value"]},{"cell_type":"markdown","metadata":{"id":"v0FBKKPp8SCF"},"source":["평가 스텝에서도 동일한 작업을 해봅시다:"]},{"cell_type":"code","execution_count":17,"metadata":{"id":"yVhtHlXf8SCF","executionInfo":{"status":"ok","timestamp":1726963144656,"user_tz":-540,"elapsed":9,"user":{"displayName":"Tae Kyu Lee","userId":"00886399863979660459"}}},"outputs":[],"source":["@tf.function\n","def test_step(x, y):\n","    val_logits = model(x, training=False)\n","    val_acc_metric.update_state(y, val_logits)"]},{"cell_type":"markdown","metadata":{"id":"6oM_Wyun8SCF"},"source":["이제, 컴파일된 트레이닝 스텝을 사용하여 트레이닝 루프를 다시 실행해 봅시다:"]},{"cell_type":"code","execution_count":18,"metadata":{"id":"8SC3EaJE8SCF","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1726963148828,"user_tz":-540,"elapsed":4167,"user":{"displayName":"Tae Kyu Lee","userId":"00886399863979660459"}},"outputId":"49d676fd-8ed2-46ba-d702-73eafb427373"},"outputs":[{"output_type":"stream","name":"stdout","text":["\n","에포크 0 시작\n","스텝 0에서의 트레이닝 손실 (1 배치 기준): 0.1458\n","지금까지 본 샘플 수: 32\n","스텝 100에서의 트레이닝 손실 (1 배치 기준): 0.4033\n","지금까지 본 샘플 수: 3232\n","스텝 200에서의 트레이닝 손실 (1 배치 기준): 0.3046\n","지금까지 본 샘플 수: 6432\n","스텝 300에서의 트레이닝 손실 (1 배치 기준): 1.1741\n","지금까지 본 샘플 수: 9632\n","스텝 400에서의 트레이닝 손실 (1 배치 기준): 0.6649\n","지금까지 본 샘플 수: 12832\n","스텝 500에서의 트레이닝 손실 (1 배치 기준): 0.2556\n","지금까지 본 샘플 수: 16032\n","스텝 600에서의 트레이닝 손실 (1 배치 기준): 0.5091\n","지금까지 본 샘플 수: 19232\n","스텝 700에서의 트레이닝 손실 (1 배치 기준): 0.3707\n","지금까지 본 샘플 수: 22432\n","스텝 800에서의 트레이닝 손실 (1 배치 기준): 0.3758\n","지금까지 본 샘플 수: 25632\n","스텝 900에서의 트레이닝 손실 (1 배치 기준): 0.8052\n","지금까지 본 샘플 수: 28832\n","스텝 1000에서의 트레이닝 손실 (1 배치 기준): 0.5190\n","지금까지 본 샘플 수: 32032\n","스텝 1100에서의 트레이닝 손실 (1 배치 기준): 1.1666\n","지금까지 본 샘플 수: 35232\n","스텝 1200에서의 트레이닝 손실 (1 배치 기준): 0.2694\n","지금까지 본 샘플 수: 38432\n","스텝 1300에서의 트레이닝 손실 (1 배치 기준): 0.5477\n","지금까지 본 샘플 수: 41632\n","스텝 1400에서의 트레이닝 손실 (1 배치 기준): 0.6991\n","지금까지 본 샘플 수: 44832\n","스텝 1500에서의 트레이닝 손실 (1 배치 기준): 0.2167\n","지금까지 본 샘플 수: 48032\n","에포크 동안의 트레이닝 정확도: 0.9114\n","검증 정확도: 0.9095\n","소요 시간: 2.31초\n","\n","에포크 1 시작\n","스텝 0에서의 트레이닝 손실 (1 배치 기준): 0.6741\n","지금까지 본 샘플 수: 32\n","스텝 100에서의 트레이닝 손실 (1 배치 기준): 0.1226\n","지금까지 본 샘플 수: 3232\n","스텝 200에서의 트레이닝 손실 (1 배치 기준): 0.2512\n","지금까지 본 샘플 수: 6432\n","스텝 300에서의 트레이닝 손실 (1 배치 기준): 0.1374\n","지금까지 본 샘플 수: 9632\n","스텝 400에서의 트레이닝 손실 (1 배치 기준): 0.3021\n","지금까지 본 샘플 수: 12832\n","스텝 500에서의 트레이닝 손실 (1 배치 기준): 0.2055\n","지금까지 본 샘플 수: 16032\n","스텝 600에서의 트레이닝 손실 (1 배치 기준): 0.6816\n","지금까지 본 샘플 수: 19232\n","스텝 700에서의 트레이닝 손실 (1 배치 기준): 0.5428\n","지금까지 본 샘플 수: 22432\n","스텝 800에서의 트레이닝 손실 (1 배치 기준): 0.1137\n","지금까지 본 샘플 수: 25632\n","스텝 900에서의 트레이닝 손실 (1 배치 기준): 0.3389\n","지금까지 본 샘플 수: 28832\n","스텝 1000에서의 트레이닝 손실 (1 배치 기준): 0.2856\n","지금까지 본 샘플 수: 32032\n","스텝 1100에서의 트레이닝 손실 (1 배치 기준): 0.6031\n","지금까지 본 샘플 수: 35232\n","스텝 1200에서의 트레이닝 손실 (1 배치 기준): 0.7296\n","지금까지 본 샘플 수: 38432\n","스텝 1300에서의 트레이닝 손실 (1 배치 기준): 0.3372\n","지금까지 본 샘플 수: 41632\n","스텝 1400에서의 트레이닝 손실 (1 배치 기준): 0.6117\n","지금까지 본 샘플 수: 44832\n","스텝 1500에서의 트레이닝 손실 (1 배치 기준): 0.7667\n","지금까지 본 샘플 수: 48032\n","에포크 동안의 트레이닝 정확도: 0.9201\n","검증 정확도: 0.9196\n","소요 시간: 1.89초\n"]}],"source":["epochs = 2\n","for epoch in range(epochs):\n","    print(f\"\\n에포크 {epoch} 시작\")\n","    start_time = time.time()\n","\n","    # 데이터셋의 배치를 반복합니다.\n","    for step, (x_batch_train, y_batch_train) in enumerate(train_dataset):\n","        loss_value = train_step(x_batch_train, y_batch_train)\n","\n","        # 100 배치마다 로그를 출력합니다.\n","        if step % 100 == 0:\n","            print(\n","                f\"스텝 {step}에서의 트레이닝 손실 (1 배치 기준): {float(loss_value):.4f}\"\n","            )\n","            print(f\"지금까지 본 샘플 수: {(step + 1) * batch_size}\")\n","\n","    # 각 에포크가 끝날 때 메트릭을 표시합니다.\n","    train_acc = train_acc_metric.result()\n","    print(f\"에포크 동안의 트레이닝 정확도: {float(train_acc):.4f}\")\n","\n","    # 각 에포크가 끝날 때 트레이닝 메트릭을 초기화합니다.\n","    train_acc_metric.reset_state()\n","\n","    # 각 에포크가 끝날 때 검증 루프를 실행합니다.\n","    for x_batch_val, y_batch_val in val_dataset:\n","        test_step(x_batch_val, y_batch_val)\n","\n","    val_acc = val_acc_metric.result()\n","    val_acc_metric.reset_state()\n","    print(f\"검증 정확도: {float(val_acc):.4f}\")\n","    print(f\"소요 시간: {time.time() - start_time:.2f}초\")"]},{"cell_type":"markdown","metadata":{"id":"RaEnDqCw8SCG"},"source":["훨씬 더 빨라졌죠, 그렇지 않나요?"]},{"cell_type":"markdown","source":["## 모델이 추적하는 손실의 낮은 레벨 처리"],"metadata":{"id":"R9lBSgVF9xDL"}},{"cell_type":"markdown","source":["레이어와 모델은 순전파 중 `self.add_loss(value)`를 호출하는 레이어에 의해 생성된 모든 손실을 재귀적으로 추적합니다.\n","그 결과로 생성된 스칼라 손실 값들의 목록은 순전파가 끝난 후,\n","`model.losses` 속성을 통해 확인할 수 있습니다.\n","\n","이러한 손실 요소들을 사용하고 싶다면,\n","이를 합산하여 트레이닝 스텝의 메인 손실에 추가해야 합니다.\n","\n","다음은 활동 정규화 손실을 생성하는 레이어입니다:"],"metadata":{"id":"tHxTkRQ492Ef"}},{"cell_type":"code","execution_count":19,"metadata":{"id":"WhiPvSvl8SCG","executionInfo":{"status":"ok","timestamp":1726963148850,"user_tz":-540,"elapsed":20,"user":{"displayName":"Tae Kyu Lee","userId":"00886399863979660459"}}},"outputs":[],"source":["class ActivityRegularizationLayer(keras.layers.Layer):\n","    def call(self, inputs):\n","        self.add_loss(1e-2 * tf.reduce_sum(inputs))\n","        return inputs"]},{"cell_type":"markdown","metadata":{"id":"q-fbGCjE8SCG"},"source":["간단한 모델을 만들어 사용해 봅시다:"]},{"cell_type":"code","execution_count":20,"metadata":{"id":"rGn-ZrKU8SCG","executionInfo":{"status":"ok","timestamp":1726963148862,"user_tz":-540,"elapsed":10,"user":{"displayName":"Tae Kyu Lee","userId":"00886399863979660459"}}},"outputs":[],"source":["inputs = keras.Input(shape=(784,), name=\"digits\")\n","x = keras.layers.Dense(64, activation=\"relu\")(inputs)\n","# activity 정규화 레이어 삽입\n","x = ActivityRegularizationLayer()(x)\n","x = keras.layers.Dense(64, activation=\"relu\")(x)\n","outputs = keras.layers.Dense(10, name=\"predictions\")(x)\n","\n","model = keras.Model(inputs=inputs, outputs=outputs)"]},{"cell_type":"markdown","metadata":{"id":"Q9J9XKJE8SCG"},"source":["현재의 트레이닝 스텝은 다음과 같이 생겼습니다:"]},{"cell_type":"code","execution_count":21,"metadata":{"id":"XAQ0FJ6W8SCG","executionInfo":{"status":"ok","timestamp":1726963148865,"user_tz":-540,"elapsed":4,"user":{"displayName":"Tae Kyu Lee","userId":"00886399863979660459"}}},"outputs":[],"source":["@tf.function\n","def train_step(x, y):\n","    with tf.GradientTape() as tape:\n","        logits = model(x, training=True)\n","        loss_value = loss_fn(y, logits)\n","        # 순전파 동안 생성된 추가 손실을 더합니다.\n","        loss_value += sum(model.losses)\n","    grads = tape.gradient(loss_value, model.trainable_weights)\n","    optimizer.apply(grads, model.trainable_weights)\n","    train_acc_metric.update_state(y, logits)\n","    return loss_value"]},{"cell_type":"markdown","source":["## 요약"],"metadata":{"id":"MTTckgnt9-i0"}},{"cell_type":"markdown","source":["이제 빌트인 트레이닝 루프를 사용하는 방법과,\n","직접 작성하는 방법에 대해 알아야 할 모든 것을 알게 되었습니다.\n","\n","마지막으로, 이 가이드에서 배운 모든 내용을 결합한 간단한 엔드 투 엔드 예제를 소개합니다:\n","MNIST 숫자에 대해 트레이닝된 DCGAN입니다."],"metadata":{"id":"CMGG3EMG9_wP"}},{"cell_type":"markdown","source":["## 엔드 투 엔드 예제: 처음부터 작성하는 GAN 트레이닝 루프"],"metadata":{"id":"Gt8X0YQ4-BSB"}},{"cell_type":"markdown","source":["생성적 적대 신경망(Generative Adversarial Networks, GANs)에 대해 들어본 적이 있을 것입니다.\n","GANs는 이미지의 트레이닝 데이터셋(이미지의 \"잠재 공간\")의 잠재 분포를 학습하여,\n","거의 실제처럼 보이는 새로운 이미지를 생성할 수 있습니다.\n","\n","GAN은 두 부분으로 구성됩니다:\n","잠재 공간의 점을 이미지 공간의 점으로 매핑하는 \"생성자(generator)\" 모델과,\n","실제 이미지(트레이닝 데이터셋에서 가져옴)와 가짜 이미지(생성기 네트워크의 출력)를 구분할 수 있는 분류기인 \"판별자(discriminator)\" 모델입니다.\n","\n","GAN의 트레이닝 루프는 다음과 같은 형태입니다:\n","\n","1\\) 판별자 트레이닝:  \n","- 잠재 공간에서 랜덤 포인트의 배치를 샘플링합니다.  \n","- \"생성자\" 모델을 통해, 포인트을 가짜 이미지로 변환합니다.  \n","- 실제 이미지의 배치를 얻고, 생성된 이미지와 결합합니다.  \n","- \"판별자\" 모델을 트레이닝하여, 생성된 이미지와 실제 이미지를 분류합니다.  \n","\n","2\\) 생성자 트레이닝:  \n","- 잠재 공간에서 랜덤 포인트를 샘플링합니다.  \n","- \"생성자\" 네트워크를 통해 포인트를 가짜 이미지로 변환합니다.  \n","- 실제 이미지의 배치를 얻고, 생성된 이미지와 결합합니다.  \n","- \"생성자\" 모델을 트레이닝하여, 판별자를 \"속이고\" 가짜 이미지를 실제 이미지로 분류하게 만듭니다.  \n","\n","GAN의 작동 방식에 대한 훨씬 더 자세한 개요는 [Deep Learning with Python](https://www.manning.com/books/deep-learning-with-python)을 참조하세요.\n","\n","이제 이 트레이닝 루프를 구현해 봅시다. 먼저, 가짜 숫자와 실제 숫자를 분류할 판별자를 생성합니다:"],"metadata":{"id":"2kYxSJu2-C5i"}},{"cell_type":"code","execution_count":22,"metadata":{"id":"Ti5Ww52t8SCG","colab":{"base_uri":"https://localhost:8080/","height":347},"executionInfo":{"status":"ok","timestamp":1726963148912,"user_tz":-540,"elapsed":46,"user":{"displayName":"Tae Kyu Lee","userId":"00886399863979660459"}},"outputId":"aadc7a18-b8ed-4480-d306-945f5e469144"},"outputs":[{"output_type":"display_data","data":{"text/plain":["\u001b[1mModel: \"discriminator\"\u001b[0m\n"],"text/html":["<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"discriminator\"</span>\n","</pre>\n"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n","┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n","┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n","│ conv2d_3 (\u001b[38;5;33mConv2D\u001b[0m)                    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m64\u001b[0m)          │             \u001b[38;5;34m640\u001b[0m │\n","├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n","│ leaky_re_lu_5 (\u001b[38;5;33mLeakyReLU\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m64\u001b[0m)          │               \u001b[38;5;34m0\u001b[0m │\n","├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n","│ conv2d_4 (\u001b[38;5;33mConv2D\u001b[0m)                    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m128\u001b[0m)           │          \u001b[38;5;34m73,856\u001b[0m │\n","├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n","│ leaky_re_lu_6 (\u001b[38;5;33mLeakyReLU\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m128\u001b[0m)           │               \u001b[38;5;34m0\u001b[0m │\n","├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n","│ global_max_pooling2d_1               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)                 │               \u001b[38;5;34m0\u001b[0m │\n","│ (\u001b[38;5;33mGlobalMaxPooling2D\u001b[0m)                 │                             │                 │\n","├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n","│ dense_8 (\u001b[38;5;33mDense\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)                   │             \u001b[38;5;34m129\u001b[0m │\n","└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"],"text/html":["<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n","┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n","┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n","│ conv2d_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)          │             <span style=\"color: #00af00; text-decoration-color: #00af00\">640</span> │\n","├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n","│ leaky_re_lu_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LeakyReLU</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)          │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n","├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n","│ conv2d_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)           │          <span style=\"color: #00af00; text-decoration-color: #00af00\">73,856</span> │\n","├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n","│ leaky_re_lu_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LeakyReLU</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)           │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n","├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n","│ global_max_pooling2d_1               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)                 │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n","│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GlobalMaxPooling2D</span>)                 │                             │                 │\n","├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n","│ dense_8 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)                   │             <span style=\"color: #00af00; text-decoration-color: #00af00\">129</span> │\n","└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n","</pre>\n"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["\u001b[1m Total params: \u001b[0m\u001b[38;5;34m74,625\u001b[0m (291.50 KB)\n"],"text/html":["<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">74,625</span> (291.50 KB)\n","</pre>\n"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m74,625\u001b[0m (291.50 KB)\n"],"text/html":["<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">74,625</span> (291.50 KB)\n","</pre>\n"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"],"text/html":["<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n","</pre>\n"]},"metadata":{}}],"source":["discriminator = keras.Sequential(\n","    [\n","        keras.Input(shape=(28, 28, 1)),\n","        keras.layers.Conv2D(64, (3, 3), strides=(2, 2), padding=\"same\"),\n","        keras.layers.LeakyReLU(negative_slope=0.2),\n","        keras.layers.Conv2D(128, (3, 3), strides=(2, 2), padding=\"same\"),\n","        keras.layers.LeakyReLU(negative_slope=0.2),\n","        keras.layers.GlobalMaxPooling2D(),\n","        keras.layers.Dense(1),\n","    ],\n","    name=\"discriminator\",\n",")\n","discriminator.summary()"]},{"cell_type":"markdown","metadata":{"id":"GmbRdImZ8SCH"},"source":["다음으로, 잠재 벡터를 `(28, 28, 1)` 모양의 출력(즉, MNIST 숫자)을 생성하는,\n","생성자 네트워크를 만들어 봅시다:"]},{"cell_type":"code","execution_count":23,"metadata":{"id":"PJZT1lLE8SCH","executionInfo":{"status":"ok","timestamp":1726963148914,"user_tz":-540,"elapsed":1,"user":{"displayName":"Tae Kyu Lee","userId":"00886399863979660459"}}},"outputs":[],"source":["latent_dim = 128\n","\n","generator = keras.Sequential(\n","    [\n","        keras.Input(shape=(latent_dim,)),\n","        # 7x7x128 맵으로 reshape 하기 위해 128개의 계수를 생성합니다.\n","        keras.layers.Dense(7 * 7 * 128),\n","        keras.layers.LeakyReLU(negative_slope=0.2),\n","        keras.layers.Reshape((7, 7, 128)),\n","        keras.layers.Conv2DTranspose(128, (4, 4), strides=(2, 2), padding=\"same\"),\n","        keras.layers.LeakyReLU(negative_slope=0.2),\n","        keras.layers.Conv2DTranspose(128, (4, 4), strides=(2, 2), padding=\"same\"),\n","        keras.layers.LeakyReLU(negative_slope=0.2),\n","        keras.layers.Conv2D(1, (7, 7), padding=\"same\", activation=\"sigmoid\"),\n","    ],\n","    name=\"generator\",\n",")"]},{"cell_type":"markdown","metadata":{"id":"NBAKdSsh8SCH"},"source":["다음은 트레이닝 루프의 핵심 부분입니다.\n","보시다시피, 매우 간단합니다. 트레이닝 스텝 함수는 단 17줄로 구성되어 있습니다."]},{"cell_type":"code","execution_count":24,"metadata":{"id":"qTds7jaf8SCH","executionInfo":{"status":"ok","timestamp":1726963148916,"user_tz":-540,"elapsed":1,"user":{"displayName":"Tae Kyu Lee","userId":"00886399863979660459"}}},"outputs":[],"source":["# 생성자와 생성자를 위한 옵티마이저 각각을 인스턴스화합니다.\n","d_optimizer = keras.optimizers.Adam(learning_rate=0.0003)\n","g_optimizer = keras.optimizers.Adam(learning_rate=0.0004)\n","\n","# 손실 함수를 인스턴스화합니다.\n","loss_fn = keras.losses.BinaryCrossentropy(from_logits=True)\n","\n","\n","@tf.function\n","def train_step(real_images):\n","    # 잠재 공간에서 랜덤한 포인트를 샘플링합니다.\n","    random_latent_vectors = tf.random.normal(shape=(batch_size, latent_dim))\n","    # 샘플을 가짜 이미지로 디코딩합니다.\n","    generated_images = generator(random_latent_vectors)\n","    # 가짜 이미지와 실제 이미지를 결합합니다.\n","    combined_images = tf.concat([generated_images, real_images], axis=0)\n","\n","    # 가짜 이미지와 실제 이미지를 구분하는 레이블을 조립합니다.\n","    labels = tf.concat(\n","        [tf.ones((batch_size, 1)), tf.zeros((real_images.shape[0], 1))], axis=0\n","    )\n","    # 레이블에 랜덤 노이즈를 추가합니다 - 중요한 트릭입니다!\n","    labels += 0.05 * tf.random.uniform(labels.shape)\n","\n","    # 판별자를 트레이닝합니다.\n","    with tf.GradientTape() as tape:\n","        predictions = discriminator(combined_images)\n","        d_loss = loss_fn(labels, predictions)\n","    grads = tape.gradient(d_loss, discriminator.trainable_weights)\n","    d_optimizer.apply(grads, discriminator.trainable_weights)\n","\n","    # 잠재 공간에서 랜덤한 포인트를 샘플링합니다.\n","    random_latent_vectors = tf.random.normal(shape=(batch_size, latent_dim))\n","    # \"모든 이미지는 진짜 (all real images)\"라고 말하는 레이블을 조립합니다.\n","    misleading_labels = tf.zeros((batch_size, 1))\n","\n","    # 생성자를 트레이닝합니다. (여기서 판별자의 가중치는 *절대로* 업데이트하면 안 됩니다)!\n","    with tf.GradientTape() as tape:\n","        predictions = discriminator(generator(random_latent_vectors))\n","        g_loss = loss_fn(misleading_labels, predictions)\n","    grads = tape.gradient(g_loss, generator.trainable_weights)\n","    g_optimizer.apply(grads, generator.trainable_weights)\n","    return d_loss, g_loss, generated_images"]},{"cell_type":"markdown","metadata":{"id":"srn5-fJN8SCH"},"source":["이제 이미지 배치에 대해 `train_step`을 반복적으로 호출하여 우리의 GAN을 트레이닝해봅시다.\n","\n","판별자와 생성자가 컨볼루션 신경망이기 때문에, 이 코드를 GPU에서 실행하는 것이 좋습니다."]},{"cell_type":"code","execution_count":25,"metadata":{"id":"sbYgAG8g8SCH","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1726963150663,"user_tz":-540,"elapsed":1746,"user":{"displayName":"Tae Kyu Lee","userId":"00886399863979660459"}},"outputId":"6306189c-d5ba-4f7f-c7f8-9da55b5990bf"},"outputs":[{"output_type":"stream","name":"stdout","text":["\n","에포크 0 시작\n","스텝 0에서의 판별기 손실: 0.71\n","스텝 0에서의 적대적 손실: 0.73\n"]}],"source":["# 데이터셋 준비. 트레이닝 및 테스트 MNIST 숫자를 모두 사용합니다.\n","batch_size = 64\n","(x_train, _), (x_test, _) = keras.datasets.mnist.load_data()\n","all_digits = np.concatenate([x_train, x_test])\n","all_digits = all_digits.astype(\"float32\") / 255.0\n","all_digits = np.reshape(all_digits, (-1, 28, 28, 1))\n","dataset = tf.data.Dataset.from_tensor_slices(all_digits)\n","dataset = dataset.shuffle(buffer_size=1024).batch(batch_size)\n","\n","epochs = 1  # 실제로는 멋진 숫자를 생성하려면 최소 20 에포크가 필요합니다.\n","save_dir = \"./\"\n","\n","for epoch in range(epochs):\n","    print(f\"\\n에포크 {epoch} 시작\")\n","\n","    for step, real_images in enumerate(dataset):\n","        # 한 배치의 실제 이미지에 대해 판별기 및 생성기를 트레이닝합니다.\n","        d_loss, g_loss, generated_images = train_step(real_images)\n","\n","        # 로깅\n","        if step % 100 == 0:\n","            # 메트릭 출력\n","            print(f\"스텝 {step}에서의 판별기 손실: {d_loss:.2f}\")\n","            print(f\"스텝 {step}에서의 적대적 손실: {g_loss:.2f}\")\n","\n","            # 생성된 이미지 중 하나를 저장합니다.\n","            img = keras.utils.array_to_img(generated_images[0] * 255.0, scale=False)\n","            img.save(os.path.join(save_dir, f\"generated_img_{step}.png\"))\n","\n","        # 실행 시간을 제한하기 위해 10 스텝 후에 중지합니다.\n","        # 실제로 모델을 트레이닝하려면, 아래의 줄을 제거하세요!\n","        if step > 10:\n","            break"]},{"cell_type":"markdown","metadata":{"id":"tDvzsObE8SCH"},"source":["이제 끝났습니다! Colab GPU에서 약 30초 동안 트레이닝한 후, 멋진 가짜 MNIST 숫자를 얻을 수 있습니다."]}],"metadata":{"accelerator":"None","colab":{"provenance":[{"file_id":"https://github.com/keras-team/keras-io/blob/master/guides/ipynb/writing_a_custom_training_loop_in_tensorflow.ipynb","timestamp":1726961756041}],"toc_visible":true},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.0"}},"nbformat":4,"nbformat_minor":0}