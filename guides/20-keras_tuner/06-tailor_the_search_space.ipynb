{"cells":[{"cell_type":"markdown","source":["# 검색 공간 맞춤 설정"],"metadata":{"id":"lDMTtuPTmOq6"}},{"cell_type":"markdown","source":["**저자:** Luca Invernizzi, James Long, Francois Chollet, Tom O'Malley, Haifeng Jin  \n","**생성일:** 2019/05/31  \n","**최종편집일:** 2021/10/27  \n","**설명:** 하이퍼모델을 변경하지 않고, 하이퍼파라미터의 일부만 튜닝하기"],"metadata":{"id":"AD6RtxsYmRg7"}},{"cell_type":"code","execution_count":1,"metadata":{"id":"oHCOsKrvNHOO","executionInfo":{"status":"ok","timestamp":1727006487092,"user_tz":-540,"elapsed":2,"user":{"displayName":"Tae Kyu Lee","userId":"00886399863979660459"}}},"outputs":[],"source":["# 이 노트북은 KerasTuner가 설치되어 있다는 가정 하에 진행됩니다.\n","#\n","# !pip install keras-tuner -q"]},{"cell_type":"code","source":["\n","# 이 노트북은 Keras 3이 설치되어 있다는 가정 하에 진행됩니다.\n","#\n","# !pip install keras --upgrade --quiet"],"metadata":{"id":"PE7JCWWLUquw","executionInfo":{"status":"ok","timestamp":1727006487094,"user_tz":-540,"elapsed":1,"user":{"displayName":"Tae Kyu Lee","userId":"00886399863979660459"}}},"execution_count":2,"outputs":[]},{"cell_type":"code","source":["# import os\n","\n","# os.environ[\"KERAS_BACKEND\"] = \"jax\""],"metadata":{"id":"qtK9JTtoYo8b","executionInfo":{"status":"ok","timestamp":1727006487102,"user_tz":-540,"elapsed":1,"user":{"displayName":"Tae Kyu Lee","userId":"00886399863979660459"}}},"execution_count":3,"outputs":[]},{"cell_type":"markdown","source":["이 가이드에서는, `HyperModel` 코드를 직접 변경하지 않고, 검색 공간을 맞춤 설정하는 방법을 보여줍니다.\n","예를 들어, 일부 하이퍼파라미터만 튜닝하고 나머지는 고정하거나,\n","`optimizer`, `loss`, `metrics`와 같은 컴파일 인수를 재정의할 수 있습니다."],"metadata":{"id":"D4hBWBj7mWLF"}},{"cell_type":"markdown","source":["## 하이퍼파라미터의 기본값"],"metadata":{"id":"vqc-CuskmXSH"}},{"cell_type":"markdown","source":["검색 공간을 맞춤 설정하기 전에,\n","모든 하이퍼파라미터에는 기본값이 있다는 것을 알아야 합니다.\n","이 기본값은 검색 공간을 맞춤 설정할 때,\n","해당 하이퍼파라미터를 튜닝하지 않는 경우에 사용됩니다.\n","\n","하이퍼파라미터를 등록할 때 `default` 인수를 사용하여, 기본값을 지정할 수 있습니다.\n","\n","```python\n","hp.Int(\"units\", min_value=32, max_value=128, step=32, default=64)\n","```\n","\n","기본값을 지정하지 않으면, 하이퍼파라미터에는 기본값이 자동으로 지정됩니다. (`Int`의 경우 `min_value`와 동일한 값)\n","\n","다음 모델 빌딩 함수에서, `units` 하이퍼파라미터의 기본값을 64로 지정했습니다."],"metadata":{"id":"TI9Xptq5mZ1_"}},{"cell_type":"code","execution_count":4,"metadata":{"id":"yQPBk7YLkNvz","executionInfo":{"status":"ok","timestamp":1727006488998,"user_tz":-540,"elapsed":1887,"user":{"displayName":"Tae Kyu Lee","userId":"00886399863979660459"}}},"outputs":[],"source":["import keras\n","from keras import layers\n","import keras_tuner\n","import numpy as np\n","\n","\n","def build_model(hp):\n","    model = keras.Sequential()\n","    model.add(layers.Flatten())\n","    model.add(\n","        layers.Dense(\n","            units=hp.Int(\"units\", min_value=32, max_value=128, step=32, default=64)\n","        )\n","    )\n","    if hp.Boolean(\"dropout\"):\n","        model.add(layers.Dropout(rate=0.25))\n","    model.add(layers.Dense(units=10, activation=\"softmax\"))\n","    model.compile(\n","        optimizer=keras.optimizers.Adam(\n","            learning_rate=hp.Choice(\"learning_rate\", values=[1e-2, 1e-3, 1e-4])\n","        ),\n","        loss=\"sparse_categorical_crossentropy\",\n","        metrics=[\"accuracy\"],\n","    )\n","    return model"]},{"cell_type":"markdown","source":["우리는 튜토리얼의 나머지 부분에서 새로운 검색 공간을 정의하지 않고,\n","하이퍼파라미터를 재정의하여 이 검색 공간을 재사용할 것입니다."],"metadata":{"id":"AHgb5GKrmeit"}},{"cell_type":"markdown","source":["## 일부만 검색하고 나머지는 고정"],"metadata":{"id":"w_y0zFpfmfx7"}},{"cell_type":"markdown","source":["기존의 하이퍼모델이 있고, 일부 하이퍼파라미터만 검색하고 나머지는 고정하고 싶다면,\n","모델 빌딩 함수나 `HyperModel` 코드에서 변경할 필요가 없습니다.\n","튜너 생성자에서 `hyperparameters` 인수로 검색하려는 모든 하이퍼파라미터를 포함한,\n","`HyperParameters` 객체를 전달할 수 있습니다.\n","다른 하이퍼파라미터의 튜닝을 방지하려면, `tune_new_entries=False`를 지정하여,\n","나머지 하이퍼파라미터는 기본값을 사용하도록 설정합니다.\n","\n","다음 예시에서 우리는 `learning_rate` 하이퍼파라미터만 튜닝하며, 그 타입과 값 범위를 변경했습니다."],"metadata":{"id":"IIQ116cemhSb"}},{"cell_type":"code","execution_count":5,"metadata":{"id":"j6oe5wkFkNv0","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1727006494005,"user_tz":-540,"elapsed":4912,"user":{"displayName":"Tae Kyu Lee","userId":"00886399863979660459"}},"outputId":"2cc0ace1-2c8a-4fd1-bd43-b54be38cc805"},"outputs":[{"output_type":"stream","name":"stdout","text":["Trial 3 Complete [00h 00m 01s]\n","val_accuracy: 0.10000000149011612\n","\n","Best val_accuracy So Far: 0.10000000149011612\n","Total elapsed time: 00h 00m 05s\n"]}],"source":["hp = keras_tuner.HyperParameters()\n","\n","# `learning_rate` 파라미터를 사용자가 선택한 값으로 재정의\n","hp.Float(\"learning_rate\", min_value=1e-4, max_value=1e-2, sampling=\"log\")\n","\n","tuner = keras_tuner.RandomSearch(\n","    hypermodel=build_model,\n","    hyperparameters=hp,\n","    # 나열되지 않은 파라미터는 튜닝하지 않음\n","    tune_new_entries=False,\n","    objective=\"val_accuracy\",\n","    max_trials=3,\n","    overwrite=True,\n","    directory=\"my_dir\",\n","    project_name=\"search_a_few\",\n",")\n","\n","# 랜덤 데이터 생성\n","x_train = np.random.rand(100, 28, 28, 1)\n","y_train = np.random.randint(0, 10, (100, 1))\n","x_val = np.random.rand(20, 28, 28, 1)\n","y_val = np.random.randint(0, 10, (20, 1))\n","\n","# 검색 실행\n","tuner.search(x_train, y_train, epochs=1, validation_data=(x_val, y_val))"]},{"cell_type":"markdown","metadata":{"id":"SynBRCeHkNv0"},"source":["하이퍼파라미터 검색 공간을 요약하면, 단 하나의 하이퍼파라미터만 볼 수 있습니다."]},{"cell_type":"code","execution_count":6,"metadata":{"id":"IEL6yP2XkNv0","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1727006494021,"user_tz":-540,"elapsed":14,"user":{"displayName":"Tae Kyu Lee","userId":"00886399863979660459"}},"outputId":"d737165f-8d3b-4af5-8598-8b9207dbfc68"},"outputs":[{"output_type":"stream","name":"stdout","text":["Search space summary\n","Default search space size: 1\n","learning_rate (Float)\n","{'default': 0.0001, 'conditions': [], 'min_value': 0.0001, 'max_value': 0.01, 'step': None, 'sampling': 'log'}\n"]}],"source":["tuner.search_space_summary()"]},{"cell_type":"markdown","source":["## 일부를 고정하고 나머지를 튜닝"],"metadata":{"id":"b5qdqYZSmm_n"}},{"cell_type":"markdown","source":["위 예시에서는 일부 하이퍼파라미터만 튜닝하고 나머지는 고정하는 방법을 보여주었습니다.\n","반대로, 일부 하이퍼파라미터만 고정하고 나머지를 모두 튜닝할 수도 있습니다.\n","\n","다음 예시에서는 `learning_rate` 하이퍼파라미터의 값을 고정했습니다.\n","`Fixed` 항목을 포함한 `hyperparameters` 인수를 전달하고,\n","`tune_new_entries=True`로 설정하여 나머지 하이퍼파라미터를 튜닝할 수 있습니다."],"metadata":{"id":"xM83SA06moUs"}},{"cell_type":"code","execution_count":7,"metadata":{"id":"AuWoleAmkNv1","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1727006501420,"user_tz":-540,"elapsed":7399,"user":{"displayName":"Tae Kyu Lee","userId":"00886399863979660459"}},"outputId":"863ecc18-fb8e-4211-86ae-a5a5e129377d"},"outputs":[{"output_type":"stream","name":"stdout","text":["Trial 3 Complete [00h 00m 03s]\n","val_accuracy: 0.05000000074505806\n","\n","Best val_accuracy So Far: 0.20000000298023224\n","Total elapsed time: 00h 00m 07s\n"]}],"source":["hp = keras_tuner.HyperParameters()\n","hp.Fixed(\"learning_rate\", value=1e-4)\n","\n","tuner = keras_tuner.RandomSearch(\n","    build_model,\n","    hyperparameters=hp,\n","    tune_new_entries=True,\n","    objective=\"val_accuracy\",\n","    max_trials=3,\n","    overwrite=True,\n","    directory=\"my_dir\",\n","    project_name=\"fix_a_few\",\n",")\n","\n","tuner.search(x_train, y_train, epochs=1, validation_data=(x_val, y_val))"]},{"cell_type":"markdown","metadata":{"id":"PffbHFwtkNv1"},"source":["검색 공간을 요약하면, `learning_rate`는 고정된 것으로 표시되고,\n","나머지 하이퍼파라미터는 튜닝되고 있음을 확인할 수 있습니다."]},{"cell_type":"code","execution_count":8,"metadata":{"id":"AtCV6LHOkNv1","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1727006501424,"user_tz":-540,"elapsed":3,"user":{"displayName":"Tae Kyu Lee","userId":"00886399863979660459"}},"outputId":"99fac986-f508-4357-a0a0-413ecd2a8915"},"outputs":[{"output_type":"stream","name":"stdout","text":["Search space summary\n","Default search space size: 3\n","learning_rate (Fixed)\n","{'conditions': [], 'value': 0.0001}\n","units (Int)\n","{'default': 64, 'conditions': [], 'min_value': 32, 'max_value': 128, 'step': 32, 'sampling': 'linear'}\n","dropout (Boolean)\n","{'default': False, 'conditions': []}\n"]}],"source":["tuner.search_space_summary()"]},{"cell_type":"markdown","source":["## 컴파일 인수 재정의"],"metadata":{"id":"onCv4tcJmuS5"}},{"cell_type":"markdown","source":["기존 하이퍼모델에서 옵티마이저, 손실 함수, 또는 메트릭스를 변경하고 싶다면,\n","이러한 인수를 튜너 생성자에 전달하여 변경할 수 있습니다."],"metadata":{"id":"2mWp26QJmvmR"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"EGWGpV-FkNv1","colab":{"base_uri":"https://localhost:8080/"},"outputId":"5df809f9-0e7e-4742-8026-4178fd6c89b9"},"outputs":[{"output_type":"stream","name":"stdout","text":["Trial 2 Complete [00h 00m 02s]\n","val_loss: 37.155399322509766\n","\n","Best val_loss So Far: 37.15408706665039\n","Total elapsed time: 00h 00m 05s\n","\n","Search: Running Trial #3\n","\n","Value             |Best Value So Far |Hyperparameter\n","128               |32                |units\n","True              |True              |dropout\n","0.001             |0.001             |learning_rate\n","\n"]}],"source":["tuner = keras_tuner.RandomSearch(\n","    build_model,\n","    optimizer=keras.optimizers.Adam(1e-3),\n","    loss=\"mse\",\n","    metrics=[\n","        \"sparse_categorical_crossentropy\",\n","    ],\n","    objective=\"val_loss\",\n","    max_trials=3,\n","    overwrite=True,\n","    directory=\"my_dir\",\n","    project_name=\"override_compile\",\n",")\n","\n","tuner.search(x_train, y_train, epochs=1, validation_data=(x_val, y_val))"]},{"cell_type":"markdown","metadata":{"id":"5Af1NZAWkNv1"},"source":["최상의 모델을 얻으면, 손실 함수가 MSE로 변경된 것을 확인할 수 있습니다."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"yb_ZhprEkNv1"},"outputs":[],"source":["tuner.get_best_models()[0].loss"]},{"cell_type":"markdown","source":["## 미리 빌드된 하이퍼모델의 검색 공간 맞춤 설정"],"metadata":{"id":"eNUZLcRbm0MK"}},{"cell_type":"markdown","source":["이 기술은 KerasTuner의 `HyperResNet`이나 `HyperXception`과 같은 미리 빌드된 모델에서도 사용할 수 있습니다.\n","그러나, 이러한 미리 빌드된 `HyperModel`에서 어떤 하이퍼파라미터가 있는지 확인하려면, 소스 코드를 읽어야 합니다.\n","\n","다음 예시에서는, `HyperXception`의 `learning_rate`만 튜닝하고, 나머지 하이퍼파라미터는 모두 고정했습니다.\n","`HyperXception`의 기본 손실 함수는 `categorical_crossentropy`인데,\n","이는 라벨이 원-핫 인코딩된 데이터를 기대합니다.\n","우리의 정수형 라벨 데이터와 맞지 않으므로,\n","컴파일 인수에서 `loss`를 `sparse_categorical_crossentropy`로 재정의해야 합니다."],"metadata":{"id":"WHBGomMsm1in"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"XNmrsu8IkNv2"},"outputs":[],"source":["hypermodel = keras_tuner.applications.HyperXception(input_shape=(28, 28, 1), classes=10)\n","\n","hp = keras_tuner.HyperParameters()\n","\n","# `learning_rate` 파라미터를 사용자가 선택한 값으로 재정의\n","hp.Choice(\"learning_rate\", values=[1e-2, 1e-3, 1e-4])\n","\n","tuner = keras_tuner.RandomSearch(\n","    hypermodel,\n","    hyperparameters=hp,\n","    # 나열되지 않은 파라미터는 튜닝하지 않음\n","    tune_new_entries=False,\n","    # 손실 함수 재정의\n","    loss=\"sparse_categorical_crossentropy\",\n","    metrics=[\"accuracy\"],\n","    objective=\"val_accuracy\",\n","    max_trials=3,\n","    overwrite=True,\n","    directory=\"my_dir\",\n","    project_name=\"helloworld\",\n",")\n","\n","# 검색 실행\n","tuner.search(x_train, y_train, epochs=1, validation_data=(x_val, y_val))\n","tuner.search_space_summary()"]}],"metadata":{"accelerator":"None","colab":{"provenance":[{"file_id":"https://github.com/keras-team/keras-io/blob/master/guides/ipynb/keras_tuner/tailor_the_search_space.ipynb","timestamp":1727005778659}],"toc_visible":true},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.0"}},"nbformat":4,"nbformat_minor":0}