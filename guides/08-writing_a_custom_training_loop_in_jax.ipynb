{"cells":[{"cell_type":"markdown","source":["# JAX에서 처음부터 트레이닝 루프 작성하기"],"metadata":{"id":"xmLA65pa3MnO"}},{"cell_type":"markdown","source":["**저자:** [fchollet](https://twitter.com/fchollet)  \n","**생성일:** 2023/06/25  \n","**최종편집일:** 2023/06/25  \n","**설명:** JAX에서 낮은 레벨의 트레이닝 및 평가 루프 작성하기"],"metadata":{"id":"ES5sGaym3OiF"}},{"cell_type":"code","execution_count":1,"metadata":{"id":"2lwgANit2-fL","executionInfo":{"status":"ok","timestamp":1726960460657,"user_tz":-540,"elapsed":44,"user":{"displayName":"Tae Kyu Lee","userId":"00886399863979660459"}}},"outputs":[],"source":["# !pip install keras --upgrade --quiet"]},{"cell_type":"markdown","metadata":{"id":"BQ0BTmeO2-fM"},"source":["## 셋업"]},{"cell_type":"code","execution_count":2,"metadata":{"id":"eejuOL5a2-fM","executionInfo":{"status":"ok","timestamp":1726960463267,"user_tz":-540,"elapsed":1784,"user":{"displayName":"Tae Kyu Lee","userId":"00886399863979660459"}}},"outputs":[],"source":["import os\n","\n","# This guide can only be run with the jax backend.\n","os.environ[\"KERAS_BACKEND\"] = \"jax\"\n","\n","import jax\n","\n","# We import TF so we can use tf.data.\n","import tensorflow as tf\n","import keras\n","import numpy as np"]},{"cell_type":"code","source":["from keras import backend\n","print(backend.backend())"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"NiXRvrbF3UMa","executionInfo":{"status":"ok","timestamp":1726960463277,"user_tz":-540,"elapsed":9,"user":{"displayName":"Tae Kyu Lee","userId":"00886399863979660459"}},"outputId":"ca1c61a4-1fe9-4d25-be70-247ea23dd70f"},"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["jax\n"]}]},{"cell_type":"markdown","source":["## 소개"],"metadata":{"id":"Wnxo0ZzY3YF0"}},{"cell_type":"markdown","source":["Keras는 기본 트레이닝 및 평가 루프인 `fit()`과 `evaluate()`를 제공합니다.\n","이러한 사용 방법은 [빌트인 메서드를 사용한 트레이닝 및 평가](https://codecompose7.github.io/keras-doc-kr.github.io/guides/training_with_built_in_methods/) 가이드에서 다룹니다.\n","\n","모델의 학습 알고리즘을 커스터마이즈하면서도 `fit()`의 편리함을 활용하고 싶다면\n","(예를 들어, `fit()`을 사용해 GAN을 트레이닝하려는 경우),\n","`Model` 클래스를 서브클래싱하고,\n","`fit()` 동안 반복적으로 호출되는 자체 `train_step()` 메서드를 구현할 수 있습니다.\n","\n","이제, 트레이닝 및 평가에 대해 매우 낮은 레벨의 제어를 원한다면,\n","처음부터 직접 트레이닝 및 평가 루프를 작성해야 합니다. 이 가이드는 그것에 관한 것입니다."],"metadata":{"id":"CTgKhzjY3ZYK"}},{"cell_type":"markdown","source":["## 첫 번째 엔드 투 엔드 예제"],"metadata":{"id":"FzFZlChA3hQM"}},{"cell_type":"markdown","source":["커스텀 트레이닝 루프를 작성하려면, 다음이 필요합니다:\n","\n","- 트레이닝할 모델.\n","- 옵티마이저. `keras.optimizers`의 옵티마이저를 사용하거나, `optax` 패키지에서 사용할 수 있습니다.\n","- 손실 함수.\n","- 데이터셋. JAX 생태계의 표준은 [`tf.data`](https://www.tensorflow.org/api_docs/python/tf/data)를 통해 데이터를 로드하는 것이므로, 이를 사용할 것입니다.\n","\n","이제 하나씩 설정해 보겠습니다.\n","\n","먼저, 모델과 MNIST 데이터셋을 가져옵니다:"],"metadata":{"id":"BcHjdCJk3iyG"}},{"cell_type":"code","execution_count":12,"metadata":{"id":"jMMy3AcD2-fM","colab":{"base_uri":"https://localhost:8080/","height":382},"executionInfo":{"status":"error","timestamp":1726960755417,"user_tz":-540,"elapsed":10297,"user":{"displayName":"Tae Kyu Lee","userId":"00886399863979660459"}},"outputId":"40e4ca7f-9259-4eb5-a55d-887419ab51da"},"outputs":[{"output_type":"error","ename":"InternalError","evalue":"Failed copying input tensor from /job:localhost/replica:0/task:0/device:CPU:0 to /job:localhost/replica:0/task:0/device:GPU:0 in order to run _EagerConst: Dst tensor is not initialized.","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mInternalError\u001b[0m                             Traceback (most recent call last)","\u001b[0;32m<ipython-input-12-4a7feb17c5cf>\u001b[0m in \u001b[0;36m<cell line: 27>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;31m# 트레이닝 데이터셋 준비.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m \u001b[0mtrain_dataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_tensor_slices\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m \u001b[0mtrain_dataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_dataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbuffer_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1024\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/data/ops/dataset_ops.py\u001b[0m in \u001b[0;36mfrom_tensor_slices\u001b[0;34m(tensors, name)\u001b[0m\n\u001b[1;32m    824\u001b[0m     \u001b[0;31m# pylint: disable=g-import-not-at-top,protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    825\u001b[0m     \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mops\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mfrom_tensor_slices_op\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 826\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mfrom_tensor_slices_op\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_from_tensor_slices\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    827\u001b[0m     \u001b[0;31m# pylint: enable=g-import-not-at-top,protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    828\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/data/ops/from_tensor_slices_op.py\u001b[0m in \u001b[0;36m_from_tensor_slices\u001b[0;34m(tensors, name)\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_from_tensor_slices\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0m_TensorSliceDataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/data/ops/from_tensor_slices_op.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, element, is_files, name)\u001b[0m\n\u001b[1;32m     31\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0melement\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mis_files\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m     \u001b[0;34m\"\"\"See `Dataset.from_tensor_slices` for details.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 33\u001b[0;31m     \u001b[0melement\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstructure\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnormalize_element\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0melement\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     34\u001b[0m     \u001b[0mbatched_spec\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstructure\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtype_spec_from_value\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0melement\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_tensors\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstructure\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_batched_tensor_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatched_spec\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0melement\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/data/util/structure.py\u001b[0m in \u001b[0;36mnormalize_element\u001b[0;34m(element, element_signature)\u001b[0m\n\u001b[1;32m    132\u001b[0m           \u001b[0mdtype\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mspec\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"dtype\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    133\u001b[0m           normalized_components.append(\n\u001b[0;32m--> 134\u001b[0;31m               ops.convert_to_tensor(t, name=\"component_%d\" % i, dtype=dtype))\n\u001b[0m\u001b[1;32m    135\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mnest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpack_sequence_as\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpack_as\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnormalized_components\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    136\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/profiler/trace.py\u001b[0m in \u001b[0;36mwrapped\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    181\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mTrace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrace_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mtrace_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    182\u001b[0m           \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 183\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    184\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    185\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mwrapped\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36mconvert_to_tensor\u001b[0;34m(value, dtype, name, as_ref, preferred_dtype, dtype_hint, ctx, accepted_result_types)\u001b[0m\n\u001b[1;32m    711\u001b[0m   \u001b[0;31m# TODO(b/142518781): Fix all call-sites and remove redundant arg\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    712\u001b[0m   \u001b[0mpreferred_dtype\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpreferred_dtype\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mdtype_hint\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 713\u001b[0;31m   return tensor_conversion_registry.convert(\n\u001b[0m\u001b[1;32m    714\u001b[0m       \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mas_ref\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpreferred_dtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maccepted_result_types\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    715\u001b[0m   )\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/framework/tensor_conversion_registry.py\u001b[0m in \u001b[0;36mconvert\u001b[0;34m(value, dtype, name, as_ref, preferred_dtype, accepted_result_types)\u001b[0m\n\u001b[1;32m    232\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    233\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mret\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 234\u001b[0;31m       \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconversion_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mas_ref\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mas_ref\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    235\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    236\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mret\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mNotImplemented\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/framework/constant_tensor_conversion.py\u001b[0m in \u001b[0;36m_constant_tensor_conversion_function\u001b[0;34m(v, dtype, name, as_ref)\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m   \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mas_ref\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 29\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mconstant_op\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconstant\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     30\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/ops/weak_tensor_ops.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    140\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    141\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_auto_dtype_conversion_enabled\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 142\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    143\u001b[0m     \u001b[0mbound_arguments\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msignature\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbind\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    144\u001b[0m     \u001b[0mbound_arguments\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_defaults\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/framework/constant_op.py\u001b[0m in \u001b[0;36mconstant\u001b[0;34m(value, dtype, shape, name)\u001b[0m\n\u001b[1;32m    274\u001b[0m     \u001b[0mValueError\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mcalled\u001b[0m \u001b[0mon\u001b[0m \u001b[0ma\u001b[0m \u001b[0msymbolic\u001b[0m \u001b[0mtensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    275\u001b[0m   \"\"\"\n\u001b[0;32m--> 276\u001b[0;31m   return _constant_impl(value, dtype, shape, name, verify_shape=False,\n\u001b[0m\u001b[1;32m    277\u001b[0m                         allow_broadcast=True)\n\u001b[1;32m    278\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/framework/constant_op.py\u001b[0m in \u001b[0;36m_constant_impl\u001b[0;34m(value, dtype, shape, name, verify_shape, allow_broadcast)\u001b[0m\n\u001b[1;32m    287\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mtrace\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTrace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"tf.constant\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    288\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0m_constant_eager_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mctx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverify_shape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 289\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_constant_eager_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mctx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverify_shape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    290\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    291\u001b[0m   const_tensor = ops._create_graph_constant(  # pylint: disable=protected-access\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/framework/constant_op.py\u001b[0m in \u001b[0;36m_constant_eager_impl\u001b[0;34m(ctx, value, dtype, shape, verify_shape)\u001b[0m\n\u001b[1;32m    299\u001b[0m ) -> ops._EagerTensorBase:\n\u001b[1;32m    300\u001b[0m   \u001b[0;34m\"\"\"Creates a constant on the current device.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 301\u001b[0;31m   \u001b[0mt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconvert_to_eager_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mctx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    302\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mshape\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    303\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/framework/constant_op.py\u001b[0m in \u001b[0;36mconvert_to_eager_tensor\u001b[0;34m(value, ctx, dtype)\u001b[0m\n\u001b[1;32m    106\u001b[0m       \u001b[0mdtype\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdtypes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_dtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_datatype_enum\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    107\u001b[0m   \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 108\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mEagerTensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    109\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    110\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mInternalError\u001b[0m: Failed copying input tensor from /job:localhost/replica:0/task:0/device:CPU:0 to /job:localhost/replica:0/task:0/device:GPU:0 in order to run _EagerConst: Dst tensor is not initialized."]}],"source":["# def get_model():\n","#     inputs = keras.Input(shape=(784,), name=\"digits\")\n","#     x1 = keras.layers.Dense(64, activation=\"relu\")(inputs)\n","#     x2 = keras.layers.Dense(64, activation=\"relu\")(x1)\n","#     outputs = keras.layers.Dense(10, name=\"predictions\")(x2)\n","#     model = keras.Model(inputs=inputs, outputs=outputs)\n","#     return model\n","\n","\n","# model = get_model()\n","\n","# # 트레이닝 데이터셋 준비.\n","# batch_size = 32\n","# (x_train, y_train), (x_test, y_test) = keras.datasets.mnist.load_data()\n","# x_train = np.reshape(x_train, (-1, 784)).astype(\"float32\")\n","# x_test = np.reshape(x_test, (-1, 784)).astype(\"float32\")\n","# y_train = keras.utils.to_categorical(y_train)\n","# y_test = keras.utils.to_categorical(y_test)\n","\n","# # 검증을 위해 10,000개의 샘플을 예약합니다.\n","# x_val = x_train[-10000:]\n","# y_val = y_train[-10000:]\n","# x_train = x_train[:-10000]\n","# y_train = y_train[:-10000]\n","\n","# # 트레이닝 데이터셋 준비.\n","# train_dataset = tf.data.Dataset.from_tensor_slices((x_train, y_train))\n","# train_dataset = train_dataset.shuffle(buffer_size=1024).batch(batch_size)\n","\n","# # 검증 데이터셋 준비.\n","# val_dataset = tf.data.Dataset.from_tensor_slices((x_val, y_val))\n","# val_dataset = val_dataset.batch(batch_size)"]},{"cell_type":"code","source":["def get_model():\n","    inputs = keras.Input(shape=(784,), name=\"digits\")\n","    x1 = keras.layers.Dense(64, activation=\"relu\")(inputs)\n","    x2 = keras.layers.Dense(64, activation=\"relu\")(x1)\n","    outputs = keras.layers.Dense(10, name=\"predictions\")(x2)\n","    model = keras.Model(inputs=inputs, outputs=outputs)\n","    return model\n","\n","\n","model = get_model()\n","\n","# 트레이닝 데이터셋 준비.\n","batch_size = 32\n","(x_train, y_train), (x_test, y_test) = keras.datasets.mnist.load_data()\n","x_train = np.reshape(x_train, (-1, 784)).astype(\"float32\")\n","x_test = np.reshape(x_test, (-1, 784)).astype(\"float32\")\n","y_train = keras.utils.to_categorical(y_train)\n","y_test = keras.utils.to_categorical(y_test)\n","\n","# 검증을 위해 10,000개의 샘플을 예약합니다.\n","x_val = x_train[-10000:]\n","y_val = y_train[-10000:]\n","x_train = x_train[:-10000]\n","y_train = y_train[:-10000]\n","\n","# GPU 사용 설정을 제어하여 텐서플로가 CPU에서만 연산하도록 설정\n","with tf.device('/CPU:0'):\n","    train_dataset = tf.data.Dataset.from_tensor_slices((x_train, y_train))\n","    train_dataset = train_dataset.shuffle(buffer_size=1024).batch(batch_size)\n","\n","    val_dataset = tf.data.Dataset.from_tensor_slices((x_val, y_val))\n","    val_dataset = val_dataset.batch(batch_size)"],"metadata":{"id":"DvVRkLZ24dFl","executionInfo":{"status":"ok","timestamp":1726960777194,"user_tz":-540,"elapsed":294,"user":{"displayName":"Tae Kyu Lee","userId":"00886399863979660459"}}},"execution_count":13,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"gf0YgifD2-fN"},"source":["다음으로, 손실 함수와 옵티마이저를 설정합니다. 이번에는 Keras 옵티마이저를 사용합니다."]},{"cell_type":"code","execution_count":14,"metadata":{"id":"Zg5jgxnl2-fN","executionInfo":{"status":"ok","timestamp":1726960782669,"user_tz":-540,"elapsed":4,"user":{"displayName":"Tae Kyu Lee","userId":"00886399863979660459"}}},"outputs":[],"source":["# 손실 함수 인스턴스화.\n","loss_fn = keras.losses.CategoricalCrossentropy(from_logits=True)\n","\n","# 옵티마이저 인스턴스화.\n","optimizer = keras.optimizers.Adam(learning_rate=1e-3)"]},{"cell_type":"markdown","source":["### JAX에서 그래디언트 계산하기"],"metadata":{"id":"7KUcA0MS4mLs"}},{"cell_type":"markdown","source":["커스텀 트레이닝 루프를 사용하여, 미니 배치 그래디언트로 모델을 트레이닝해봅시다.\n","\n","JAX에서는 *메타프로그래밍(metaprogramming)*을 통해 그래디언트를 계산합니다.\n","`jax.grad` (또는 `jax.value_and_grad`)를 함수에 호출하여,\n","그 함수에 대한 그래디언트 계산 함수를 생성합니다.\n","\n","따라서 먼저 필요한 것은 손실 값을 반환하는 함수입니다.\n","이 함수를 사용하여 그래디언트 함수를 생성할 것입니다.\n","다음과 같은 형태입니다:\n","\n","```python\n","def compute_loss(x, y):\n","    ...\n","    return loss\n","```\n","\n","이와 같은 함수를 갖게 되면, 메타프로그래밍을 통해 다음과 같이 그래디언트를 계산할 수 있습니다:\n","\n","```python\n","grad_fn = jax.grad(compute_loss)\n","grads = grad_fn(x, y)\n","```\n","\n","일반적으로는, 단순히 그래디언트 값만 얻는 것이 아니라 손실 값도 함께 얻고자 합니다.\n","이를 위해 `jax.grad` 대신 `jax.value_and_grad`를 사용할 수 있습니다:\n","\n","```python\n","grad_fn = jax.value_and_grad(compute_loss)\n","loss, grads = grad_fn(x, y)\n","```"],"metadata":{"id":"ZazT5e8Y4ppi"}},{"cell_type":"markdown","source":["### JAX 계산은 순수하게 stateless입니다"],"metadata":{"id":"Xl8YjxRy4r-r"}},{"cell_type":"markdown","source":["JAX에서는, 모든 것이 stateless 함수여야 하므로, 손실 계산 함수도 stateless여야 합니다.\n","이는 모든 Keras 변수(예: 가중치 텐서)를 함수의 입력으로 전달해야 하며,\n","순전파 동안 업데이트된 모든 변수를 함수의 출력으로 반환해야 함을 의미합니다.\n","함수는 부수 효과가 없어야 합니다.\n","\n","순전파 동안 Keras 모델의 비트레이닝 변수는 업데이트될 수 있습니다.\n","이러한 변수는 예를 들어 RNG 시드 상태 변수나 BatchNormalization 통계일 수 있습니다.\n","우리는 이러한 변수들을 반환해야 합니다.\n","따라서 다음과 같은 함수가 필요합니다:\n","\n","```python\n","def compute_loss_and_updates(trainable_variables, non_trainable_variables, x, y):\n","    ...\n","    return loss, non_trainable_variables\n","```\n","\n","이러한 함수를 갖게 되면,\n","`value_and_grad`에서 `has_aux`를 지정하여 그래디언트 함수를 얻을 수 있습니다.\n","이는 JAX에 손실 계산 함수가 손실 외에도 더 많은 출력을 반환한다고 알려줍니다.\n","손실은 항상 첫 번째 출력이어야 한다는 점에 유의하세요.\n","\n","```python\n","grad_fn = jax.value_and_grad(compute_loss_and_updates, has_aux=True)\n","(loss, non_trainable_variables), grads = grad_fn(\n","    trainable_variables, non_trainable_variables, x, y\n",")\n","```\n","\n","이제 기본 사항을 정립했으니, `compute_loss_and_updates` 함수를 구현해봅시다.\n","Keras 모델에는 `stateless_call` 메서드가 있는데,\n","이 메서드는 여기서 유용하게 사용할 수 있습니다.\n","`model.__call__`과 비슷하게 작동하지만,\n","모델의 모든 변수 값을 명시적으로 전달해야 하며,\n","`__call__` 출력뿐만 아니라 (잠재적으로 업데이트된) 트레이닝 불가능한(non-trainable) 변수도 반환합니다.\n"],"metadata":{"id":"3BCUFZ3x4wuU"}},{"cell_type":"code","source":["def compute_loss_and_updates(trainable_variables, non_trainable_variables, x, y):\n","    y_pred, non_trainable_variables = model.stateless_call(\n","        trainable_variables, non_trainable_variables, x\n","    )\n","    loss = loss_fn(y, y_pred)\n","    return loss, non_trainable_variables"],"metadata":{"id":"BYfdPfdZ4zo7","executionInfo":{"status":"ok","timestamp":1726960860919,"user_tz":-540,"elapsed":2,"user":{"displayName":"Tae Kyu Lee","userId":"00886399863979660459"}}},"execution_count":15,"outputs":[]},{"cell_type":"markdown","source":["그래디언트 함수를 구해봅시다:"],"metadata":{"id":"cNEJXTi440qG"}},{"cell_type":"code","execution_count":16,"metadata":{"id":"KziWaNhV2-fN","executionInfo":{"status":"ok","timestamp":1726960861691,"user_tz":-540,"elapsed":1,"user":{"displayName":"Tae Kyu Lee","userId":"00886399863979660459"}}},"outputs":[],"source":["grad_fn = jax.value_and_grad(compute_loss_and_updates, has_aux=True)"]},{"cell_type":"markdown","source":["### 트레이닝 스텝 함수"],"metadata":{"id":"rt7IkUdt45TC"}},{"cell_type":"markdown","source":["다음으로, 엔드 투 엔드 트레이닝 스텝을 구현해봅시다.\n","이 함수는 순전파를 실행하고, 손실을 계산하고, 그래디언트를 계산하며,\n","옵티마이저를 사용하여 트레이닝 가능한 변수를 업데이트하는 역할을 합니다.\n","이 함수도 stateless여야 하므로,\n","우리가 사용할 모든 상태 요소를 포함하는 `state` 튜플을 입력으로 받아야 합니다:\n","\n","-   `trainable_variables` 및 `non_trainable_variables`: 모델의 변수들.\n","-   `optimizer_variables`: 옵티마이저의 상태 변수들, 예를 들어 모멘텀 누적기(momentum accumulators)와 같은 것들.\n","\n","트레이닝 가능한 변수를 업데이트하기 위해,\n","옵티마이저의 stateless 메서드인 `stateless_apply`를 사용합니다.\n","이는 `optimizer.apply()`와 동등하지만,\n","항상 `trainable_variables`와 `optimizer_variables`를 전달해야 합니다.\n","이는 업데이트된 `trainable_variables`와 업데이트된 `optimizer_variables`를 반환합니다."],"metadata":{"id":"gOYTUaSV47iV"}},{"cell_type":"code","execution_count":17,"metadata":{"id":"7MsiQNy62-fO","executionInfo":{"status":"ok","timestamp":1726960885504,"user_tz":-540,"elapsed":6,"user":{"displayName":"Tae Kyu Lee","userId":"00886399863979660459"}}},"outputs":[],"source":["def train_step(state, data):\n","    trainable_variables, non_trainable_variables, optimizer_variables = state\n","    x, y = data\n","    (loss, non_trainable_variables), grads = grad_fn(\n","        trainable_variables, non_trainable_variables, x, y\n","    )\n","    trainable_variables, optimizer_variables = optimizer.stateless_apply(\n","        grads, trainable_variables, optimizer_variables\n","    )\n","    # 업데이트된 상태 반환\n","    return loss, (\n","        trainable_variables,\n","        non_trainable_variables,\n","        optimizer_variables,\n","    )"]},{"cell_type":"markdown","source":["### `jax.jit`로 속도 향상시키기"],"metadata":{"id":"jhqK8Ovk4-7i"}},{"cell_type":"markdown","source":["기본적으로 JAX 연산은 TensorFlow eager 모드와 PyTorch eager 모드처럼, 즉시(eagerly) 실행됩니다.\n","그리고, TensorFlow eager 모드와 PyTorch eager 모드처럼 꽤 느립니다.\n","즉시 실행(eager) 모드는 디버깅 환경으로 더 적합하며,\n","실제 작업을 수행하는 방법으로는 적합하지 않습니다.\n","따라서, `train_step`을 컴파일하여 빠르게 만들어봅시다.\n","\n","stateless JAX 함수가 있는 경우,\n","`@jax.jit` 데코레이터를 통해 이를 XLA로 컴파일할 수 있습니다.\n","첫 번째 실행 시 함수가 추적되고,\n","이후 실행에서는 추적된 그래프를 실행하게 됩니다.\n","(이는 `@tf.function(jit_compile=True)`와 유사합니다)\n","시도해 봅시다:"],"metadata":{"id":"drygmHpP5BGm"}},{"cell_type":"code","execution_count":18,"metadata":{"id":"r1w_EtGh2-fO","executionInfo":{"status":"ok","timestamp":1726960907189,"user_tz":-540,"elapsed":2,"user":{"displayName":"Tae Kyu Lee","userId":"00886399863979660459"}}},"outputs":[],"source":["@jax.jit\n","def train_step(state, data):\n","    trainable_variables, non_trainable_variables, optimizer_variables = state\n","    x, y = data\n","    (loss, non_trainable_variables), grads = grad_fn(\n","        trainable_variables, non_trainable_variables, x, y\n","    )\n","    trainable_variables, optimizer_variables = optimizer.stateless_apply(\n","        optimizer_variables, grads, trainable_variables\n","    )\n","    # 업데이트된 상태 반환\n","    return loss, (\n","        trainable_variables,\n","        non_trainable_variables,\n","        optimizer_variables,\n","    )"]},{"cell_type":"markdown","metadata":{"id":"gC9M0EP02-fO"},"source":["이제 모델을 트레이닝할 준비가 되었습니다.\n","트레이닝 루프 자체는 간단합니다:\n","`loss, state = train_step(state, data)`를 반복적으로 호출하기만 하면 됩니다.\n","\n","참고:\n","\n","-   [`tf.data.Dataset`](https://www.tensorflow.org/api_docs/python/tf/data/Dataset)에서 생성된(yielded) TF 텐서를 JAX 함수에 전달하기 전에 NumPy로 변환합니다.\n","-   모든 변수는 사전에 빌드되어야 합니다: 모델은 빌드되어야 하고, 옵티마이저도 빌드되어야 합니다.\n","    우리가 사용하는 것은 Functional API 모델이므로 이미 빌드되어 있지만,\n","    만약 서브클래스화된 모델이라면 데이터를 하나의 배치에 대해 호출하여 빌드해야 합니다."]},{"cell_type":"code","execution_count":19,"metadata":{"id":"hpaPl0402-fO","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1726960927886,"user_tz":-540,"elapsed":1995,"user":{"displayName":"Tae Kyu Lee","userId":"00886399863979660459"}},"outputId":"3335b873-0955-42d7-842d-c4ba62e3d63a"},"outputs":[{"output_type":"stream","name":"stdout","text":["스텝 0에서의 트레이닝 손실 (1 배치 기준): 107.2267\n","지금까지 본 샘플 수: 32\n","스텝 100에서의 트레이닝 손실 (1 배치 기준): 6.7405\n","지금까지 본 샘플 수: 3232\n","스텝 200에서의 트레이닝 손실 (1 배치 기준): 2.7234\n","지금까지 본 샘플 수: 6432\n","스텝 300에서의 트레이닝 손실 (1 배치 기준): 1.1312\n","지금까지 본 샘플 수: 9632\n","스텝 400에서의 트레이닝 손실 (1 배치 기준): 1.1312\n","지금까지 본 샘플 수: 12832\n","스텝 500에서의 트레이닝 손실 (1 배치 기준): 1.5062\n","지금까지 본 샘플 수: 16032\n","스텝 600에서의 트레이닝 손실 (1 배치 기준): 0.6042\n","지금까지 본 샘플 수: 19232\n","스텝 700에서의 트레이닝 손실 (1 배치 기준): 0.8140\n","지금까지 본 샘플 수: 22432\n","스텝 800에서의 트레이닝 손실 (1 배치 기준): 0.5992\n","지금까지 본 샘플 수: 25632\n","스텝 900에서의 트레이닝 손실 (1 배치 기준): 0.0656\n","지금까지 본 샘플 수: 28832\n","스텝 1000에서의 트레이닝 손실 (1 배치 기준): 0.6418\n","지금까지 본 샘플 수: 32032\n","스텝 1100에서의 트레이닝 손실 (1 배치 기준): 0.3030\n","지금까지 본 샘플 수: 35232\n","스텝 1200에서의 트레이닝 손실 (1 배치 기준): 0.6413\n","지금까지 본 샘플 수: 38432\n","스텝 1300에서의 트레이닝 손실 (1 배치 기준): 0.9199\n","지금까지 본 샘플 수: 41632\n","스텝 1400에서의 트레이닝 손실 (1 배치 기준): 0.3257\n","지금까지 본 샘플 수: 44832\n","스텝 1500에서의 트레이닝 손실 (1 배치 기준): 0.5051\n","지금까지 본 샘플 수: 48032\n"]}],"source":["# 옵티마이저 변수 빌드\n","optimizer.build(model.trainable_variables)\n","\n","trainable_variables = model.trainable_variables\n","non_trainable_variables = model.non_trainable_variables\n","optimizer_variables = optimizer.variables\n","state = trainable_variables, non_trainable_variables, optimizer_variables\n","\n","# 트레이닝 루프\n","for step, data in enumerate(train_dataset):\n","    data = (data[0].numpy(), data[1].numpy())\n","    loss, state = train_step(state, data)\n","    # 100 배치마다 로그 출력\n","    if step % 100 == 0:\n","        print(f\"스텝 {step}에서의 트레이닝 손실 (1 배치 기준): {float(loss):.4f}\")\n","        print(f\"지금까지 본 샘플 수: {(step + 1) * batch_size}\")"]},{"cell_type":"markdown","metadata":{"id":"28AQ3Xu42-fO"},"source":["여기서 주목해야 할 중요한 점은 루프가 완전히 stateless하다는 것입니다.\n","모델에 첨부된 변수들(`model.weights`)은 루프 동안 절대 업데이트되지 않습니다.\n","변수의 새로운 값은 오직 `state` 튜플에만 저장됩니다.\n","이는 모델을 저장하기 전에, 새로운 변수 값을 다시 모델에 연결해야 한다는 것을 의미합니다.\n","\n","업데이트하려는 각 모델 변수에 대해,\n","`variable.assign(new_value)`를 호출하기만 하면 됩니다:"]},{"cell_type":"code","execution_count":20,"metadata":{"id":"vgOynX8r2-fO","executionInfo":{"status":"ok","timestamp":1726960952177,"user_tz":-540,"elapsed":4,"user":{"displayName":"Tae Kyu Lee","userId":"00886399863979660459"}}},"outputs":[],"source":["trainable_variables, non_trainable_variables, optimizer_variables = state\n","for variable, value in zip(model.trainable_variables, trainable_variables):\n","    variable.assign(value)\n","for variable, value in zip(model.non_trainable_variables, non_trainable_variables):\n","    variable.assign(value)"]},{"cell_type":"markdown","source":["## 메트릭의 낮은 레벨 처리"],"metadata":{"id":"SLB7JMal5PgV"}},{"cell_type":"markdown","source":["이 기본 트레이닝 루프에 메트릭 모니터링을 추가해 봅시다.\n","\n","이렇게 처음부터 작성한 트레이닝 루프에서도 빌트인 Keras 메트릭(또는 사용자가 작성한 커스텀 메트릭)을 쉽게 재사용할 수 있습니다. 흐름은 다음과 같습니다:\n","\n","-   루프 시작 시 메트릭을 인스턴스화합니다.\n","-   `train_step` 인자와 `compute_loss_and_updates` 인자에 `metric_variables`를 포함시킵니다.\n","-   `compute_loss_and_updates` 함수에서 `metric.stateless_update_state()`를 호출합니다.\n","    이는 `update_state()`와 같은 역할을 하지만, stateless인 것만 다릅니다.\n","-   `train_step` 외부 (즉시 실행 범위)에서 메트릭의 현재 값을 표시해야 할 때,\n","    새로운 메트릭 변수 값을 메트릭 객체에 연결하고, `metric.result()`를 호출합니다.\n","-   메트릭의 상태를 초기화해야 할 때(일반적으로 에포크가 끝날 때),\n","    `metric.reset_state()`를 호출합니다.\n","\n","이 지식을 사용하여 트레이닝이 끝날 때,\n","트레이닝 및 검증 데이터에 대한 `CategoricalAccuracy`를 계산해 보겠습니다:"],"metadata":{"id":"Z1wr8Vyu5RfN"}},{"cell_type":"code","execution_count":21,"metadata":{"id":"-fk79XPe2-fO","executionInfo":{"status":"ok","timestamp":1726960977429,"user_tz":-540,"elapsed":17,"user":{"displayName":"Tae Kyu Lee","userId":"00886399863979660459"}}},"outputs":[],"source":["# 새로운 모델 가져오기\n","model = get_model()\n","\n","# 모델을 트레이닝할 옵티마이저 인스턴스화\n","optimizer = keras.optimizers.Adam(learning_rate=1e-3)\n","# 손실 함수 인스턴스화\n","loss_fn = keras.losses.CategoricalCrossentropy(from_logits=True)\n","\n","# 메트릭 준비\n","train_acc_metric = keras.metrics.CategoricalAccuracy()\n","val_acc_metric = keras.metrics.CategoricalAccuracy()\n","\n","\n","def compute_loss_and_updates(\n","    trainable_variables, non_trainable_variables, metric_variables, x, y\n","):\n","    y_pred, non_trainable_variables = model.stateless_call(\n","        trainable_variables, non_trainable_variables, x\n","    )\n","    loss = loss_fn(y, y_pred)\n","    metric_variables = train_acc_metric.stateless_update_state(\n","        metric_variables, y, y_pred\n","    )\n","    return loss, (non_trainable_variables, metric_variables)\n","\n","\n","grad_fn = jax.value_and_grad(compute_loss_and_updates, has_aux=True)\n","\n","\n","@jax.jit\n","def train_step(state, data):\n","    (\n","        trainable_variables,\n","        non_trainable_variables,\n","        optimizer_variables,\n","        metric_variables,\n","    ) = state\n","    x, y = data\n","    (loss, (non_trainable_variables, metric_variables)), grads = grad_fn(\n","        trainable_variables, non_trainable_variables, metric_variables, x, y\n","    )\n","    trainable_variables, optimizer_variables = optimizer.stateless_apply(\n","        optimizer_variables, grads, trainable_variables\n","    )\n","    # 업데이트된 상태 반환\n","    return loss, (\n","        trainable_variables,\n","        non_trainable_variables,\n","        optimizer_variables,\n","        metric_variables,\n","    )"]},{"cell_type":"markdown","metadata":{"id":"tN6dEagq2-fO"},"source":["평가 스텝 함수도 준비해 보겠습니다:"]},{"cell_type":"code","execution_count":22,"metadata":{"id":"_44ptYt-2-fO","executionInfo":{"status":"ok","timestamp":1726960987648,"user_tz":-540,"elapsed":6,"user":{"displayName":"Tae Kyu Lee","userId":"00886399863979660459"}}},"outputs":[],"source":["@jax.jit\n","def eval_step(state, data):\n","    trainable_variables, non_trainable_variables, metric_variables = state\n","    x, y = data\n","    y_pred, non_trainable_variables = model.stateless_call(\n","        trainable_variables, non_trainable_variables, x\n","    )\n","    loss = loss_fn(y, y_pred)\n","    metric_variables = val_acc_metric.stateless_update_state(\n","        metric_variables, y, y_pred\n","    )\n","    return loss, (\n","        trainable_variables,\n","        non_trainable_variables,\n","        metric_variables,\n","    )"]},{"cell_type":"markdown","metadata":{"id":"2wZeYUXa2-fO"},"source":["다음은 우리의 루프입니다:"]},{"cell_type":"code","execution_count":23,"metadata":{"id":"NLZpIAva2-fO","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1726961002446,"user_tz":-540,"elapsed":1789,"user":{"displayName":"Tae Kyu Lee","userId":"00886399863979660459"}},"outputId":"9c4ee6e1-8dfa-4cf3-fe20-70556b31100f"},"outputs":[{"output_type":"stream","name":"stdout","text":["스텝 0에서의 트레이닝 손실 (1 배치 기준): 67.6475\n","트레이닝 정확도: 0.09375\n","지금까지 본 샘플 수: 32\n","스텝 100에서의 트레이닝 손실 (1 배치 기준): 0.5520\n","트레이닝 정확도: 0.6237623691558838\n","지금까지 본 샘플 수: 3232\n","스텝 200에서의 트레이닝 손실 (1 배치 기준): 1.7044\n","트레이닝 정확도: 0.7061566710472107\n","지금까지 본 샘플 수: 6432\n","스텝 300에서의 트레이닝 손실 (1 배치 기준): 3.9200\n","트레이닝 정확도: 0.7398255467414856\n","지금까지 본 샘플 수: 9632\n","스텝 400에서의 트레이닝 손실 (1 배치 기준): 1.7450\n","트레이닝 정확도: 0.7601309418678284\n","지금까지 본 샘플 수: 12832\n","스텝 500에서의 트레이닝 손실 (1 배치 기준): 0.8434\n","트레이닝 정확도: 0.7722055912017822\n","지금까지 본 샘플 수: 16032\n","스텝 600에서의 트레이닝 손실 (1 배치 기준): 1.3430\n","트레이닝 정확도: 0.7849417328834534\n","지금까지 본 샘플 수: 19232\n","스텝 700에서의 트레이닝 손실 (1 배치 기준): 0.8401\n","트레이닝 정확도: 0.7963623404502869\n","지금까지 본 샘플 수: 22432\n","스텝 800에서의 트레이닝 손실 (1 배치 기준): 0.5475\n","트레이닝 정확도: 0.8038779497146606\n","지금까지 본 샘플 수: 25632\n","스텝 900에서의 트레이닝 손실 (1 배치 기준): 0.7952\n","트레이닝 정확도: 0.8097253441810608\n","지금까지 본 샘플 수: 28832\n","스텝 1000에서의 트레이닝 손실 (1 배치 기준): 0.5830\n","트레이닝 정확도: 0.8139672875404358\n","지금까지 본 샘플 수: 32032\n","스텝 1100에서의 트레이닝 손실 (1 배치 기준): 0.3177\n","트레이닝 정확도: 0.8200215697288513\n","지금까지 본 샘플 수: 35232\n","스텝 1200에서의 트레이닝 손실 (1 배치 기준): 0.6213\n","트레이닝 정확도: 0.8245992660522461\n","지금까지 본 샘플 수: 38432\n","스텝 1300에서의 트레이닝 손실 (1 배치 기준): 0.4691\n","트레이닝 정확도: 0.8282090425491333\n","지금까지 본 샘플 수: 41632\n","스텝 1400에서의 트레이닝 손실 (1 배치 기준): 0.4223\n","트레이닝 정확도: 0.8325972557067871\n","지금까지 본 샘플 수: 44832\n","스텝 1500에서의 트레이닝 손실 (1 배치 기준): 0.9313\n","트레이닝 정확도: 0.8358386158943176\n","지금까지 본 샘플 수: 48032\n","스텝 0에서의 검증 손실 (1 배치 기준): 0.2635\n","검증 정확도: 0.8373241424560547\n","지금까지 본 샘플 수: 32\n","스텝 100에서의 검증 손실 (1 배치 기준): 0.2913\n","검증 정확도: 0.8384430408477783\n","지금까지 본 샘플 수: 3232\n","스텝 200에서의 검증 손실 (1 배치 기준): 0.2617\n","검증 정확도: 0.840462863445282\n","지금까지 본 샘플 수: 6432\n","스텝 300에서의 검증 손실 (1 배치 기준): 0.1913\n","검증 정확도: 0.8428528308868408\n","지금까지 본 샘플 수: 9632\n"]}],"source":["# 옵티마이저 변수 빌드\n","optimizer.build(model.trainable_variables)\n","\n","trainable_variables = model.trainable_variables\n","non_trainable_variables = model.non_trainable_variables\n","optimizer_variables = optimizer.variables\n","metric_variables = train_acc_metric.variables\n","state = (\n","    trainable_variables,\n","    non_trainable_variables,\n","    optimizer_variables,\n","    metric_variables,\n",")\n","\n","# 트레이닝 루프\n","for step, data in enumerate(train_dataset):\n","    data = (data[0].numpy(), data[1].numpy())\n","    loss, state = train_step(state, data)\n","    # 100 배치마다 로그 출력\n","    if step % 100 == 0:\n","        print(f\"스텝 {step}에서의 트레이닝 손실 (1 배치 기준): {float(loss):.4f}\")\n","        _, _, _, metric_variables = state\n","        for variable, value in zip(train_acc_metric.variables, metric_variables):\n","            variable.assign(value)\n","        print(f\"트레이닝 정확도: {train_acc_metric.result()}\")\n","        print(f\"지금까지 본 샘플 수: {(step + 1) * batch_size}\")\n","\n","metric_variables = val_acc_metric.variables\n","(\n","    trainable_variables,\n","    non_trainable_variables,\n","    optimizer_variables,\n","    metric_variables,\n",") = state\n","state = trainable_variables, non_trainable_variables, metric_variables\n","\n","# 평가 루프\n","for step, data in enumerate(val_dataset):\n","    data = (data[0].numpy(), data[1].numpy())\n","    loss, state = eval_step(state, data)\n","    # 100 배치마다 로그 출력\n","    if step % 100 == 0:\n","        print(f\"스텝 {step}에서의 검증 손실 (1 배치 기준): {float(loss):.4f}\")\n","        _, _, metric_variables = state\n","        for variable, value in zip(val_acc_metric.variables, metric_variables):\n","            variable.assign(value)\n","        print(f\"검증 정확도: {val_acc_metric.result()}\")\n","        print(f\"지금까지 본 샘플 수: {(step + 1) * batch_size}\")"]},{"cell_type":"markdown","source":["## 모델이 추적하는 손실의 낮은 레벨 처리"],"metadata":{"id":"cBDoNd0k5dx9"}},{"cell_type":"markdown","source":["레이어와 모델은 순전파 중,\n","`self.add_loss(value)`를 호출하는 레이어에 의해 생성된 모든 손실을 재귀적으로 추적합니다.\n","그 결과 생성된 스칼라 손실 값들의 목록은,\n","순전파가 끝난 후 `model.losses` 속성을 통해 확인할 수 있습니다.\n","\n","이러한 손실 요소들을 사용하고 싶다면,\n","이를 합산하여 트레이닝 스텝의 메인 손실에 추가해야 합니다.\n","\n","활동 정규화 손실을 생성하는 다음 레이어를 고려해 보세요:"],"metadata":{"id":"koM45Uz35fiq"}},{"cell_type":"code","execution_count":24,"metadata":{"id":"KY9ZQqEN2-fO","executionInfo":{"status":"ok","timestamp":1726961043868,"user_tz":-540,"elapsed":5,"user":{"displayName":"Tae Kyu Lee","userId":"00886399863979660459"}}},"outputs":[],"source":["class ActivityRegularizationLayer(keras.layers.Layer):\n","    def call(self, inputs):\n","        self.add_loss(1e-2 * jax.numpy.sum(inputs))\n","        return inputs"]},{"cell_type":"markdown","metadata":{"id":"5NslOXuw2-fO"},"source":["간단한 모델을 빌드해봅시다:"]},{"cell_type":"code","execution_count":25,"metadata":{"id":"dGGVQBqP2-fO","executionInfo":{"status":"ok","timestamp":1726961044336,"user_tz":-540,"elapsed":20,"user":{"displayName":"Tae Kyu Lee","userId":"00886399863979660459"}}},"outputs":[],"source":["inputs = keras.Input(shape=(784,), name=\"digits\")\n","x = keras.layers.Dense(64, activation=\"relu\")(inputs)\n","# activity 정규화 레이어를 추가합니다.\n","x = ActivityRegularizationLayer()(x)\n","x = keras.layers.Dense(64, activation=\"relu\")(x)\n","outputs = keras.layers.Dense(10, name=\"predictions\")(x)\n","\n","model = keras.Model(inputs=inputs, outputs=outputs)"]},{"cell_type":"markdown","metadata":{"id":"0ZyX4nJY2-fP"},"source":["다음은 `compute_loss_and_updates` 함수가 어떻게 생겨야 하는지 보여줍니다:\n","\n","- `model.stateless_call()`에 `return_losses=True`를 전달합니다.\n","- 결과로 생성된 `losses`를 합산하여, 메인 손실에 추가합니다."]},{"cell_type":"code","execution_count":26,"metadata":{"id":"gBgDI_ej2-fP","executionInfo":{"status":"ok","timestamp":1726961057695,"user_tz":-540,"elapsed":4,"user":{"displayName":"Tae Kyu Lee","userId":"00886399863979660459"}}},"outputs":[],"source":["def compute_loss_and_updates(\n","    trainable_variables, non_trainable_variables, metric_variables, x, y\n","):\n","    y_pred, non_trainable_variables, losses = model.stateless_call(\n","        trainable_variables, non_trainable_variables, x, return_losses=True\n","    )\n","    loss = loss_fn(y, y_pred)\n","    if losses:\n","        loss += jax.numpy.sum(losses)\n","    metric_variables = train_acc_metric.stateless_update_state(\n","        metric_variables, y, y_pred\n","    )\n","    return loss, non_trainable_variables, metric_variables"]},{"cell_type":"markdown","metadata":{"id":"fELAbP0J2-fP"},"source":["이것으로 끝입니다!"]}],"metadata":{"accelerator":"None","colab":{"provenance":[{"file_id":"https://github.com/keras-team/keras-io/blob/master/guides/ipynb/writing_a_custom_training_loop_in_jax.ipynb","timestamp":1726960371921}],"toc_visible":true},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.0"}},"nbformat":4,"nbformat_minor":0}