{"cells":[{"cell_type":"markdown","source":["# 서브클래싱을 통해 새로운 레이어와 모델 만들기"],"metadata":{"id":"kE-KqpTenZCL"}},{"cell_type":"markdown","source":["**저자:** [fchollet](https://twitter.com/fchollet)  \n","**생성일:** 2019/03/01  \n","**최종편집일:** 2023/06/25  \n","**설명:** `Layer`와 `Model` 객체를 처음부터 작성하는 방법에 대한 전체 가이드입니다.\n"],"metadata":{"id":"YHKPVl1dna59"}},{"cell_type":"code","source":["# 이 노트북은 Keras 3이 설치되어 있다는 가정 하에 진행됩니다.\n","#\n","# !pip install keras --upgrade --quiet"],"metadata":{"id":"-4LZ9HnSiZ3C","executionInfo":{"status":"ok","timestamp":1726922747932,"user_tz":-540,"elapsed":4,"user":{"displayName":"Tae Kyu Lee","userId":"00886399863979660459"}}},"execution_count":1,"outputs":[]},{"cell_type":"code","source":["import numpy as np\n","import os\n","\n","os.environ[\"KERAS_BACKEND\"] = \"jax\""],"metadata":{"id":"TQLre7Mbibxy","executionInfo":{"status":"ok","timestamp":1726922748077,"user_tz":-540,"elapsed":3,"user":{"displayName":"Tae Kyu Lee","userId":"00886399863979660459"}}},"execution_count":2,"outputs":[]},{"cell_type":"code","source":["from keras import backend\n","print(backend.backend())"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ASK66I7XigmD","executionInfo":{"status":"ok","timestamp":1726922748809,"user_tz":-540,"elapsed":611,"user":{"displayName":"Tae Kyu Lee","userId":"00886399863979660459"}},"outputId":"54e5247a-cea8-4448-a044-657d90eb0ea7"},"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["jax\n"]}]},{"cell_type":"markdown","source":["## 소개"],"metadata":{"id":"Y5sZKs88nhL9"}},{"cell_type":"markdown","source":["이 가이드에서는 자체 서브클래싱된 레이어와 모델을 빌드하는 데 필요한 모든 내용을 다룹니다.\n","특히, 다음 기능에 대해 알아봅니다.\n","\n","* `Layer` 클래스\n","* `add_weight()` 메서드\n","* 트레이닝 가능한 가중치와 트레이닝 불가능한 가중치\n","* `build()` 메서드\n","* 레이어를 모든 백엔드에서 사용할 수 있는지 확인\n","* `add_loss()` 메서드\n","* `call()`의 `training` 인수\n","* `call()`의 `mask` 인수\n","* 레이어를 직렬화할 수 있는지 확인\n","\n","자세히 알아보겠습니다."],"metadata":{"id":"fim8isiunjsr"}},{"cell_type":"markdown","metadata":{"id":"FMWCV4s9nIUQ"},"source":["## 셋업"]},{"cell_type":"code","execution_count":4,"metadata":{"id":"S1QGuWgnnIUQ","executionInfo":{"status":"ok","timestamp":1726922778974,"user_tz":-540,"elapsed":42,"user":{"displayName":"Tae Kyu Lee","userId":"00886399863979660459"}}},"outputs":[],"source":["import numpy as np\n","import keras\n","from keras import ops\n","from keras import layers"]},{"cell_type":"markdown","source":["## `Layer` 클래스: 상태(가중치)와 일부 계산의 조합"],"metadata":{"id":"LDemjhQ_pWL2"}},{"cell_type":"markdown","source":["Keras의 중심 추상화 중 하나는 `Layer` 클래스입니다.\n","레이어는 상태(레이어의 \"가중치\")와 입력에서 출력으로의 변환(레이어의 포워드 패스인 \"호출\")을 모두 캡슐화합니다.\n","\n","다음은 밀집 연결 레이어(densely-connected layer)입니다.\n","여기에는 두 개의 상태 변수가 있습니다. 변수 `w`와 `b`입니다."],"metadata":{"id":"5rxFMIhkpXnc"}},{"cell_type":"code","execution_count":5,"metadata":{"id":"mQS3IUaHnIUR","executionInfo":{"status":"ok","timestamp":1726923255922,"user_tz":-540,"elapsed":7,"user":{"displayName":"Tae Kyu Lee","userId":"00886399863979660459"}}},"outputs":[],"source":["class Linear(keras.layers.Layer):\n","    def __init__(self, units=32, input_dim=32):\n","        super().__init__()\n","        self.w = self.add_weight(\n","            shape=(input_dim, units),\n","            initializer=\"random_normal\",\n","            trainable=True,\n","        )\n","        self.b = self.add_weight(shape=(units,), initializer=\"zeros\", trainable=True)\n","\n","    def call(self, inputs):\n","        return ops.matmul(inputs, self.w) + self.b"]},{"cell_type":"markdown","metadata":{"id":"S1LkKthDnIUS"},"source":["(Python 함수처럼) 텐서 입력에 대해 호출하여 레이어를 사용합니다."]},{"cell_type":"code","execution_count":6,"metadata":{"id":"xb4IfDOHnIUS","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1726923262695,"user_tz":-540,"elapsed":527,"user":{"displayName":"Tae Kyu Lee","userId":"00886399863979660459"}},"outputId":"1d266a7f-0b3c-4d57-85e9-730b0a6087cd"},"outputs":[{"output_type":"stream","name":"stdout","text":["[[-0.0796053   0.05426962  0.06638172 -0.13000847]\n"," [-0.0796053   0.05426962  0.06638172 -0.13000847]]\n"]}],"source":["x = ops.ones((2, 2))\n","linear_layer = Linear(4, 2)\n","y = linear_layer(x)\n","print(y)"]},{"cell_type":"markdown","metadata":{"id":"dFVr4Zu2nIUS"},"source":["가중치 `w`와 `b`는 레이어 속성으로 설정되면, 레이어에서 자동으로 추적됩니다."]},{"cell_type":"code","execution_count":7,"metadata":{"id":"jWO-UPabnIUS","executionInfo":{"status":"ok","timestamp":1726923275388,"user_tz":-540,"elapsed":5,"user":{"displayName":"Tae Kyu Lee","userId":"00886399863979660459"}}},"outputs":[],"source":["assert linear_layer.weights == [linear_layer.w, linear_layer.b]"]},{"cell_type":"markdown","source":["## 레이어에는 트레이닝 불가능한 가중치가 있을 수 있습니다."],"metadata":{"id":"w9gkOaDNphfH"}},{"cell_type":"markdown","source":["트레이닝 가능한 가중치 외에도, 레이어에 트레이닝 불가능한 가중치를 추가할 수 있습니다.\n","이러한 가중치는, 레이어를 트레이닝할 때, 역전파 중에 고려되지 않아야 합니다.\n","\n","트레이닝 불가능한 가중치를 추가하고 사용하는 방법은 다음과 같습니다."],"metadata":{"id":"osTy4B-QpjQx"}},{"cell_type":"code","execution_count":8,"metadata":{"id":"ma4BSXDQnIUT","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1726923299142,"user_tz":-540,"elapsed":113,"user":{"displayName":"Tae Kyu Lee","userId":"00886399863979660459"}},"outputId":"872970c3-33c4-48f1-eecd-54ea8607948f"},"outputs":[{"output_type":"stream","name":"stdout","text":["[2. 2.]\n","[4. 4.]\n"]}],"source":["class ComputeSum(keras.layers.Layer):\n","    def __init__(self, input_dim):\n","        super().__init__()\n","        self.total = self.add_weight(\n","            initializer=\"zeros\", shape=(input_dim,), trainable=False\n","        )\n","\n","    def call(self, inputs):\n","        self.total.assign_add(ops.sum(inputs, axis=0))\n","        return self.total\n","\n","\n","x = ops.ones((2, 2))\n","my_sum = ComputeSum(2)\n","y = my_sum(x)\n","print(y.numpy())\n","y = my_sum(x)\n","print(y.numpy())"]},{"cell_type":"markdown","metadata":{"id":"QIvO-OjDnIUT"},"source":["이는 `layer.weights`의 일부이지만, 트레이닝 불가능한 가중치로 분류됩니다."]},{"cell_type":"code","execution_count":9,"metadata":{"id":"bmwQ3vefnIUT","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1726923312197,"user_tz":-540,"elapsed":9,"user":{"displayName":"Tae Kyu Lee","userId":"00886399863979660459"}},"outputId":"9ff25c18-654b-4ca1-8b84-3c576e0a3346"},"outputs":[{"output_type":"stream","name":"stdout","text":["weights: 1\n","non-trainable weights: 1\n","trainable_weights: []\n"]}],"source":["print(\"weights:\", len(my_sum.weights))\n","print(\"non-trainable weights:\", len(my_sum.non_trainable_weights))\n","\n","# 트레이닝 가능한 가중치에 포함되지 않습니다.\n","print(\"trainable_weights:\", my_sum.trainable_weights)"]},{"cell_type":"markdown","source":["## 모범 사례: 입력 모양이 알려질 때까지, 가중치 생성을 연기합니다."],"metadata":{"id":"rqT4wXicpqyB"}},{"cell_type":"markdown","source":["위의 `Linear` 레이어는, `__init__()`에서 가중치 `w`와 `b`의 모양을 계산하는 데 사용된,\n","`input_dim` 인수를 사용했습니다."],"metadata":{"id":"ojKyQTikpsUN"}},{"cell_type":"code","execution_count":10,"metadata":{"id":"e-Iu9NyGnIUT","executionInfo":{"status":"ok","timestamp":1726923336810,"user_tz":-540,"elapsed":3,"user":{"displayName":"Tae Kyu Lee","userId":"00886399863979660459"}}},"outputs":[],"source":["class Linear(keras.layers.Layer):\n","    def __init__(self, units=32, input_dim=32):\n","        super().__init__()\n","        self.w = self.add_weight(\n","            shape=(input_dim, units),\n","            initializer=\"random_normal\",\n","            trainable=True,\n","        )\n","        self.b = self.add_weight(shape=(units,), initializer=\"zeros\", trainable=True)\n","\n","    def call(self, inputs):\n","        return ops.matmul(inputs, self.w) + self.b"]},{"cell_type":"markdown","metadata":{"id":"gzFxO0hFnIUT"},"source":["많은 경우, 입력 크기를 미리 알 수 없으며,\n","레이어를 인스턴스화한 얼마간 이후, 해당 값이 알려질 때,\n","지연하여(lazily) 가중치를 생성하고 싶을 것입니다.\n","\n","Keras API에서, 레이어의 `build(self, inputs_shape)` 메서드에서 레이어 가중치를 생성하는 것이 좋습니다.\n","다음과 같습니다."]},{"cell_type":"code","execution_count":11,"metadata":{"id":"L8Fpfhk9nIUT","executionInfo":{"status":"ok","timestamp":1726923349130,"user_tz":-540,"elapsed":12,"user":{"displayName":"Tae Kyu Lee","userId":"00886399863979660459"}}},"outputs":[],"source":["class Linear(keras.layers.Layer):\n","    def __init__(self, units=32):\n","        super().__init__()\n","        self.units = units\n","\n","    def build(self, input_shape):\n","        self.w = self.add_weight(\n","            shape=(input_shape[-1], self.units),\n","            initializer=\"random_normal\",\n","            trainable=True,\n","        )\n","        self.b = self.add_weight(\n","            shape=(self.units,), initializer=\"random_normal\", trainable=True\n","        )\n","\n","    def call(self, inputs):\n","        return ops.matmul(inputs, self.w) + self.b"]},{"cell_type":"markdown","metadata":{"id":"3IHtZ846nIUU"},"source":["레이어의 `__call__()` 메서드는 처음 호출될 때 자동으로 build를 실행합니다.\n","이제 지연되고(lazy), 사용하기 쉬운 레이어가 생겼습니다."]},{"cell_type":"code","execution_count":12,"metadata":{"id":"l7CZycZCnIUU","executionInfo":{"status":"ok","timestamp":1726923360955,"user_tz":-540,"elapsed":344,"user":{"displayName":"Tae Kyu Lee","userId":"00886399863979660459"}}},"outputs":[],"source":["# 인스턴스화 시, 이것이 어떤 입력에 대해 호출될지 알 수 없습니다.\n","linear_layer = Linear(32)\n","\n","# 레이어의 가중치는 레이어가 처음 호출될 때 동적으로 생성됩니다.\n","y = linear_layer(x)"]},{"cell_type":"markdown","metadata":{"id":"1c0uGby0nIUU"},"source":["위에 표시된 것처럼 `build()`를 별도로 구현하면,\n","가중치를 한 번만 생성하는 것과,\n","모든 호출에서 가중치를 사용하는 것을 깔끔하게 분리할 수 있습니다."]},{"cell_type":"markdown","source":["## 레이어는 재귀적으로 구성 가능합니다."],"metadata":{"id":"3lpdF8Pxp3xm"}},{"cell_type":"markdown","source":["Layer 인스턴스를 다른 Layer의 속성으로 할당하면,\n","외부 레이어는 내부 레이어에서 생성된 가중치를 추적하기 시작합니다.\n","\n","`__init__()` 메서드에서 이러한 하위 레이어를 생성하고,\n","첫 번째 `__call__()`에서 가중치를 빌드하도록 트리거하는 것이 좋습니다."],"metadata":{"id":"8pskP8jcp5Sa"}},{"cell_type":"code","execution_count":13,"metadata":{"id":"xG_WM7PznIUU","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1726923388512,"user_tz":-540,"elapsed":696,"user":{"displayName":"Tae Kyu Lee","userId":"00886399863979660459"}},"outputId":"ae529f0c-b905-4de5-8a7c-8b7343622e3d"},"outputs":[{"output_type":"stream","name":"stdout","text":["weights: 6\n","trainable weights: 6\n"]}],"source":["class MLPBlock(keras.layers.Layer):\n","    def __init__(self):\n","        super().__init__()\n","        self.linear_1 = Linear(32)\n","        self.linear_2 = Linear(32)\n","        self.linear_3 = Linear(1)\n","\n","    def call(self, inputs):\n","        x = self.linear_1(inputs)\n","        x = keras.activations.relu(x)\n","        x = self.linear_2(x)\n","        x = keras.activations.relu(x)\n","        return self.linear_3(x)\n","\n","\n","mlp = MLPBlock()\n","y = mlp(ops.ones(shape=(3, 64)))  # `mlp`에 대한 첫 번째 호출은 가중치를 생성합니다.\n","print(\"weights:\", len(mlp.weights))\n","print(\"trainable weights:\", len(mlp.trainable_weights))"]},{"cell_type":"markdown","source":["## 백엔드에 독립적인 레이어와 백엔드에 특화된 레이어"],"metadata":{"id":"A5QFHiSbp9kj"}},{"cell_type":"markdown","metadata":{"id":"Fo6Sh59anIUU"},"source":["레이어가 `keras.ops` 네임스페이스(또는 `keras.activations`, `keras.random` 또는 `keras.layers`와 같은 그 외 Keras 네임스페이스)의 API만 사용하는 한,\n","TensorFlow, JAX 또는 PyTorch와 같은 모든 백엔드에서 사용할 수 있습니다.\n","\n","이 가이드에서 지금까지 본 모든 레이어는 모든 Keras 백엔드에서 작동합니다.\n","\n","`keras.ops` 네임스페이스는 다음에 대한 액세스를 제공합니다.\n","\n","* NumPy API, 예: `ops.matmul`, `ops.sum`, `ops.reshape`, `ops.stack` 등\n","* `ops.softmax`, `ops.conv`, `ops.binary_crossentropy`, `ops.relu` 등과 같은 신경망 전용 API\n","\n","레이어에서 백엔드 네이티브 API(예: [`tf.nn`](https://www.tensorflow.org/api_docs/python/tf/nn) 함수)를 사용할 수도 있지만,\n","이렇게 하면 레이어는 해당 백엔드에서만 사용할 수 있습니다.\n","예를 들어, `jax.numpy`를 사용하여 다음과 같은 JAX 전용 레이어를 작성할 수 있습니다.\n","\n","```python\n","import jax\n","\n","class Linear(keras.layers.Layer):\n","    ...\n","\n","    def call(self, inputs):\n","        return jax.numpy.matmul(inputs, self.w) + self.b\n","```\n","\n","이것은 동등한 TensorFlow 전용 레이어 입니다.\n","\n","```python\n","\n","import tensorflow as tf\n","\n","class Linear(keras.layers.Layer):\n","    ...\n","\n","    def call(self, inputs):\n","        return tf.matmul(inputs, self.w) + self.b\n","```\n","\n","그리고 이것은 동등한 PyTorch 전용 레이어 입니다:\n","\n","```python\n","import torch\n","\n","class Linear(keras.layers.Layer):\n","    ...\n","\n","    def call(self, inputs):\n","        return torch.matmul(inputs, self.w) + self.b\n","```\n","\n","크로스 백엔드 호환성은 매우 유용한 속성이므로,\n","Keras API만 활용하여 레이어를 항상 백엔드에 독립적으로 만드는 것이 좋습니다."]},{"cell_type":"markdown","source":["## `add_loss()` 메서드"],"metadata":{"id":"NTdnrvejqF41"}},{"cell_type":"markdown","source":["레이어의 `call()` 메서드를 작성할 때,\n","나중에 트레이닝 루프를 작성할 때,\n","사용하고 싶은 손실 텐서를 만들 수 있습니다.\n","`self.add_loss(value)`를 호출하면 가능합니다."],"metadata":{"id":"yzG3iliQqG_I"}},{"cell_type":"code","execution_count":14,"metadata":{"id":"3SOWxVXKnIUU","executionInfo":{"status":"ok","timestamp":1726923443759,"user_tz":-540,"elapsed":38,"user":{"displayName":"Tae Kyu Lee","userId":"00886399863979660459"}}},"outputs":[],"source":["# 활동 정규화 손실(activity regularization loss)을 생성하는 레이어\n","class ActivityRegularizationLayer(keras.layers.Layer):\n","    def __init__(self, rate=1e-2):\n","        super().__init__()\n","        self.rate = rate\n","\n","    def call(self, inputs):\n","        self.add_loss(self.rate * ops.mean(inputs))\n","        return inputs"]},{"cell_type":"markdown","metadata":{"id":"AjzkRfmvnIUU"},"source":["이러한 손실(내부 레이어에서 생성된 손실 포함)은 `layer.losses`를 통해 검색할 수 있습니다.\n","이 속성은 최상위 레이어에 대한 모든 `__call__()` 시작 시 재설정되므로,\n","`layer.losses`는 항상 마지막 전방 패스 중에 생성된 손실 값을 포함합니다."]},{"cell_type":"code","execution_count":16,"metadata":{"id":"wsbi5u1mnIUU","executionInfo":{"status":"ok","timestamp":1726923475209,"user_tz":-540,"elapsed":22,"user":{"displayName":"Tae Kyu Lee","userId":"00886399863979660459"}}},"outputs":[],"source":["class OuterLayer(keras.layers.Layer):\n","    def __init__(self):\n","        super().__init__()\n","        self.activity_reg = ActivityRegularizationLayer(1e-2)\n","\n","    def call(self, inputs):\n","        return self.activity_reg(inputs)\n","\n","\n","layer = OuterLayer()\n","assert len(layer.losses) == 0  # 레이어가 호출된 적이 없으므로 아직 손실이 없습니다.\n","\n","_ = layer(ops.zeros((1, 1)))\n","assert len(layer.losses) == 1  # 우리는 하나의 손실 값을 생성했습니다\n","\n","# `layer.losses`는 각 __call__ 시작 시 재설정됩니다.\n","_ = layer(ops.zeros((1, 1)))\n","assert len(layer.losses) == 1  # 이는 위의 호출 중에 발생한 손실입니다."]},{"cell_type":"markdown","metadata":{"id":"fsC-iGPinIUU"},"source":["또한, `loss` 속성에는 내부 레이어의 가중치에 대해 생성된 정규화 손실도 포함됩니다."]},{"cell_type":"code","execution_count":17,"metadata":{"id":"rCs-5SHgnIUU","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1726923476478,"user_tz":-540,"elapsed":196,"user":{"displayName":"Tae Kyu Lee","userId":"00886399863979660459"}},"outputId":"424d6bb9-968b-4319-94b6-fb90c5350c4d"},"outputs":[{"output_type":"stream","name":"stdout","text":["[Array(0.00175959, dtype=float32)]\n"]}],"source":["class OuterLayerWithKernelRegularizer(keras.layers.Layer):\n","    def __init__(self):\n","        super().__init__()\n","        self.dense = keras.layers.Dense(\n","            32, kernel_regularizer=keras.regularizers.l2(1e-3)\n","        )\n","\n","    def call(self, inputs):\n","        return self.dense(inputs)\n","\n","\n","layer = OuterLayerWithKernelRegularizer()\n","_ = layer(ops.zeros((1, 1)))\n","\n","# 이는 위의 `kernel_regularizer`에 의해 생성된, `1e-3 * sum(layer.dense.kernel ** 2)`입니다.\n","print(layer.losses)"]},{"cell_type":"markdown","metadata":{"id":"ae_H7ekbnIUV"},"source":["이러한 손실은 커스텀 트레이닝 루프를 작성할 때 고려해야 합니다.\n","\n","또한 `fit()`와 원활하게 작동합니다. (있는 경우, 자동으로 합산되어 메인 손실에 추가됩니다.):\n"]},{"cell_type":"code","execution_count":18,"metadata":{"id":"mP0uAECrnIUV","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1726923494800,"user_tz":-540,"elapsed":343,"user":{"displayName":"Tae Kyu Lee","userId":"00886399863979660459"}},"outputId":"739630fe-024b-4e4b-ddd8-abdc11136f15"},"outputs":[{"output_type":"stream","name":"stdout","text":["\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 149ms/step - loss: 0.1324\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - loss: 0.0057\n"]},{"output_type":"execute_result","data":{"text/plain":["<keras.src.callbacks.history.History at 0x7616d0121180>"]},"metadata":{},"execution_count":18}],"source":["inputs = keras.Input(shape=(3,))\n","outputs = ActivityRegularizationLayer()(inputs)\n","model = keras.Model(inputs, outputs)\n","\n","# `compile`에 손실이 전달된 손실이 있으면, 정규화 손실에 합산되어 추가됩니다.\n","model.compile(optimizer=\"adam\", loss=\"mse\")\n","model.fit(np.random.random((2, 3)), np.random.random((2, 3)))\n","\n","# 모델에는 이미 최소화해야 할 손실이 있으므로,\n","# 전방 전달(forward pass) 중 `add_loss` 호출을 통해,\n","# `compile`에서 아무런 손실도 전달하지 않는 것도 가능합니다!\n","model.compile(optimizer=\"adam\")\n","model.fit(np.random.random((2, 3)), np.random.random((2, 3)))"]},{"cell_type":"markdown","source":["## 선택적으로 레이어에서 직렬화를 활성화할 수 있습니다"],"metadata":{"id":"TsG3GtLZqYuy"}},{"cell_type":"markdown","source":["커스텀 레이어를 [함수형 모델](https://codecompose7.github.io/keras-doc-kr.github.io/guides/functional_api/)의 일부로 직렬화할 필요가 있는 경우,\n","선택적으로 `get_config()` 메서드를 구현할 수 있습니다."],"metadata":{"id":"nqmrheqrqZ5L"}},{"cell_type":"code","execution_count":19,"metadata":{"id":"eA740THcnIUV","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1726923541569,"user_tz":-540,"elapsed":3,"user":{"displayName":"Tae Kyu Lee","userId":"00886399863979660459"}},"outputId":"6701e91a-ad80-4df4-9a4c-943198619465"},"outputs":[{"output_type":"stream","name":"stdout","text":["{'units': 64}\n"]}],"source":["class Linear(keras.layers.Layer):\n","    def __init__(self, units=32):\n","        super().__init__()\n","        self.units = units\n","\n","    def build(self, input_shape):\n","        self.w = self.add_weight(\n","            shape=(input_shape[-1], self.units),\n","            initializer=\"random_normal\",\n","            trainable=True,\n","        )\n","        self.b = self.add_weight(\n","            shape=(self.units,), initializer=\"random_normal\", trainable=True\n","        )\n","\n","    def call(self, inputs):\n","        return ops.matmul(inputs, self.w) + self.b\n","\n","    def get_config(self):\n","        return {\"units\": self.units}\n","\n","\n","# 이제 config에서 레이어를 다시 생성할 수 있습니다.\n","layer = Linear(64)\n","config = layer.get_config()\n","print(config)\n","new_layer = Linear.from_config(config)"]},{"cell_type":"markdown","metadata":{"id":"S_iGxeq5nIUV"},"source":["베이스 `Layer` 클래스의 `__init__()` 메서드는 일부 키워드 인수, 특히 `name`과 `dtype`을 취합니다.\n","이러한 인수를 `__init__()`에서 부모 클래스에 전달하고, 레이어 config에 포함하는 것이 좋습니다."]},{"cell_type":"code","execution_count":20,"metadata":{"id":"s9h2TIxKnIUV","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1726923557794,"user_tz":-540,"elapsed":1015,"user":{"displayName":"Tae Kyu Lee","userId":"00886399863979660459"}},"outputId":"4fba64dc-6874-40d0-8bd3-3499d732b56d"},"outputs":[{"output_type":"stream","name":"stdout","text":["{'name': 'linear_7', 'trainable': True, 'dtype': {'module': 'keras', 'class_name': 'DTypePolicy', 'config': {'name': 'float32'}, 'registered_name': None}, 'units': 64}\n"]}],"source":["class Linear(keras.layers.Layer):\n","    def __init__(self, units=32, **kwargs):\n","        super().__init__(**kwargs)\n","        self.units = units\n","\n","    def build(self, input_shape):\n","        self.w = self.add_weight(\n","            shape=(input_shape[-1], self.units),\n","            initializer=\"random_normal\",\n","            trainable=True,\n","        )\n","        self.b = self.add_weight(\n","            shape=(self.units,), initializer=\"random_normal\", trainable=True\n","        )\n","\n","    def call(self, inputs):\n","        return ops.matmul(inputs, self.w) + self.b\n","\n","    def get_config(self):\n","        config = super().get_config()\n","        config.update({\"units\": self.units})\n","        return config\n","\n","\n","layer = Linear(64)\n","config = layer.get_config()\n","print(config)\n","new_layer = Linear.from_config(config)"]},{"cell_type":"markdown","metadata":{"id":"EIrH2hp8nIUV"},"source":["레이어를 config에서 역직렬화할 때 더 많은 유연성이 필요한 경우,\n","`from_config()` 클래스 메서드를 재정의할 수도 있습니다.\n","이것은 `from_config()`의 베이스 구현입니다.\n","\n","```python\n","def from_config(cls, config):\n","    return cls(**config)\n","```\n","\n","직렬화 및 저장에 대해 자세히 알아보려면,\n","[모델 저장 및 직렬화 가이드](https://codecompose7.github.io/keras-doc-kr.github.io/guides/serialization_and_saving/)를 참조하세요."]},{"cell_type":"markdown","source":["## `call()` 메서드의 특권(Privileged) `training` 인수"],"metadata":{"id":"gW-kulnYqt1r"}},{"cell_type":"markdown","source":["일부 레이어, 특히 `BatchNormalization` 레이어와 `Dropout` 레이어는,\n","트레이닝 및 추론 중에 서로 다른 동작을 합니다.\n","이러한 레이어의 경우, `call()` 메서드에서 `training`(boolean) 인수를 노출하는 것이 표준 관행입니다.\n","\n","`call()`에서 이 인수를 노출하면, 빌트인 트레이닝 및 평가 루프(예: `fit()`)가,\n","트레이닝 및 추론에서 레이어를 올바르게 사용할 수 있습니다."],"metadata":{"id":"-H_tb6hZqvhP"}},{"cell_type":"code","execution_count":21,"metadata":{"id":"VXIX1vIFnIUV","executionInfo":{"status":"ok","timestamp":1726923611722,"user_tz":-540,"elapsed":9,"user":{"displayName":"Tae Kyu Lee","userId":"00886399863979660459"}}},"outputs":[],"source":["class CustomDropout(keras.layers.Layer):\n","    def __init__(self, rate, **kwargs):\n","        super().__init__(**kwargs)\n","        self.rate = rate\n","        self.seed_generator = keras.random.SeedGenerator(1337)\n","\n","    def call(self, inputs, training=None):\n","        if training:\n","            return keras.random.dropout(\n","                inputs, rate=self.rate, seed=self.seed_generator\n","            )\n","        return inputs"]},{"cell_type":"markdown","source":["## `call()` 메서드의 특권 `mask` 인수"],"metadata":{"id":"foAjaFwZqzs7"}},{"cell_type":"markdown","source":["`call()`에서 지원하는 다른 특권 인수는 `mask` 인수입니다.\n","\n","모든 Keras RNN 레이어에서 찾을 수 있습니다.\n","마스크는 boolean 텐서(입력의 타임스텝당 하나의 boolean 값)로,\n","시계열 데이터를 처리할 때 특정 입력 타임스텝을 건너뛰는 데 사용됩니다.\n","\n","Keras는, 이전 레이어에서 마스크가 생성될 때,\n","이를 지원하는 레이어에 대해 올바른 `mask` 인수를 `__call__()`에 자동으로 전달합니다.\n","마스크를 생성하는 레이어는 `mask_zero=True`로 구성된 `Embedding` 레이어와 `Masking` 레이어입니다."],"metadata":{"id":"U-NJZnxrq1LX"}},{"cell_type":"markdown","source":["## `Model` 클래스"],"metadata":{"id":"iOW-eNfUq4Lo"}},{"cell_type":"markdown","source":["일반적으로, `Layer` 클래스를 사용하여 내부 계산 블록을 정의하고,\n","`Model` 클래스를 사용하여 외부 모델(트레이닝할 객체)을 정의합니다.\n","\n","예를 들어, ResNet50 모델에서는, `Layer`를 하위 클래스화하는 여러 ResNet 블록과,\n","전체 ResNet50 네트워크를 포괄하는 단일 `Model`이 있습니다.\n","\n","`Model` 클래스는 `Layer`와 동일한 API를 사용하지만, 다음과 같은 차이점이 있습니다.\n","\n","* 빌트인 트레이닝, 평가 및 예측 루프(`model.fit()`, `model.evaluate()`, `model.predict()`)를 노출합니다.\n","* `model.layers` 속성을 통해, 내부 레이어 리스트를 노출합니다.\n","* 저장 및 직렬화 API(`save()`, `save_weights()`...)를 노출합니다.\n","\n","실제로, `Layer` 클래스는 문헌에서 \"레이어\"(예: \"컨볼루션 레이어\" 또는 \"recurrent 레이어\") 또는 \"블록\"(예: \"ResNet 블록\" 또는 \"Inception 블록\")이라고 하는 것과 일치합니다.\n","\n","한편, `Model` 클래스는 문헌에서 \"모델\"(예: \"딥러닝 모델\") 또는 \"네트워크\"(예: \"딥 신경망(신경 네트워크)\")라고 하는 것에 해당합니다.\n","\n","따라서, \"`Layer` 클래스나 `Model` 클래스를 사용해야 할까?\"라는 것이 궁금하다면 스스로에게 물어보세요.\n","`fit()`를 호출해야 할까요? `save()`를 호출해야 할까요? 그렇다면 `Model`을 사용하세요.\n","그렇지 않다면(클래스가 더 큰 시스템의 블록이거나 직접 트레이닝 및 저장 코드를 작성하고 있기 때문) `Layer`를 사용하세요.\n","\n","예를 들어, 위의 미니 resnet 예제를 가져와, `fit()`로 트레이닝하고,\n","`save_weights()`로 저장할 수 있는 `Model`을 빌드할 수 있습니다."],"metadata":{"id":"sOg_iLa_q6Jp"}},{"cell_type":"markdown","metadata":{"id":"1vLzpC9wnIUa"},"source":["```python\n","class ResNet(keras.Model):\n","\n","    def __init__(self, num_classes=1000):\n","        super().__init__()\n","        self.block_1 = ResNetBlock()\n","        self.block_2 = ResNetBlock()\n","        self.global_pool = layers.GlobalAveragePooling2D()\n","        self.classifier = Dense(num_classes)\n","\n","    def call(self, inputs):\n","        x = self.block_1(inputs)\n","        x = self.block_2(x)\n","        x = self.global_pool(x)\n","        return self.classifier(x)\n","\n","\n","resnet = ResNet()\n","dataset = ...\n","resnet.fit(dataset, epochs=10)\n","resnet.save(filepath.keras)\n","```"]},{"cell_type":"markdown","source":["## 모두 합치기: 종단간 예시"],"metadata":{"id":"Lr0QXAhVrAQ4"}},{"cell_type":"markdown","source":["지금까지 배운 내용은 다음과 같습니다.\n","\n","* `Layer`는 상태(`__init__()` 또는 `build()`에서 생성)와 일부 계산(`call()`에서 정의)을 캡슐화합니다.\n","* 레이어는 재귀적으로 중첩되어, 새롭고 더 큰 계산 블록을 만들 수 있습니다.\n","* 레이어는 Keras API만 사용하는 한 백엔드에 구애받지 않습니다.\n","  백엔드 네이티브 API(예: `jax.numpy`, `torch.nn` 또는 [`tf.nn`](https://www.tensorflow.org/api_docs/python/tf/nn))를 사용할 수 있지만, 그러면 레이어는 해당 특정 백엔드에서만 사용할 수 있습니다.\n","* 레이어는 `add_loss()`를 통해 손실(일반적으로 정규화 손실)을 생성하고 추적할 수 있습니다.\n","* 외부 컨테이너, 즉 트레이닝하려는 것은 `Model`입니다.\n","  `Model`은 `Layer`와 같지만 트레이닝 및 직렬화 유틸리티가 추가되었습니다.\n","\n","이 모든 것을 엔드투엔드 예제로 모아 보겠습니다.\n","백엔드에 독립적인 방식으로 Variational AutoEncoder(VAE)를 구현하여,\n","TensorFlow, JAX, PyTorch에서 동일하게 실행되도록 하겠습니다.\n","MNIST 숫자로 트레이닝합니다.\n","\n","VAE는 `Model`의 하위 클래스이며,\n","`Layer`를 하위 클래스화하는 레이어의 중첩된 구성으로 구축됩니다.\n","정규화 손실(KL 발산)이 특징입니다."],"metadata":{"id":"yGsfcuZwrCXt"}},{"cell_type":"code","execution_count":22,"metadata":{"id":"AaMo1HkCnIUa","executionInfo":{"status":"ok","timestamp":1726923693232,"user_tz":-540,"elapsed":44,"user":{"displayName":"Tae Kyu Lee","userId":"00886399863979660459"}}},"outputs":[],"source":["class Sampling(layers.Layer):\n","    \"\"\"(z_mean, z_log_var)를 사용하여 숫자를 인코딩하는 벡터 z를 샘플링합니다.\"\"\"\n","\n","    def __init__(self, **kwargs):\n","        super().__init__(**kwargs)\n","        self.seed_generator = keras.random.SeedGenerator(1337)\n","\n","    def call(self, inputs):\n","        z_mean, z_log_var = inputs\n","        batch = ops.shape(z_mean)[0]\n","        dim = ops.shape(z_mean)[1]\n","        epsilon = keras.random.normal(shape=(batch, dim), seed=self.seed_generator)\n","        return z_mean + ops.exp(0.5 * z_log_var) * epsilon\n","\n","\n","class Encoder(layers.Layer):\n","    \"\"\"MNIST 숫자를 삼중항(z_mean, z_log_var, z)으로 매핑합니다.\"\"\"\n","\n","    def __init__(self, latent_dim=32, intermediate_dim=64, name=\"encoder\", **kwargs):\n","        super().__init__(name=name, **kwargs)\n","        self.dense_proj = layers.Dense(intermediate_dim, activation=\"relu\")\n","        self.dense_mean = layers.Dense(latent_dim)\n","        self.dense_log_var = layers.Dense(latent_dim)\n","        self.sampling = Sampling()\n","\n","    def call(self, inputs):\n","        x = self.dense_proj(inputs)\n","        z_mean = self.dense_mean(x)\n","        z_log_var = self.dense_log_var(x)\n","        z = self.sampling((z_mean, z_log_var))\n","        return z_mean, z_log_var, z\n","\n","\n","class Decoder(layers.Layer):\n","    \"\"\"인코딩된 숫자 벡터 z를 다시 읽을 수 있는 숫자로 변환합니다.\"\"\"\n","\n","    def __init__(self, original_dim, intermediate_dim=64, name=\"decoder\", **kwargs):\n","        super().__init__(name=name, **kwargs)\n","        self.dense_proj = layers.Dense(intermediate_dim, activation=\"relu\")\n","        self.dense_output = layers.Dense(original_dim, activation=\"sigmoid\")\n","\n","    def call(self, inputs):\n","        x = self.dense_proj(inputs)\n","        return self.dense_output(x)\n","\n","\n","class VariationalAutoEncoder(keras.Model):\n","    \"\"\"인코더와 디코더를 엔드투엔드 모델로 결합하여 트레이닝을 수행합니다.\"\"\"\n","\n","    def __init__(\n","        self,\n","        original_dim,\n","        intermediate_dim=64,\n","        latent_dim=32,\n","        name=\"autoencoder\",\n","        **kwargs\n","    ):\n","        super().__init__(name=name, **kwargs)\n","        self.original_dim = original_dim\n","        self.encoder = Encoder(latent_dim=latent_dim, intermediate_dim=intermediate_dim)\n","        self.decoder = Decoder(original_dim, intermediate_dim=intermediate_dim)\n","\n","    def call(self, inputs):\n","        z_mean, z_log_var, z = self.encoder(inputs)\n","        reconstructed = self.decoder(z)\n","        # KL 발산 정규화 손실을 추가합니다.\n","        kl_loss = -0.5 * ops.mean(\n","            z_log_var - ops.square(z_mean) - ops.exp(z_log_var) + 1\n","        )\n","        self.add_loss(kl_loss)\n","        return reconstructed"]},{"cell_type":"markdown","metadata":{"id":"x0VZiJFZnIUa"},"source":["`fit()` API를 사용하여 MNIST에 대해 트레이닝해 보겠습니다."]},{"cell_type":"code","execution_count":23,"metadata":{"id":"KcU3LYmMnIUa","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1726923713674,"user_tz":-540,"elapsed":5437,"user":{"displayName":"Tae Kyu Lee","userId":"00886399863979660459"}},"outputId":"404dc49c-995e-47de-94fd-a39cc9f19bf8"},"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/2\n","\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - loss: 0.0947\n","Epoch 2/2\n","\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 510us/step - loss: 0.0677\n"]},{"output_type":"execute_result","data":{"text/plain":["<keras.src.callbacks.history.History at 0x76169cbf1d20>"]},"metadata":{},"execution_count":23}],"source":["(x_train, _), _ = keras.datasets.mnist.load_data()\n","x_train = x_train.reshape(60000, 784).astype(\"float32\") / 255\n","\n","original_dim = 784\n","vae = VariationalAutoEncoder(784, 64, 32)\n","\n","optimizer = keras.optimizers.Adam(learning_rate=1e-3)\n","vae.compile(optimizer, loss=keras.losses.MeanSquaredError())\n","\n","vae.fit(x_train, x_train, epochs=2, batch_size=64)"]},{"cell_type":"code","source":[],"metadata":{"id":"x3StdDezrJaQ"},"execution_count":null,"outputs":[]}],"metadata":{"accelerator":"None","colab":{"provenance":[{"file_id":"https://github.com/keras-team/keras-io/blob/master/guides/ipynb/making_new_layers_and_models_via_subclassing.ipynb","timestamp":1726922656744}],"toc_visible":true},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.0"}},"nbformat":4,"nbformat_minor":0}