{"cells":[{"cell_type":"markdown","source":["# PyTorch에서 `fit()`의 동작을 커스터마이즈하기"],"metadata":{"id":"K8nWA_Q31WoA"}},{"cell_type":"markdown","source":["**저자:** [fchollet](https://twitter.com/fchollet)  \n","**생성일:** 2023/06/27  \n","**최종편집일:** 2024/08/01  \n","**설명:** PyTorch의 Model 클래스에서 트레이닝 스텝 오버라이딩하기"],"metadata":{"id":"Rcg8RyON1YXP"}},{"cell_type":"markdown","source":["## 소개"],"metadata":{"id":"V2sZZi7S1aC5"}},{"cell_type":"markdown","source":["지도 학습을 할 때, `fit()`을 사용하면 모든 것이 원활하게 작동합니다.\n","\n","모든 작은 부분까지 제어해야 할 때는,\n","처음부터 완전히 직접 트레이닝 루프를 작성할 수 있습니다.\n","\n","하지만 커스텀 트레이닝 알고리즘이 필요하지만,\n","콜백, 빌트인 분산 지원, 또는 스텝 퓨징(step fusing)과 같은,\n","`fit()`의 편리한 기능을 여전히 활용하고 싶다면 어떻게 해야 할까요?\n","\n","Keras의 핵심 원칙 중 하나는 **복잡성의 점진적 공개**입니다.\n","낮은 레벨의 워크플로우로 점진적으로 진입할 수 있어야 합니다.\n","높은 레벨의 기능이 정확히 당신의 사용 사례와 맞지 않더라도, 갑자기 막히지 않아야 합니다.\n","높은 레벨의 편의성을 유지하면서도 작은 세부사항에 대한 더 많은 제어를 얻을 수 있어야 합니다.\n","\n","`fit()`이 수행하는 작업을 커스터마이즈해야 할 때는,\n","**`Model` 클래스의 트레이닝 스텝 함수를 오버라이드**해야 합니다.\n","이 함수는 `fit()`이 각 데이터 배치마다 호출하는 함수입니다.\n","그러면 평소처럼 `fit()`을 호출할 수 있고, 여러분의 학습 알고리즘이 실행될 것입니다.\n","\n","이 패턴은 Functional API로 모델을 구축하는 것을 방해하지 않는다는 점에 유의하세요.\n","`Sequential` 모델이든, Functional API 모델이든, 서브클래싱된 모델이든,\n","이 작업을 수행할 수 있습니다.\n","\n","이것이 어떻게 작동하는지 살펴보겠습니다."],"metadata":{"id":"wTykJMeB1b13"}},{"cell_type":"markdown","metadata":{"id":"n2j9Jysa1J_8"},"source":["## 셋업"]},{"cell_type":"code","execution_count":1,"metadata":{"id":"wyRr1laT1J_8","executionInfo":{"status":"ok","timestamp":1726959991074,"user_tz":-540,"elapsed":2034,"user":{"displayName":"Tae Kyu Lee","userId":"00886399863979660459"}}},"outputs":[],"source":["import os\n","\n","# 이 가이드는 torch 백엔드에서만 실행할 수 있습니다.\n","os.environ[\"KERAS_BACKEND\"] = \"torch\"\n","\n","import torch\n","import keras\n","from keras import layers\n","import numpy as np"]},{"cell_type":"code","source":["from keras import backend\n","print(backend.backend())"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"pLvlObxo1hqY","executionInfo":{"status":"ok","timestamp":1726959991081,"user_tz":-540,"elapsed":4,"user":{"displayName":"Tae Kyu Lee","userId":"00886399863979660459"}},"outputId":"6ef1df51-5d2d-4ffe-9d95-ee6f0a7827d0"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["torch\n"]}]},{"cell_type":"markdown","source":["## 첫 번째 간단한 예제"],"metadata":{"id":"-BV4_0911kqZ"}},{"cell_type":"markdown","source":["간단한 예제부터 시작해봅시다:\n","- [`keras.Model`](https://codecompose7.github.io/keras-doc-kr.github.io/api/models/model#model-class)를 서브클래싱하는 새로운 클래스를 생성합니다.\n","- 메서드 `train_step(self, data)`만 오버라이드합니다.\n","- 메트릭 이름(손실을 포함하여)을 현재 값에 매핑하는 딕셔너리를 반환합니다.\n","\n","입력 인자 `data`는 트레이닝 데이터로서 `fit`에 전달되는 것입니다:\n","\n","- `fit(x, y, ...)`를 호출하여 NumPy 배열을 전달하면,\n","  `data`는 튜플 `(x, y)`가 됩니다.\n","- `fit(dataset, ...)`를 호출하여 `torch.utils.data.DataLoader` 또는 [`tf.data.Dataset`](https://www.tensorflow.org/api_docs/python/tf/data/Dataset)를 전달하면,\n","  `data`는 각 배치마다 `dataset`에 의해 생성(yielded)되는 것입니다.\n","\n","`train_step()` 메서드의 본문에서, 여러분이 이미 익숙한 일반적인 트레이닝 업데이트를 구현합니다.\n","중요한 점은, **`self.compute_loss()`를 통해 손실을 계산한다는 것**인데,\n","이는 `compile()`에 전달된 손실 함수들을 감싸고 있습니다.\n","\n","마찬가지로, `self.metrics`로부터의 메트릭에 대해 `metric.update_state(y, y_pred)`를 호출하여,\n","`compile()`에 전달된 메트릭의 상태를 업데이트하고,\n","마지막에 `self.metrics`에서 결과를 조회하여 현재 값을 가져옵니다."],"metadata":{"id":"yJHbUskk1mKO"}},{"cell_type":"code","execution_count":3,"metadata":{"id":"F7jMh6wN1J_9","executionInfo":{"status":"ok","timestamp":1726960066619,"user_tz":-540,"elapsed":3,"user":{"displayName":"Tae Kyu Lee","userId":"00886399863979660459"}}},"outputs":[],"source":["class CustomModel(keras.Model):\n","    def train_step(self, data):\n","        # 데이터를 언패킹합니다.\n","        # 그 구조는 모델과 `fit()`에 전달한 것에 따라 달라집니다.\n","        x, y = data\n","\n","        # 이전 트레이닝 스텝에서 남은 가중치의 그래디언트를 지우기 위해\n","        # torch.nn.Module.zero_grad()를 호출합니다.\n","        self.zero_grad()\n","\n","        # 손실 계산\n","        y_pred = self(x, training=True)  # Forward pass\n","        loss = self.compute_loss(y=y, y_pred=y_pred)\n","\n","        # 손실에 대해 torch.Tensor.backward()를 호출하여\n","        # 가중치의 그래디언트를 계산합니다.\n","        loss.backward()\n","\n","        trainable_weights = [v for v in self.trainable_weights]\n","        gradients = [v.value.grad for v in trainable_weights]\n","\n","        # 가중치 업데이트\n","        with torch.no_grad():\n","            self.optimizer.apply(gradients, trainable_weights)\n","\n","        # 메트릭 업데이트 (손실을 추적하는 메트릭 포함)\n","        for metric in self.metrics:\n","            if metric.name == \"loss\":\n","                metric.update_state(loss)\n","            else:\n","                metric.update_state(y, y_pred)\n","\n","        # 메트릭 이름을 현재 값에 매핑하는 딕셔너리를 반환합니다.\n","        # 이는 손실을 포함한다는 점에 유의하세요. (self.metrics에서 추적됨)\n","        return {m.name: m.result() for m in self.metrics}"]},{"cell_type":"markdown","metadata":{"id":"6zbYKSuu1J_9"},"source":["이것을 시도해봅시다:"]},{"cell_type":"code","execution_count":4,"metadata":{"id":"3PoZZZnK1J_9","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1726960077589,"user_tz":-540,"elapsed":1039,"user":{"displayName":"Tae Kyu Lee","userId":"00886399863979660459"}},"outputId":"7ef1a690-3532-4bbc-c686-4999805b103d"},"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/3\n","\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - mae: 0.5994 - loss: 0.5441\n","Epoch 2/3\n","\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - mae: 0.4284 - loss: 0.2819\n","Epoch 3/3\n","\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - mae: 0.4147 - loss: 0.2627\n"]},{"output_type":"execute_result","data":{"text/plain":["<keras.src.callbacks.history.History at 0x7e0e6471b910>"]},"metadata":{},"execution_count":4}],"source":["# CustomModel의 인스턴스를 생성하고 컴파일합니다.\n","inputs = keras.Input(shape=(32,))\n","outputs = keras.layers.Dense(1)(inputs)\n","model = CustomModel(inputs, outputs)\n","model.compile(optimizer=\"adam\", loss=\"mse\", metrics=[\"mae\"])\n","\n","# 평소처럼 `fit`을 사용합니다.\n","x = np.random.random((1000, 32))\n","y = np.random.random((1000, 1))\n","model.fit(x, y, epochs=3)"]},{"cell_type":"markdown","source":["## 더 낮은 레벨로 내려가기"],"metadata":{"id":"YZfzTnRb16kW"}},{"cell_type":"markdown","source":["당연히, `compile()`에서 손실 함수를 전달하지 않고,\n","대신 `train_step`에서 모든 작업을 *수동으로* 처리할 수 있습니다.\n","메트릭도 마찬가지입니다.\n","\n","다음은 옵티마이저 설정만을 위해 `compile()`을 사용하는, 더 낮은 레벨의 예제입니다:\n","\n","- `__init__()`에서, 손실과 MAE 점수를 추적하기 위한 `Metric` 인스턴스를 만듭니다.\n","- 이 메트릭들의 상태를 (메트릭에 대해 `update_state()` 호출하여) 업데이트하는,\n","  커스텀 `train_step()`을 구현하고,\n","  그런 다음 진행률 표시줄에 표시하거나 콜백으로 전달하기 위해,\n","  현재 평균 값을 반환하도록 `result()`를 통해 조회합니다.\n","- 각 에포크 사이에 메트릭에 대해 `reset_states()`를 호출해야 한다는 점을 유의하세요!\n","  그렇지 않으면, `result()`를 호출하면 트레이닝 시작 이후의 평균이 반환되는데,\n","  우리는 일반적으로 에포크별 평균을 사용합니다.\n","  다행히도 프레임워크는 이를 자동으로 처리해줍니다:\n","  모델의 `metrics` 속성에 초기화하려는 메트릭을 나열하기만 하면 됩니다.\n","  모델은 각 `fit()` 에포크의 시작 시 또는 `evaluate()` 호출의 시작 시에,\n","  여기에 나열된 모든 객체에 대해 `reset_states()`를 호출합니다."],"metadata":{"id":"LlvPEt-W18GF"}},{"cell_type":"code","execution_count":5,"metadata":{"id":"9mZ9Ps3O1J_-","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1726960104649,"user_tz":-540,"elapsed":424,"user":{"displayName":"Tae Kyu Lee","userId":"00886399863979660459"}},"outputId":"8ccac5a2-c191-462e-9666-fd7c636f9d06"},"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/5\n","\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.1953 - mae: 0.3530\n","Epoch 2/5\n","\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.1985 - mae: 0.3555\n","Epoch 3/5\n","\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.1793 - mae: 0.3364\n","Epoch 4/5\n","\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.1724 - mae: 0.3320\n","Epoch 5/5\n","\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.1613 - mae: 0.3235\n"]},{"output_type":"execute_result","data":{"text/plain":["<keras.src.callbacks.history.History at 0x7e0d601a9cf0>"]},"metadata":{},"execution_count":5}],"source":["class CustomModel(keras.Model):\n","    def __init__(self, *args, **kwargs):\n","        super().__init__(*args, **kwargs)\n","        self.loss_tracker = keras.metrics.Mean(name=\"loss\")\n","        self.mae_metric = keras.metrics.MeanAbsoluteError(name=\"mae\")\n","        self.loss_fn = keras.losses.MeanSquaredError()\n","\n","    def train_step(self, data):\n","        x, y = data\n","\n","        # 이전 트레이닝 스텝에서 남은 가중치의 그래디언트를 지우기 위해\n","        # torch.nn.Module.zero_grad()를 호출합니다.\n","        self.zero_grad()\n","\n","        # 손실 계산\n","        y_pred = self(x, training=True)  # 순전파\n","        loss = self.loss_fn(y, y_pred)\n","\n","        # 손실에 대해 torch.Tensor.backward()를 호출하여 가중치의\n","        # 그래디언트를 계산합니다.\n","        loss.backward()\n","\n","        trainable_weights = [v for v in self.trainable_weights]\n","        gradients = [v.value.grad for v in trainable_weights]\n","\n","        # 가중치 업데이트\n","        with torch.no_grad():\n","            self.optimizer.apply(gradients, trainable_weights)\n","\n","        # 자체 메트릭 계산\n","        self.loss_tracker.update_state(loss)\n","        self.mae_metric.update_state(y, y_pred)\n","        return {\n","            \"loss\": self.loss_tracker.result(),\n","            \"mae\": self.mae_metric.result(),\n","        }\n","\n","    @property\n","    def metrics(self):\n","        # 여기에 `Metric` 객체를 나열하여,\n","        # 각 에포크의 시작 시 또는 `evaluate()`의 시작 시,\n","        # 자동으로 `reset_states()`가 호출되도록 합니다.\n","        return [self.loss_tracker, self.mae_metric]\n","\n","\n","# CustomModel의 인스턴스 생성\n","inputs = keras.Input(shape=(32,))\n","outputs = keras.layers.Dense(1)(inputs)\n","model = CustomModel(inputs, outputs)\n","\n","# 여기서 손실이나 메트릭을 전달하지 않습니다.\n","model.compile(optimizer=\"adam\")\n","\n","# 평소처럼 `fit`을 사용합니다 -- 콜백 등을 사용할 수 있습니다.\n","x = np.random.random((1000, 32))\n","y = np.random.random((1000, 1))\n","model.fit(x, y, epochs=5)"]},{"cell_type":"markdown","source":["## `sample_weight` & `class_weight` 지원"],"metadata":{"id":"BP4qhNLJ2BJa"}},{"cell_type":"markdown","source":["첫 번째 기본 예제에서 샘플 가중치에 대해 언급하지 않은 것을 눈치채셨을 겁니다.\n","`sample_weight`와 `class_weight`를 `fit()` 인자로 지원하려면,\n","간단히 다음과 같이 하면 됩니다:\n","\n","- `data` 인자에서 `sample_weight`를 언팩합니다.\n","- `compute_loss`와 `update_state`에 이를 전달합니다.\n","  (물론, 손실 및 메트릭에 대해 `compile()`을 사용하지 않는다면, 수동으로 적용할 수도 있습니다.)\n","- 끝입니다."],"metadata":{"id":"jUCzfXaY2FEn"}},{"cell_type":"code","execution_count":6,"metadata":{"id":"-H36seeV1J_-","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1726960138202,"user_tz":-540,"elapsed":299,"user":{"displayName":"Tae Kyu Lee","userId":"00886399863979660459"}},"outputId":"728c22ca-7d48-4b2b-ad0e-ac0f77900247"},"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/3\n","\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - mae: 0.5749 - loss: 0.2544\n","Epoch 2/3\n","\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - mae: 0.3678 - loss: 0.1085\n","Epoch 3/3\n","\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - mae: 0.3355 - loss: 0.0848\n"]},{"output_type":"execute_result","data":{"text/plain":["<keras.src.callbacks.history.History at 0x7e0d601a9c30>"]},"metadata":{},"execution_count":6}],"source":["class CustomModel(keras.Model):\n","    def train_step(self, data):\n","        # 데이터를 언팩합니다. 그 구조는 모델과\n","        # `fit()`에 전달한 것에 따라 달라집니다.\n","        if len(data) == 3:\n","            x, y, sample_weight = data\n","        else:\n","            sample_weight = None\n","            x, y = data\n","\n","        # 이전 트레이닝 스텝에서 남은 가중치의 그래디언트를 지우기 위해\n","        # torch.nn.Module.zero_grad()를 호출합니다.\n","        self.zero_grad()\n","\n","\n","        # 손실 계산\n","        y_pred = self(x, training=True)  # 순전파\n","        loss = self.compute_loss(\n","            y=y,\n","            y_pred=y_pred,\n","            sample_weight=sample_weight,\n","        )\n","\n","        # 손실에 대해 torch.Tensor.backward()를 호출하여,\n","        # 가중치의 그래디언트를 계산합니다.\n","        loss.backward()\n","\n","        trainable_weights = [v for v in self.trainable_weights]\n","        gradients = [v.value.grad for v in trainable_weights]\n","\n","        # 가중치 업데이트\n","        with torch.no_grad():\n","            self.optimizer.apply(gradients, trainable_weights)\n","\n","        # 메트릭 업데이트 (손실을 추적하는 메트릭 포함)\n","        for metric in self.metrics:\n","            if metric.name == \"loss\":\n","                metric.update_state(loss)\n","            else:\n","                metric.update_state(y, y_pred, sample_weight=sample_weight)\n","\n","        # 메트릭 이름을 현재 값에 매핑하는 딕셔너리를 반환합니다.\n","        # 이는 손실을 포함한다는 점에 유의하세요. (self.metrics에서 추적됨)\n","        return {m.name: m.result() for m in self.metrics}\n","\n","\n","# CustomModel의 인스턴스를 생성하고 컴파일합니다\n","inputs = keras.Input(shape=(32,))\n","outputs = keras.layers.Dense(1)(inputs)\n","model = CustomModel(inputs, outputs)\n","model.compile(optimizer=\"adam\", loss=\"mse\", metrics=[\"mae\"])\n","\n","# 이제 sample_weight 인자를 사용할 수 있습니다.\n","x = np.random.random((1000, 32))\n","y = np.random.random((1000, 1))\n","sw = np.random.random((1000, 1))\n","model.fit(x, y, sample_weight=sw, epochs=3)"]},{"cell_type":"markdown","source":["## 사용자 정의 평가 단계 제공하기"],"metadata":{"id":"qw0H5ne_2Jtt"}},{"cell_type":"markdown","source":["`model.evaluate()` 호출에 대해서도 동일한 작업을 하고 싶다면 어떻게 해야 할까요?\n","그런 경우, `test_step`을 정확히 동일한 방식으로 오버라이드하면 됩니다.\n","다음은 그 예시입니다:"],"metadata":{"id":"FZ2lUTcy2K0P"}},{"cell_type":"code","execution_count":7,"metadata":{"id":"8xQbnuqA1J__","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1726960161242,"user_tz":-540,"elapsed":80,"user":{"displayName":"Tae Kyu Lee","userId":"00886399863979660459"}},"outputId":"7ce48c8c-7b16-4d49-d24e-9ecdb0c7c9eb"},"outputs":[{"output_type":"stream","name":"stdout","text":["\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - mae: 1.5243 - loss: 2.5875\n"]},{"output_type":"execute_result","data":{"text/plain":["[2.5731401443481445, 1.5204790830612183]"]},"metadata":{},"execution_count":7}],"source":["class CustomModel(keras.Model):\n","    def test_step(self, data):\n","        # 데이터를 언팩합니다\n","        x, y = data\n","        # 예측값 계산\n","        y_pred = self(x, training=False)\n","        # 손실을 추적하는 메트릭을 업데이트합니다.\n","        loss = self.compute_loss(y=y, y_pred=y_pred)\n","        # 메트릭을 업데이트합니다.\n","        for metric in self.metrics:\n","            if metric.name == \"loss\":\n","                metric.update_state(loss)\n","            else:\n","                metric.update_state(y, y_pred)\n","        # 메트릭 이름을 현재 값에 매핑하는 딕셔너리를 반환합니다.\n","        # 이는 손실을 포함한다는 점에 유의하세요. (self.metrics에서 추적됨)\n","        return {m.name: m.result() for m in self.metrics}\n","\n","\n","# CustomModel의 인스턴스를 생성합니다.\n","inputs = keras.Input(shape=(32,))\n","outputs = keras.layers.Dense(1)(inputs)\n","model = CustomModel(inputs, outputs)\n","model.compile(loss=\"mse\", metrics=[\"mae\"])\n","\n","# 우리의 커스텀 test_step으로 평가합니다.\n","x = np.random.random((1000, 32))\n","y = np.random.random((1000, 1))\n","model.evaluate(x, y)"]},{"cell_type":"markdown","source":["## 마무리: 엔드 투 엔드 GAN 예제"],"metadata":{"id":"PHr-Tkkl2OIP"}},{"cell_type":"markdown","source":["엔드 투 엔드 예제를 통해 지금까지 배운 모든 것을 활용해 봅시다.\n","\n","다음과 같은 구성 요소를 고려하겠습니다:\n","\n","- 28x28x1 이미지를 생성하는 생성자 네트워크\n","- 28x28x1 이미지를 두 개의 클래스(\"가짜\"와 \"진짜\")로 분류하는 판별자 네트워크\n","- 각 네트워크에 대한 옵티마이저 하나\n","- 판별자를 트레이닝하기 위한 손실 함수"],"metadata":{"id":"9MGdIz6F2Pb_"}},{"cell_type":"code","execution_count":8,"metadata":{"id":"zvyYEayD1J__","executionInfo":{"status":"ok","timestamp":1726960182187,"user_tz":-540,"elapsed":43,"user":{"displayName":"Tae Kyu Lee","userId":"00886399863979660459"}}},"outputs":[],"source":["# 판별자 생성\n","discriminator = keras.Sequential(\n","    [\n","        keras.Input(shape=(28, 28, 1)),\n","        layers.Conv2D(64, (3, 3), strides=(2, 2), padding=\"same\"),\n","        layers.LeakyReLU(negative_slope=0.2),\n","        layers.Conv2D(128, (3, 3), strides=(2, 2), padding=\"same\"),\n","        layers.LeakyReLU(negative_slope=0.2),\n","        layers.GlobalMaxPooling2D(),\n","        layers.Dense(1),\n","    ],\n","    name=\"discriminator\",\n",")\n","\n","# 생성자 생성\n","latent_dim = 128\n","generator = keras.Sequential(\n","    [\n","        keras.Input(shape=(latent_dim,)),\n","        # 7x7x128 맵으로 reshape 하기 위해 128개의 계수를 생성합니다.\n","        layers.Dense(7 * 7 * 128),\n","        layers.LeakyReLU(negative_slope=0.2),\n","        layers.Reshape((7, 7, 128)),\n","        layers.Conv2DTranspose(128, (4, 4), strides=(2, 2), padding=\"same\"),\n","        layers.LeakyReLU(negative_slope=0.2),\n","        layers.Conv2DTranspose(128, (4, 4), strides=(2, 2), padding=\"same\"),\n","        layers.LeakyReLU(negative_slope=0.2),\n","        layers.Conv2D(1, (7, 7), padding=\"same\", activation=\"sigmoid\"),\n","    ],\n","    name=\"generator\",\n",")"]},{"cell_type":"markdown","metadata":{"id":"PsEtIjws1J__"},"source":["여기에는 `compile()`을 자신의 시그니처로 사용하고,\n","`train_step`에서 전체 GAN 알고리즘을 17줄로 구현한,\n","기능이 완전한(feature-complete) GAN 클래스가 있습니다:"]},{"cell_type":"code","execution_count":9,"metadata":{"id":"1PnocdrW1J__","executionInfo":{"status":"ok","timestamp":1726960194049,"user_tz":-540,"elapsed":6,"user":{"displayName":"Tae Kyu Lee","userId":"00886399863979660459"}}},"outputs":[],"source":["class GAN(keras.Model):\n","    def __init__(self, discriminator, generator, latent_dim):\n","        super().__init__()\n","        self.discriminator = discriminator\n","        self.generator = generator\n","        self.latent_dim = latent_dim\n","        self.d_loss_tracker = keras.metrics.Mean(name=\"d_loss\")\n","        self.g_loss_tracker = keras.metrics.Mean(name=\"g_loss\")\n","        self.seed_generator = keras.random.SeedGenerator(1337)\n","        self.built = True\n","\n","    @property\n","    def metrics(self):\n","        return [self.d_loss_tracker, self.g_loss_tracker]\n","\n","    def compile(self, d_optimizer, g_optimizer, loss_fn):\n","        super().compile()\n","        self.d_optimizer = d_optimizer\n","        self.g_optimizer = g_optimizer\n","        self.loss_fn = loss_fn\n","\n","    def train_step(self, real_images):\n","        device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n","        if isinstance(real_images, tuple) or isinstance(real_images, list):\n","            real_images = real_images[0]\n","        # 잠재 공간에서 랜덤 포인트 샘플링\n","        batch_size = real_images.shape[0]\n","        random_latent_vectors = keras.random.normal(\n","            shape=(batch_size, self.latent_dim), seed=self.seed_generator\n","        )\n","\n","        # 가짜 이미지를 생성합니다.\n","        generated_images = self.generator(random_latent_vectors)\n","\n","        # 이를 진짜 이미지와 결합합니다.\n","        real_images = torch.tensor(real_images, device=device)\n","        combined_images = torch.concat([generated_images, real_images], axis=0)\n","\n","        # 진짜와 가짜 이미지를 구분하는 레이블을 조합합니다.\n","        labels = torch.concat(\n","            [\n","                torch.ones((batch_size, 1), device=device),\n","                torch.zeros((batch_size, 1), device=device),\n","            ],\n","            axis=0,\n","        )\n","        # 레이블에 랜덤 노이즈를 추가합니다. - 중요한 트릭입니다!\n","        labels += 0.05 * keras.random.uniform(labels.shape, seed=self.seed_generator)\n","\n","        # 판별자를 트레이닝합니다.\n","        self.zero_grad()\n","        predictions = self.discriminator(combined_images)\n","        d_loss = self.loss_fn(labels, predictions)\n","        d_loss.backward()\n","        grads = [v.value.grad for v in self.discriminator.trainable_weights]\n","        with torch.no_grad():\n","            self.d_optimizer.apply(grads, self.discriminator.trainable_weights)\n","\n","        # 잠재 공간에서 랜덤 포인트 샘플링\n","        random_latent_vectors = keras.random.normal(\n","            shape=(batch_size, self.latent_dim), seed=self.seed_generator\n","        )\n","\n","        # \"모든 진짜 이미지 (all real images)\"라고 말하는 레이블을 조합합니다.\n","        misleading_labels = torch.zeros((batch_size, 1), device=device)\n","\n","        # 생성자를 트레이닝합니다. (판별자의 가중치를 업데이트하면 안됩니다)\n","        self.zero_grad()\n","        predictions = self.discriminator(self.generator(random_latent_vectors))\n","        g_loss = self.loss_fn(misleading_labels, predictions)\n","        grads = g_loss.backward()\n","        grads = [v.value.grad for v in self.generator.trainable_weights]\n","        with torch.no_grad():\n","            self.g_optimizer.apply(grads, self.generator.trainable_weights)\n","\n","        # 메트릭을 업데이트하고 그 값을 반환합니다.\n","        self.d_loss_tracker.update_state(d_loss)\n","        self.g_loss_tracker.update_state(g_loss)\n","        return {\n","            \"d_loss\": self.d_loss_tracker.result(),\n","            \"g_loss\": self.g_loss_tracker.result(),\n","        }"]},{"cell_type":"markdown","metadata":{"id":"Fa_m4ZqE1J__"},"source":["이를 테스트해봅시다:"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"sOx-xvnR1J__","colab":{"base_uri":"https://localhost:8080/"},"outputId":"704d78bd-d48d-4821-b9bd-cb8eaf6ba8fe"},"outputs":[{"output_type":"stream","name":"stdout","text":["\u001b[1m   4/1094\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m21s\u001b[0m 20ms/step - d_loss: 0.6668 - g_loss: 0.7123  "]},{"output_type":"stream","name":"stderr","text":["<ipython-input-9-3ba60e97f8d0>:36: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  real_images = torch.tensor(real_images, device=device)\n"]},{"output_type":"stream","name":"stdout","text":["\u001b[1m 814/1094\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m5s\u001b[0m 19ms/step - d_loss: 0.4984 - g_loss: 1.0113"]}],"source":["# 데이터셋을 준비합니다. 우리는 MNIST 숫자의 트레이닝과 테스트 데이터를 모두 사용합니다.\n","batch_size = 64\n","(x_train, _), (x_test, _) = keras.datasets.mnist.load_data()\n","all_digits = np.concatenate([x_train, x_test])\n","all_digits = all_digits.astype(\"float32\") / 255.0\n","all_digits = np.reshape(all_digits, (-1, 28, 28, 1))\n","\n","# TensorDataset 생성\n","dataset = torch.utils.data.TensorDataset(\n","    torch.from_numpy(all_digits), torch.from_numpy(all_digits)\n",")\n","\n","# DataLoader 생성\n","dataloader = torch.utils.data.DataLoader(dataset, batch_size=batch_size, shuffle=True)\n","\n","gan = GAN(discriminator=discriminator, generator=generator, latent_dim=latent_dim)\n","gan.compile(\n","    d_optimizer=keras.optimizers.Adam(learning_rate=0.0003),\n","    g_optimizer=keras.optimizers.Adam(learning_rate=0.0003),\n","    loss_fn=keras.losses.BinaryCrossentropy(from_logits=True),\n",")\n","\n","gan.fit(dataloader, epochs=1)"]},{"cell_type":"markdown","metadata":{"id":"-XzfyOYD1J__"},"source":["딥러닝의 기본 개념은 간단한데, 왜 그 구현은 고통스러워야 할까요?"]}],"metadata":{"accelerator":"GPU","colab":{"provenance":[{"file_id":"https://github.com/keras-team/keras-io/blob/master/guides/ipynb/custom_train_step_in_torch.ipynb","timestamp":1726959893701}],"toc_visible":true},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.0"}},"nbformat":4,"nbformat_minor":0}