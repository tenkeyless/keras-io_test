{"cells":[{"cell_type":"markdown","source":["# KerasNLP 시작하기"],"metadata":{"id":"CyV0ZVnjOdfj"}},{"cell_type":"markdown","source":["**저자:** [Jonathan Bischof](https://github.com/jbischof)  \n","**생성일:** 2022/12/15  \n","**최종편집일:** 2023/07/01  \n","**설명:** KerasNLP API에 대한 소개입니다."],"metadata":{"id":"jDnXsYuMOewn"}},{"cell_type":"markdown","source":["## 소개"],"metadata":{"id":"Xa-tjNE-Ogpx"}},{"cell_type":"markdown","metadata":{"id":"QQKpETNWOSgg"},"source":["KerasNLP는 전체 개발 주기를 지원하는 자연어 처리 라이브러리입니다.\n","우리의 워크플로우는 모듈형 구성 요소로 이루어져 있으며,\n","최첨단 사전 트레이닝된 가중치와 아키텍처를 제공하며,\n","사용자 필요에 따라 쉽게 커스터마이즈할 수 있습니다.\n","\n","이 라이브러리는 코어 Keras API의 확장입니다.\n","모든 높은 레벨 모듈은 [`Layers`](https://codecompose7.github.io/keras-doc-kr.github.io/api/layers/) 또는 [`Models`](https://codecompose7.github.io/keras-doc-kr.github.io/api/models/)입니다.\n","Keras에 익숙하다면, 축하합니다! 이미 대부분의 KerasNLP를 이해하고 있는 것입니다.\n","\n","KerasNLP는 Keras 3를 사용하여, TensorFlow, Pytorch, Jax와 함께 작동합니다.\n","아래 가이드에서는, 모델 트레이닝을 위해 `jax` 백엔드를 사용하고,\n","입력 전처리를 효율적으로 처리하기 위해, [tf.data](https://www.tensorflow.org/guide/data)를 사용합니다.\n","하지만, 자유롭게 다른 것을 사용해도 됩니다!\n","이 가이드는 백엔드를 TensorFlow 또는 PyTorch로 바꿔도 아무런 변경 없이 실행됩니다.\n","아래 `KERAS_BACKEND`를 업데이트하기만 하면 됩니다.\n","\n","이 가이드는 감정 분석 예제를 통해, 모듈식 접근 방식을 여섯 가지 복잡도 레벨에서 보여줍니다:\n","\n","-   사전 트레이닝된 분류기를 사용한 추론\n","-   사전 트레이닝된 백본을 미세 조정\n","-   사용자 제어 전처리로 미세 조정\n","-   커스텀 모델을 미세 조정\n","-   백본 모델을 사전 트레이닝\n","-   처음부터 직접 트랜스포머 모델 빌드 및 트레이닝\n","\n","가이드 전체에서, 우리는 Keras 공식 마스코트인 Keras 교수(Professor Keras)를 시각적 참조로 사용하여 자료의 복잡성을 설명합니다:\n","\n","<img src=\"https://storage.googleapis.com/keras-nlp/getting_started_guide/prof_keras_evolution.png\" alt=\"drawing\" height=\"250\"/>"]},{"cell_type":"code","execution_count":1,"metadata":{"id":"YgxRavNlDkOF","executionInfo":{"status":"ok","timestamp":1727140741815,"user_tz":-540,"elapsed":6,"user":{"displayName":"Tae Kyu Lee","userId":"00886399863979660459"}}},"outputs":[],"source":["# 이 노트북은 Keras cv가 설치되어 있다는 가정 하에 진행됩니다.\n","# 이 노트북은 Keras 3이 설치되어 있다는 가정 하에 진행됩니다.\n","#\n","# !pip install -q --upgrade keras-cv\n","# !pip install -q --upgrade keras  # Upgrade to Keras 3."]},{"cell_type":"code","source":["# import os\n","\n","# os.environ[\"KERAS_BACKEND\"] = \"tensorflow\"\n","# os.environ[\"KERAS_BACKEND\"] = \"jax\"\n","# os.environ[\"KERAS_BACKEND\"] = \"torch\""],"metadata":{"id":"RAe2RgdnGBKE","executionInfo":{"status":"ok","timestamp":1727140741817,"user_tz":-540,"elapsed":0,"user":{"displayName":"Tae Kyu Lee","userId":"00886399863979660459"}}},"execution_count":2,"outputs":[]},{"cell_type":"code","source":["from keras import backend\n","\n","print(backend.backend())"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"2wmCaTMYGVP7","executionInfo":{"status":"ok","timestamp":1727140743481,"user_tz":-540,"elapsed":1663,"user":{"displayName":"Tae Kyu Lee","userId":"00886399863979660459"}},"outputId":"b9b553b6-4e69-4fea-d008-ddff0ecf9274"},"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["tensorflow\n"]}]},{"cell_type":"code","source":["import keras\n","\n","print(keras.__version__)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"dm_WihC9yFqN","executionInfo":{"status":"ok","timestamp":1727140743486,"user_tz":-540,"elapsed":4,"user":{"displayName":"Tae Kyu Lee","userId":"00886399863979660459"}},"outputId":"72005e32-97a7-4227-c191-17c84512dcbf"},"execution_count":4,"outputs":[{"output_type":"stream","name":"stdout","text":["3.4.1\n"]}]},{"cell_type":"code","execution_count":5,"metadata":{"id":"d1UjG7Y-OSgh","executionInfo":{"status":"ok","timestamp":1727140743625,"user_tz":-540,"elapsed":140,"user":{"displayName":"Tae Kyu Lee","userId":"00886399863979660459"}}},"outputs":[],"source":["import os\n","\n","os.environ[\"KERAS_BACKEND\"] = \"jax\"  # 또는 \"tensorflow\", \"torch\"\n","\n","import keras_nlp\n","import keras\n","\n","# 이 가이드에서 모든 트레이닝을 가속화하기 위해 혼합 정밀도 사용.\n","keras.mixed_precision.set_global_policy(\"mixed_float16\")"]},{"cell_type":"markdown","source":["## API 빠른 시작"],"metadata":{"id":"QJcX0BaBO8ha"}},{"cell_type":"markdown","metadata":{"id":"HTs4rUW5OSgh"},"source":["가장 높은 레벨의 API는 `keras_nlp.models`입니다.\n","이 심볼들은 문자열을 토큰으로, 토큰을 밀집 특성으로,\n","그리고 dense 특성을 작업별 출력으로 변환하는 전체 과정을 다룹니다.\n","각 `XX` 아키텍처(예: `Bert`)에 대해, 다음 모듈을 제공합니다:\n","\n","-   **Tokenizer**: `keras_nlp.models.XXTokenizer`\n","    -   **기능**: 문자열을 토큰 ID 시퀀스로 변환합니다.\n","    -   **중요성**: 문자열의 raw 바이트는 유용한 특성으로 사용되기엔 차원이 너무 높으므로,\n","        먼저 작은 수의 토큰으로 매핑합니다.\n","        예를 들어, `\"The quick brown fox\"`는 `[\"the\", \"qu\", \"##ick\", \"br\", \"##own\", \"fox\"]`로 변환됩니다.\n","    -   **상속받는 클래스**: [`keras.layers.Layer`](https://codecompose7.github.io/keras-doc-kr.github.io/api/layers/base_layer#layer-class).\n","  \n","-   **Preprocessor**: `keras_nlp.models.XXPreprocessor`\n","    -   **기능**: 문자열을 토큰화로 시작하여, 백본이 사용할 수 있는 전처리된, 텐서 딕셔너리로 변환합니다.\n","    -   **중요성**: 각 모델은 입력을 이해하기 위해, 구분 기호 토큰과 같은 특수 토큰 및 추가 텐서를 사용합니다.\n","        예를 들어 입력 세그먼트를 구분하거나, 패딩 토큰을 식별하는 기능이 포함됩니다.\n","        모든 시퀀스를 동일한 길이로 패딩하면, 계산 효율성이 높아집니다.\n","    -   **구성 요소**: `XXTokenizer`.\n","    -   **상속받는 클래스**: [`keras.layers.Layer`](https://codecompose7.github.io/keras-doc-kr.github.io/api/layers/base_layer#layer-class).\n","  \n","-   **Backbone**: `keras_nlp.models.XXBackbone`\n","    -   **기능**: 전처리된 텐서를 dense 특성으로 변환합니다. *문자열 처리는 하지 않으므로, 먼저 전처리기를 호출해야 합니다.*\n","    -   **중요성**: 백본은 입력 토큰을 dense 특성으로 압축하여, 후속 작업에 사용할 수 있도록 합니다.\n","        백본 모델은 일반적으로 대량의 비지도 학습 데이터를 사용하여, 언어 모델링 작업으로 사전 트레이닝된 것입니다.\n","        이러한 정보를 새로운 작업에 전이하는 것은 현대 NLP에서 중요한 돌파구입니다.\n","    -   **상속받는 클래스**: [`keras.Model`](https://codecompose7.github.io/keras-doc-kr.github.io/api/models/model#model-class).\n","  \n","-   **Task**: 예를 들어, `keras_nlp.models.XXClassifier`\n","    -   **기능**: 문자열을 작업별 출력(예: 분류 확률)으로 변환합니다.\n","    -   **중요성**: 작업 모델은 문자열 전처리와 백본 모델을 작업별 `Layers`와 결합하여,\n","        문장 분류, 토큰 분류, 텍스트 생성 등의 문제를 해결합니다.\n","        추가된 `Layers`는 라벨이 지정된 데이터를 사용하여 미세 조정해야 합니다.\n","    -   **구성 요소**: `XXBackbone`과 `XXPreprocessor`.\n","    -   **상속받는 클래스**: [`keras.Model`](https://codecompose7.github.io/keras-doc-kr.github.io/api/models/model#model-class).\n","\n","다음은 `BertClassifier`의 모듈 계층 구조입니다(모든 관계는 구성적 관계입니다):\n","\n","<img src=\"https://storage.googleapis.com/keras-nlp/getting_started_guide/class_diagram.png\" alt=\"drawing\" height=\"300\"/>\n","\n","모든 모듈은 독립적으로 사용할 수 있으며, **사전 설정**된 아키텍처와 가중치로 클래스를 인스턴스화하는,\n","`from_preset()` 메서드를 갖고 있습니다. (아래 예 참조)"]},{"cell_type":"markdown","source":["## 데이터"],"metadata":{"id":"weUqzpgiPNne"}},{"cell_type":"markdown","metadata":{"id":"X_UEaHftOSgh"},"source":["우리는 IMDB 영화 리뷰의 감정 분석 예시를 사용합니다.\n","이 작업에서는 텍스트를 사용하여 리뷰가 긍정적(`label = 1`)인지 부정적(`label = 0`)인지를 예측합니다.\n","\n","데이터는 [`keras.utils.text_dataset_from_directory`](https://codecompose7.github.io/keras-doc-kr.github.io/api/data_loading/text#textdatasetfromdirectory-function)를 사용하여 로드되며,\n","이는 강력한 [`tf.data.Dataset`](https://www.tensorflow.org/api_docs/python/tf/data/Dataset) 형식을 이용합니다."]},{"cell_type":"code","execution_count":6,"metadata":{"id":"pqhwuw7LOSgh","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1727140844282,"user_tz":-540,"elapsed":100655,"user":{"displayName":"Tae Kyu Lee","userId":"00886399863979660459"}},"outputId":"4b902d4a-6ef9-421e-c081-d051ff5b0aa5"},"outputs":[{"output_type":"stream","name":"stdout","text":["  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n","                                 Dload  Upload   Total   Spent    Left  Speed\n","100 80.2M  100 80.2M    0     0   850k      0  0:01:36  0:01:36 --:--:--  897k\n"]}],"source":["!curl -O https://ai.stanford.edu/~amaas/data/sentiment/aclImdb_v1.tar.gz\n","!tar -xf aclImdb_v1.tar.gz\n","!# 비지도 학습 예제 제거\n","!rm -r aclImdb/train/unsup"]},{"cell_type":"code","execution_count":7,"metadata":{"id":"IaReHB7WOSgi","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1727140846235,"user_tz":-540,"elapsed":1950,"user":{"displayName":"Tae Kyu Lee","userId":"00886399863979660459"}},"outputId":"75b7837e-1f94-4658-c37b-8ac59f762a70"},"outputs":[{"output_type":"stream","name":"stdout","text":["Found 25000 files belonging to 2 classes.\n","Found 25000 files belonging to 2 classes.\n","(<tf.Tensor: shape=(), dtype=string, numpy=b'I remember watching this in the 1970s - then I have just recently borrowed a couple of episodes from our public library.<br /><br />With a nearly 30 year hiatus, I have come to another conclusion. Most of the principals interviewed in this series - some at the center of power like Traudl Junge (Hitler\\'s Secretary),Karl Doenitz (head of Germany\\'s navy) Anthony Eden (UK) - are long gone but their first hand accounts will live on.From Generals and Admirals to Sergeants, Russian civilians, concentration camp survivors, all are on record here. <br /><br />I can remember the Lord Mountbatten interview (killed in the 1970s) <br /><br />This is truly a gem and I believe the producer of this series was knighted by Queen Elizabeth for this work - well deserved.<br /><br />Seeing these few episodes from the library makes me want to buy the set.<br /><br />This is the only \"10\" I have given any review but I have discovered like a fine bottle of wine, it is more appreciated with a little time...'>, <tf.Tensor: shape=(), dtype=int32, numpy=1>)\n"]}],"source":["BATCH_SIZE = 16\n","imdb_train = keras.utils.text_dataset_from_directory(\n","    \"aclImdb/train\",\n","    batch_size=BATCH_SIZE,\n",")\n","imdb_test = keras.utils.text_dataset_from_directory(\n","    \"aclImdb/test\",\n","    batch_size=BATCH_SIZE,\n",")\n","\n","# 첫 번째 리뷰 확인\n","# 형식은 (리뷰 텍스트 텐서, 라벨 텐서)\n","print(imdb_train.unbatch().take(1).get_single_element())"]},{"cell_type":"markdown","source":["## 사전 트레이닝된 분류기로 추론하기"],"metadata":{"id":"nPDPuW38PvAX"}},{"cell_type":"markdown","metadata":{"id":"2nwQxvcROSgi"},"source":["<img src=\"https://storage.googleapis.com/keras-nlp/getting_started_guide/prof_keras_beginner.png\" height=\"250\" alt=\"drawing\" />\n","\n","KerasNLP에서 가장 높은 레벨의 모듈은 **태스크**입니다.\n","**태스크**는 (일반적으로 사전 트레이닝된) **백본** 모델과 태스크 특화 레이어들로 구성된 [`keras.Model`](https://codecompose7.github.io/keras-doc-kr.github.io/api/models/model#model-class)입니다.\n","다음은 [`keras_nlp.models.BertClassifier`](https://codecompose7.github.io/keras-doc-kr.github.io/api/keras_nlp/models/bert/bert_classifier#bertclassifier-class)를 사용하는 예시입니다.\n","\n","**참고**: 출력은 클래스별 로짓입니다.\n","(예: `[0, 0]`은 긍정일 확률이 50%임을 나타냅니다)\n","출력은 이진 분류의 경우 \\[negative, positive\\]입니다."]},{"cell_type":"code","execution_count":8,"metadata":{"id":"IlH8t7ctOSgi","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1727140863382,"user_tz":-540,"elapsed":17145,"user":{"displayName":"Tae Kyu Lee","userId":"00886399863979660459"}},"outputId":"250cd228-7b17-48d5-a522-bfb1472b1124"},"outputs":[{"output_type":"stream","name":"stderr","text":["Downloading from https://www.kaggle.com/api/v1/models/keras/bert/keras/bert_tiny_en_uncased_sst2/4/download/config.json...\n","100%|██████████| 454/454 [00:00<00:00, 601kB/s]\n","Downloading from https://www.kaggle.com/api/v1/models/keras/bert/keras/bert_tiny_en_uncased_sst2/4/download/task.json...\n","100%|██████████| 2.04k/2.04k [00:00<00:00, 2.48MB/s]\n","Downloading from https://www.kaggle.com/api/v1/models/keras/bert/keras/bert_tiny_en_uncased_sst2/4/download/assets/tokenizer/vocabulary.txt...\n","100%|██████████| 226k/226k [00:00<00:00, 284kB/s]\n","Downloading from https://www.kaggle.com/api/v1/models/keras/bert/keras/bert_tiny_en_uncased_sst2/4/download/task.weights.h5...\n","100%|██████████| 50.3M/50.3M [00:04<00:00, 11.5MB/s]\n","/usr/local/lib/python3.10/dist-packages/keras/src/saving/saving_lib.py:576: UserWarning: Skipping variable loading for optimizer 'loss_scale_optimizer', because it has 4 variables whereas the saved optimizer has 84 variables. \n","  saveable.load_own_variables(weights_store.get(inner_path))\n","/usr/local/lib/python3.10/dist-packages/keras/src/saving/saving_lib.py:576: UserWarning: Skipping variable loading for optimizer 'adam', because it has 2 variables whereas the saved optimizer has 0 variables. \n","  saveable.load_own_variables(weights_store.get(inner_path))\n","Downloading from https://www.kaggle.com/api/v1/models/keras/bert/keras/bert_tiny_en_uncased_sst2/4/download/model.weights.h5...\n","100%|██████████| 16.8M/16.8M [00:02<00:00, 5.96MB/s]\n"]},{"output_type":"stream","name":"stdout","text":["\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4s/step\n"]},{"output_type":"execute_result","data":{"text/plain":["array([[-1.289,  1.395]], dtype=float16)"]},"metadata":{},"execution_count":8}],"source":["classifier = keras_nlp.models.BertClassifier.from_preset(\"bert_tiny_en_uncased_sst2\")\n","# 참고: 배치 입력이 필요하므로, 문자열을 iterable로 래핑해야 합니다.\n","classifier.predict([\"I love modular workflows in keras-nlp!\"])"]},{"cell_type":"markdown","metadata":{"id":"Z9Vq9lNyOSgi"},"source":["모든 **태스크**에는 사전 설정된 전처리, 아키텍처 및 가중치로 [`keras.Model`](https://codecompose7.github.io/keras-doc-kr.github.io/api/models/model#model-class) 인스턴스를 생성하는 `from_preset` 메서드가 있습니다.\n","이는 우리가 [`keras.Model`](https://codecompose7.github.io/keras-doc-kr.github.io/api/models/model#model-class)에서 허용하는 모든 형식의 raw 문자열을 전달하고, 태스크에 맞는 출력 값을 받을 수 있음을 의미합니다.\n","\n","이 특정 **프리셋**은 `\"bert_tiny_uncased_en\"` **백본**을 `sst2`로 파인 튜닝한 모델로,\n","이는 Rotten Tomatoes 영화 리뷰 감성 분석을 수행한 모델입니다.\n","데모에서는 `tiny` 아키텍처를 사용하지만, 더 큰 모델을 사용하면 최신 성능(SoTA)을 얻을 수 있습니다.\n","`BertClassifier`에 사용 가능한 모든 태스크별 프리셋은,\n","[models 페이지](https://codecompose7.github.io/keras-doc-kr.github.io/api/keras_nlp/models/)에서 확인할 수 있습니다.\n","\n","이제 IMDB 데이터셋에서 분류기를 평가해 봅시다.\n","여기서 [`keras.Model.compile`](https://codecompose7.github.io/keras-doc-kr.github.io/api/models/model_training_apis#compile-method)를 호출할 필요는 없습니다.\n","`BertClassifier`와 같은 모든 **태스크** 모델은 기본적으로 컴파일된 상태로 제공되므로,\n","[`keras.Model.evaluate`](https://codecompose7.github.io/keras-doc-kr.github.io/api/models/model_training_apis#evaluate-method)를 바로 호출할 수 있습니다.\n","물론, 원한다면 새로운 메트릭을 추가하기 위해, 일반적인 컴파일 방식을 사용할 수 있습니다.\n","\n","출력 값은 \\[loss, accuracy\\]입니다."]},{"cell_type":"code","execution_count":9,"metadata":{"id":"j9iKDMEAOSgi","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1727140873838,"user_tz":-540,"elapsed":10455,"user":{"displayName":"Tae Kyu Lee","userId":"00886399863979660459"}},"outputId":"70591d27-5e3e-4e67-a786-618b3affa2ea"},"outputs":[{"output_type":"stream","name":"stdout","text":["\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 4ms/step - loss: 0.4521 - sparse_categorical_accuracy: 0.7908\n"]},{"output_type":"execute_result","data":{"text/plain":["[0.45500361919403076, 0.7903199791908264]"]},"metadata":{},"execution_count":9}],"source":["classifier.evaluate(imdb_test)"]},{"cell_type":"markdown","metadata":{"id":"EgzQ7kY-OSgi"},"source":["결과는 78%의 정확도로, 아무런 트레이닝 없이 이 정도 성능을 얻었습니다. 나쁘지 않네요!"]},{"cell_type":"markdown","source":["## 사전 트레이닝된 BERT 백본 파인 튜닝"],"metadata":{"id":"sBhE1Te9QJt2"}},{"cell_type":"markdown","metadata":{"id":"H885lJe1OSgi"},"source":["<img src=\"https://storage.googleapis.com/keras-nlp/getting_started_guide/prof_keras_intermediate.png\" height=\"250\" alt=\"drawing\" />\n","\n","태스크에 맞는 라벨링된 텍스트가 있으면, 커스텀 분류기를 파인 튜닝하여 성능을 향상시킬 수 있습니다.\n","IMDB 리뷰 감성을 예측하려면, Rotten Tomatoes 데이터보다 IMDB 데이터를 사용하는 것이 더 나은 성능을 낼 것입니다.\n","또한, 많은 태스크에서 관련 사전 트레이닝된 모델이 없을 수도 있습니다. (예: 고객 리뷰 분류(categorizing))\n","\n","파인 튜닝의 워크플로우는 위와 거의 동일하지만, 전체 분류기 대신 **백본** 전용 **프리셋**을 요청하는 차이만 있습니다.\n","**백본** **프리셋**이 전달되면, **태스크** `Model`은 태스크에 맞는 레이어들을 무작위로 초기화하고 트레이닝 준비를 합니다.\n","`BertClassifier`에 사용 가능한 모든 **백본** 프리셋은,\n","[models 페이지](https://codecompose7.github.io/keras-doc-kr.github.io/api/keras_nlp/models/)에서 확인할 수 있습니다.\n","\n","분류기를 트레이닝하려면, 다른 [`keras.Model`](https://codecompose7.github.io/keras-doc-kr.github.io/api/models/model#model-class)처럼 [`keras.Model.fit`](https://codecompose7.github.io/keras-doc-kr.github.io/api/models/model_training_apis#fit-method)를 사용하면 됩니다.\n","위에서와 마찬가지로 **태스크**에 대해, [`keras.Model.compile`](https://codecompose7.github.io/keras-doc-kr.github.io/api/models/model_training_apis#compile-method)을 스킵하고, 컴파일 기본값을 사용할 수 있습니다.\n","전처리가 포함되어 있으므로, raw 데이터를 바로 전달할 수 있습니다."]},{"cell_type":"code","execution_count":10,"metadata":{"id":"KN8rFkAmOSgi","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1727140920637,"user_tz":-540,"elapsed":46798,"user":{"displayName":"Tae Kyu Lee","userId":"00886399863979660459"}},"outputId":"7c93274a-bb4c-453b-d67f-c170ca288c9a"},"outputs":[{"output_type":"stream","name":"stderr","text":["Downloading from https://www.kaggle.com/api/v1/models/keras/bert/keras/bert_tiny_en_uncased/2/download/config.json...\n","100%|██████████| 507/507 [00:00<00:00, 222kB/s]\n","Downloading from https://www.kaggle.com/api/v1/models/keras/bert/keras/bert_tiny_en_uncased/2/download/task.json...\n","Downloading from https://www.kaggle.com/api/v1/models/keras/bert/keras/bert_tiny_en_uncased/2/download/model.weights.h5...\n","100%|██████████| 16.8M/16.8M [00:03<00:00, 4.66MB/s]\n","Downloading from https://www.kaggle.com/api/v1/models/keras/bert/keras/bert_tiny_en_uncased/2/download/preprocessor.json...\n","Downloading from https://www.kaggle.com/api/v1/models/keras/bert/keras/bert_tiny_en_uncased/2/download/tokenizer.json...\n","100%|██████████| 547/547 [00:00<00:00, 1.09MB/s]\n","Downloading from https://www.kaggle.com/api/v1/models/keras/bert/keras/bert_tiny_en_uncased/2/download/assets/tokenizer/vocabulary.txt...\n","100%|██████████| 226k/226k [00:00<00:00, 268kB/s]\n"]},{"output_type":"stream","name":"stdout","text":["\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 14ms/step - loss: 0.5245 - sparse_categorical_accuracy: 0.7212 - val_loss: 0.3178 - val_sparse_categorical_accuracy: 0.8633\n"]},{"output_type":"execute_result","data":{"text/plain":["<keras.src.callbacks.history.History at 0x7a6b8ddb2fb0>"]},"metadata":{},"execution_count":10}],"source":["classifier = keras_nlp.models.BertClassifier.from_preset(\n","    \"bert_tiny_en_uncased\",\n","    num_classes=2,\n",")\n","classifier.fit(\n","    imdb_train,\n","    validation_data=imdb_test,\n","    epochs=1,\n",")"]},{"cell_type":"markdown","metadata":{"id":"seeb9tn_OSgi"},"source":["여기서는 한 번의 트레이닝만으로 검증 정확도가 0.78에서 0.87로 크게 상승하는 것을 볼 수 있습니다.\n","IMDB 데이터셋이 `sst2`보다 훨씬 작음에도 불구하고 말이죠."]},{"cell_type":"markdown","source":["## 사용자 제어 전처리로 파인 튜닝"],"metadata":{"id":"OCwFB7h9QlkU"}},{"cell_type":"markdown","metadata":{"id":"NpegrIRCOSgj"},"source":["<img src=\"https://storage.googleapis.com/keras-nlp/getting_started_guide/prof_keras_advanced.png\" height=\"250\" alt=\"drawing\" />\n","\n","일부 고급 트레이닝 시나리오에서는, 사용자가 전처리를 직접 제어하기를 원할 수 있습니다.\n","대규모 데이터셋의 경우, 예제를 미리 전처리하여 디스크에 저장하거나,\n","[`tf.data.experimental.service`](https://www.tensorflow.org/api_docs/python/tf/data/experimental/service)를 사용하여 별도의 작업자 풀에서 전처리할 수 있습니다.\n","또는, 입력을 다루기 위해 커스텀 전처리가 필요한 경우도 있습니다.\n","\n","**태스크** `Model` 생성자에 `preprocessor=None`을 전달하여 자동 전처리를 건너뛰거나,\n","대신 커스텀 `BertPreprocessor`를 전달할 수 있습니다."]},{"cell_type":"markdown","source":["### 동일한 프리셋에서 전처리 분리하기"],"metadata":{"id":"VA4pJqkdQpBt"}},{"cell_type":"markdown","metadata":{"id":"hGWF1NCxOSgj"},"source":["각 모델 아키텍처에는 자체 `from_preset` 생성자가 있는, 병렬 **전처리** `Layer`가 있습니다.\n","이 `Layer`에 대해 동일한 **프리셋**을 사용하면, **태스크**와 일치하는 **전처리**를 반환합니다.\n","\n","이 워크플로우에서는 `tf.data.Dataset.cache()`를 사용하여,\n","fit 시작 전에 전처리를 한 번만 계산하고 그 결과를 캐시한 다음,\n","3번의 에포크 동안 모델을 트레이닝합니다.\n","\n","**참고:** [`tf.data`](https://www.tensorflow.org/api_docs/python/tf/data)를 사용하여,\n","Jax 또는 PyTorch 백엔드에서 전처리를 실행할 수 있습니다.\n","입력 데이터셋은 트레이닝 중에 백엔드 네이티브 텐서 타입으로 자동 변환됩니다.\n","실제로 [`tf.data`](https://www.tensorflow.org/api_docs/python/tf/data)의 전처리 효율성을 고려할 때,\n","모든 백엔드에서 이를 사용하는 것이 좋은 관행입니다."]},{"cell_type":"code","execution_count":11,"metadata":{"id":"MyVhdcgiOSgj","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1727140973698,"user_tz":-540,"elapsed":53059,"user":{"displayName":"Tae Kyu Lee","userId":"00886399863979660459"}},"outputId":"a5416acb-0651-4c26-889c-997e90e7e63f"},"outputs":[{"output_type":"stream","name":"stderr","text":["Downloading from https://www.kaggle.com/api/v1/models/keras/bert/keras/bert_tiny_en_uncased/2/download/preprocessor.json...\n","Downloading from https://www.kaggle.com/api/v1/models/keras/bert/keras/bert_tiny_en_uncased/2/download/task.json...\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 1/3\n","\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 12ms/step - loss: 0.5329 - sparse_categorical_accuracy: 0.7144 - val_loss: 0.3163 - val_sparse_categorical_accuracy: 0.8637\n","Epoch 2/3\n","\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 6ms/step - loss: 0.2889 - sparse_categorical_accuracy: 0.8802 - val_loss: 0.3161 - val_sparse_categorical_accuracy: 0.8687\n","Epoch 3/3\n","\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 8ms/step - loss: 0.2156 - sparse_categorical_accuracy: 0.9143 - val_loss: 0.3374 - val_sparse_categorical_accuracy: 0.8682\n"]},{"output_type":"execute_result","data":{"text/plain":["<keras.src.callbacks.history.History at 0x7a6b83d86470>"]},"metadata":{},"execution_count":11}],"source":["import tensorflow as tf\n","\n","preprocessor = keras_nlp.models.BertPreprocessor.from_preset(\n","    \"bert_tiny_en_uncased\",\n","    sequence_length=512,\n",")\n","\n","# 전처리를 `map()`을 사용해, 트레이닝 및 테스트 데이터의 각 샘플에 적용합니다.\n","# 성능을 조정하려면 [`tf.data.AUTOTUNE`](https://www.tensorflow.org/api_docs/python/tf/data/AUTOTUNE)과\n","# `prefetch()` 옵션을 사용할 수 있습니다.\n","# 성능 세부 사항은 https://www.tensorflow.org/guide/data_performance에서 확인하세요.\n","\n","# 참고: `cache()`는 트레이닝 데이터가 CPU 메모리에 맞는 경우에만 호출하세요!\n","imdb_train_cached = (\n","    imdb_train.map(preprocessor, tf.data.AUTOTUNE).cache().prefetch(tf.data.AUTOTUNE)\n",")\n","imdb_test_cached = (\n","    imdb_test.map(preprocessor, tf.data.AUTOTUNE).cache().prefetch(tf.data.AUTOTUNE)\n",")\n","\n","classifier = keras_nlp.models.BertClassifier.from_preset(\n","    \"bert_tiny_en_uncased\", preprocessor=None, num_classes=2\n",")\n","classifier.fit(\n","    imdb_train_cached,\n","    validation_data=imdb_test_cached,\n","    epochs=3,\n",")"]},{"cell_type":"markdown","metadata":{"id":"qdW0q-Z1OSgj"},"source":["세 번의 에포크 후, 우리의 검증 정확도는 0.88로 증가했습니다.\n","이는 데이터셋의 크기와 모델의 크기에 의해 결정됩니다.\n","90% 이상의 정확도를 달성하려면, `\"bert_base_en_uncased\"`와 같은 더 큰 **프리셋**을 시도해 보세요.\n","사용 가능한 모든 **백본** 프리셋은,\n","keras.io [모델 페이지](https://codecompose7.github.io/keras-doc-kr.github.io/api/keras_nlp/models/)에서 확인할 수 있습니다."]},{"cell_type":"markdown","source":["### 커스텀 전처리"],"metadata":{"id":"rwZCxf61QyRw"}},{"cell_type":"markdown","metadata":{"id":"X326eQ45OSgj"},"source":["커스텀 전처리가 필요한 경우, raw 문자열을 토큰으로 매핑하는 `Tokenizer` 클래스를 직접 사용할 수 있습니다.\n","이 클래스에는 사전 트레이닝과 일치하는 어휘를 얻기 위한, `from_preset()` 생성자가 있습니다.\n","\n","**참고:** `BertTokenizer`는 기본적으로 시퀀스를 패딩하지 않으므로, 출력은 길이가 가변적인 형식으로 나타납니다.\n","아래의 `MultiSegmentPacker`는 이러한 가변 길이 시퀀스를 dense 텐서 타입([`tf.Tensor`](https://www.tensorflow.org/api_docs/python/tf/Tensor) 또는 `torch.Tensor`)으로 패딩 처리합니다."]},{"cell_type":"code","execution_count":12,"metadata":{"id":"3rGvEKLOOSgj","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1727140975022,"user_tz":-540,"elapsed":1322,"user":{"displayName":"Tae Kyu Lee","userId":"00886399863979660459"}},"outputId":"129ef7dc-856e-42ae-9a27-f3651d062eed"},"outputs":[{"output_type":"stream","name":"stdout","text":["({'token_ids': <tf.Tensor: shape=(64,), dtype=int32, numpy=\n","array([  101,  2023,  2034,  2048,  3692,  1997,  2023,  4038,  2186,\n","        2020,  2200,  4326,  1998,  2027,  4694,  1005,  1056,  2200,\n","        6057,  1998,  2018,  1037,  3689,  5783,  2073,  3021,  1006,\n","        1996,  2388,  1007,  2001,  8084,  2007,  2035,  1996,  5156,\n","        3471,  1999,  2166,  2021,  2008,  5783,  2001,  1037,  2978,\n","        2139, 24128,  1998,  2134,  1005,  1056,  4666,  2092,  2007,\n","       16215,  4038,  3787,  2029,  2003,  2763,  2339,  2009,  2001,\n","         102], dtype=int32)>, 'segment_ids': <tf.Tensor: shape=(64,), dtype=int32, numpy=\n","array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n","      dtype=int32)>, 'padding_mask': <tf.Tensor: shape=(64,), dtype=bool, numpy=\n","array([ True,  True,  True,  True,  True,  True,  True,  True,  True,\n","        True,  True,  True,  True,  True,  True,  True,  True,  True,\n","        True,  True,  True,  True,  True,  True,  True,  True,  True,\n","        True,  True,  True,  True,  True,  True,  True,  True,  True,\n","        True,  True,  True,  True,  True,  True,  True,  True,  True,\n","        True,  True,  True,  True,  True,  True,  True,  True,  True,\n","        True,  True,  True,  True,  True,  True,  True,  True,  True,\n","        True])>}, <tf.Tensor: shape=(), dtype=int32, numpy=1>)\n"]}],"source":["tokenizer = keras_nlp.models.BertTokenizer.from_preset(\"bert_tiny_en_uncased\")\n","tokenizer([\"I love modular workflows!\", \"Libraries over frameworks!\"])\n","\n","# 직접 패커를 작성하거나 `Layers` 중 하나를 사용할 수 있습니다.\n","packer = keras_nlp.layers.MultiSegmentPacker(\n","    start_value=tokenizer.cls_token_id,\n","    end_value=tokenizer.sep_token_id,\n","    # 참고: 이 값은 프리셋의 `sequence_length`보다 길 수 없으며,\n","    # 커스텀 전처리기에는 이를 확인하는 과정이 없습니다!\n","    sequence_length=64,\n",")\n","\n","# 이 함수는 텍스트 샘플 `x`와 해당 레이블 `y`를 입력받아,\n","# 텍스트를 BERT 모델에 적합한 형식으로 변환합니다.\n","def preprocessor(x, y):\n","    token_ids, segment_ids = packer(tokenizer(x))\n","    x = {\n","        \"token_ids\": token_ids,\n","        \"segment_ids\": segment_ids,\n","        \"padding_mask\": token_ids != 0,\n","    }\n","    return x, y\n","\n","\n","imdb_train_preprocessed = imdb_train.map(preprocessor, tf.data.AUTOTUNE).prefetch(\n","    tf.data.AUTOTUNE\n",")\n","imdb_test_preprocessed = imdb_test.map(preprocessor, tf.data.AUTOTUNE).prefetch(\n","    tf.data.AUTOTUNE\n",")\n","\n","# 전처리된 예시 출력\n","print(imdb_train_preprocessed.unbatch().take(1).get_single_element())"]},{"cell_type":"markdown","source":["## 커스텀 모델을 사용한 파인 튜닝"],"metadata":{"id":"0LmJepnxQ3Dq"}},{"cell_type":"markdown","metadata":{"id":"xAhQ5ciXOSgj"},"source":["<img src=\"https://storage.googleapis.com/keras-nlp/getting_started_guide/prof_keras_advanced.png\" height=\"250\" alt=\"drawing\" />\n","\n","더 고급 응용 프로그램의 경우, 적절한 **태스크** `Model`이 제공되지 않을 수 있습니다.\n","이 경우, 커스텀 `Layer`와 함께 사용할 수 있는 **백본** `Model`에 직접 액세스할 수 있으며,\n","이는 자체 `from_preset` 생성자를 가지고 있습니다.\n","자세한 예시는 [전이 학습 가이드](https://codecompose7.github.io/keras-doc-kr.github.io/guides/transfer_learning/)에서 확인할 수 있습니다.\n","\n","**백본** `Model`은 자동 전처리를 포함하지 않지만,\n","이전 워크플로우에서 보여준 것처럼,\n","동일한 **프리셋**을 사용하는 일치하는 **전처리기**와 함께 사용할 수 있습니다.\n","\n","이번 워크플로우에서는, 백본 모델을 동결하고, 새로운 입력에 맞게, 두 개의 트레이닝 가능한 트랜스포머 레이어를 추가하여 실험합니다.\n","\n","**참고**: 우리는 BERT의 시퀀스 출력을 사용하고 있으므로, `pooled_dense` 레이어에 대한 경고를 무시할 수 있습니다."]},{"cell_type":"code","execution_count":13,"metadata":{"id":"0D58zu0jOSgj","colab":{"base_uri":"https://localhost:8080/","height":605},"executionInfo":{"status":"ok","timestamp":1727141039057,"user_tz":-540,"elapsed":64034,"user":{"displayName":"Tae Kyu Lee","userId":"00886399863979660459"}},"outputId":"a361f1fb-eefd-45a5-badd-8fde53dcc954"},"outputs":[{"output_type":"stream","name":"stderr","text":["Downloading from https://www.kaggle.com/api/v1/models/keras/bert/keras/bert_tiny_en_uncased/2/download/preprocessor.json...\n"]},{"output_type":"display_data","data":{"text/plain":["\u001b[1mModel: \"functional\"\u001b[0m\n"],"text/html":["<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional\"</span>\n","</pre>\n"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n","┃\u001b[1m \u001b[0m\u001b[1mLayer (type)             \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m       Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to          \u001b[0m\u001b[1m \u001b[0m┃\n","┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n","│ padding_mask (\u001b[38;5;33mInputLayer\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m)           │              \u001b[38;5;34m0\u001b[0m │ -                      │\n","├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n","│ segment_ids (\u001b[38;5;33mInputLayer\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m)           │              \u001b[38;5;34m0\u001b[0m │ -                      │\n","├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n","│ token_ids (\u001b[38;5;33mInputLayer\u001b[0m)    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m)           │              \u001b[38;5;34m0\u001b[0m │ -                      │\n","├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n","│ bert_backbone             │ [(\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m), (\u001b[38;5;45mNone\u001b[0m,   │      \u001b[38;5;34m4,385,920\u001b[0m │ padding_mask[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],    │\n","│ (\u001b[38;5;33mBertBackbone\u001b[0m)            │ \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)]            │                │ segment_ids[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],     │\n","│                           │                        │                │ token_ids[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]        │\n","├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n","│ transformer_encoder       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)      │        \u001b[38;5;34m198,272\u001b[0m │ bert_backbone[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m1\u001b[0m]    │\n","│ (\u001b[38;5;33mTransformerEncoder\u001b[0m)      │                        │                │                        │\n","├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n","│ transformer_encoder_1     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)      │        \u001b[38;5;34m198,272\u001b[0m │ transformer_encoder[\u001b[38;5;34m0\u001b[0m… │\n","│ (\u001b[38;5;33mTransformerEncoder\u001b[0m)      │                        │                │                        │\n","├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n","│ get_item_4 (\u001b[38;5;33mGetItem\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │              \u001b[38;5;34m0\u001b[0m │ transformer_encoder_1… │\n","├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n","│ dense (\u001b[38;5;33mDense\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2\u001b[0m)              │            \u001b[38;5;34m258\u001b[0m │ get_item_4[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]       │\n","└───────────────────────────┴────────────────────────┴────────────────┴────────────────────────┘\n"],"text/html":["<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n","┃<span style=\"font-weight: bold\"> Layer (type)              </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">        Param # </span>┃<span style=\"font-weight: bold\"> Connected to           </span>┃\n","┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n","│ padding_mask (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>)           │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                      │\n","├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n","│ segment_ids (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>)           │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                      │\n","├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n","│ token_ids (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>)           │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                      │\n","├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n","│ bert_backbone             │ [(<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>), (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>,   │      <span style=\"color: #00af00; text-decoration-color: #00af00\">4,385,920</span> │ padding_mask[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],    │\n","│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BertBackbone</span>)            │ <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)]            │                │ segment_ids[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],     │\n","│                           │                        │                │ token_ids[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]        │\n","├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n","│ transformer_encoder       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)      │        <span style=\"color: #00af00; text-decoration-color: #00af00\">198,272</span> │ bert_backbone[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>]    │\n","│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">TransformerEncoder</span>)      │                        │                │                        │\n","├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n","│ transformer_encoder_1     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)      │        <span style=\"color: #00af00; text-decoration-color: #00af00\">198,272</span> │ transformer_encoder[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n","│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">TransformerEncoder</span>)      │                        │                │                        │\n","├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n","│ get_item_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GetItem</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ transformer_encoder_1… │\n","├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n","│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>)              │            <span style=\"color: #00af00; text-decoration-color: #00af00\">258</span> │ get_item_4[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       │\n","└───────────────────────────┴────────────────────────┴────────────────┴────────────────────────┘\n","</pre>\n"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["\u001b[1m Total params: \u001b[0m\u001b[38;5;34m4,782,722\u001b[0m (18.24 MB)\n"],"text/html":["<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">4,782,722</span> (18.24 MB)\n","</pre>\n"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m396,802\u001b[0m (1.51 MB)\n"],"text/html":["<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">396,802</span> (1.51 MB)\n","</pre>\n"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m4,385,920\u001b[0m (16.73 MB)\n"],"text/html":["<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">4,385,920</span> (16.73 MB)\n","</pre>\n"]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Epoch 1/3\n","\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 18ms/step - loss: 0.6489 - sparse_categorical_accuracy: 0.6518 - val_loss: 0.5828 - val_sparse_categorical_accuracy: 0.7006\n","Epoch 2/3\n","\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 6ms/step - loss: 0.5081 - sparse_categorical_accuracy: 0.7533 - val_loss: 0.4922 - val_sparse_categorical_accuracy: 0.7708\n","Epoch 3/3\n","\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 6ms/step - loss: 0.4537 - sparse_categorical_accuracy: 0.7844 - val_loss: 0.4574 - val_sparse_categorical_accuracy: 0.7904\n"]},{"output_type":"execute_result","data":{"text/plain":["<keras.src.callbacks.history.History at 0x7a6b5d79fdc0>"]},"metadata":{},"execution_count":13}],"source":["preprocessor = keras_nlp.models.BertPreprocessor.from_preset(\"bert_tiny_en_uncased\")\n","backbone = keras_nlp.models.BertBackbone.from_preset(\"bert_tiny_en_uncased\")\n","\n","imdb_train_preprocessed = (\n","    imdb_train.map(preprocessor, tf.data.AUTOTUNE).cache().prefetch(tf.data.AUTOTUNE)\n",")\n","imdb_test_preprocessed = (\n","    imdb_test.map(preprocessor, tf.data.AUTOTUNE).cache().prefetch(tf.data.AUTOTUNE)\n",")\n","\n","backbone.trainable = False\n","inputs = backbone.input\n","sequence = backbone(inputs)[\"sequence_output\"]\n","for _ in range(2):\n","    sequence = keras_nlp.layers.TransformerEncoder(\n","        num_heads=2,\n","        intermediate_dim=512,\n","        dropout=0.1,\n","    )(sequence)\n","# [CLS] 토큰 출력을 사용하여 분류\n","outputs = keras.layers.Dense(2)(sequence[:, backbone.cls_token_index, :])\n","\n","model = keras.Model(inputs, outputs)\n","model.compile(\n","    loss=keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n","    optimizer=keras.optimizers.AdamW(5e-5),\n","    metrics=[keras.metrics.SparseCategoricalAccuracy()],\n","    jit_compile=True,\n",")\n","model.summary()\n","model.fit(\n","    imdb_train_preprocessed,\n","    validation_data=imdb_test_preprocessed,\n","    epochs=3,\n",")"]},{"cell_type":"markdown","source":["이 모델은 `BertClassifier` 모델에 비해 트레이닝 가능한 파라미터 수가 10%밖에 되지 않지만,\n","상당히 좋은 정확도를 달성합니다.\n","캐시된 전처리를 감안해도, 각 트레이닝 단계가 약 1/3의 시간을 소요합니다."],"metadata":{"id":"fAALB1Imc4Od"}},{"cell_type":"markdown","source":["## 백본 모델 사전 트레이닝"],"metadata":{"id":"vKtTdCoIc5vr"}},{"cell_type":"markdown","metadata":{"id":"wZrWhaMTOSgj"},"source":["<img src=\"https://storage.googleapis.com/keras-nlp/getting_started_guide/prof_keras_expert.png\" height=\"250\" alt=\"drawing\" />\n","\n","당신의 도메인에서, 대규모 라벨이 없는 데이터셋에 접근할 수 있나요?\n","이러한 데이터셋의 크기가 BERT, RoBERTa 또는 GPT2와 같은 유명한 백본 모델을 트레이닝시키는 데 사용된 데이터와 유사한 크기(XX+ GiB)인가요?\n","그렇다면, 도메인에 특화된 사전 트레이닝을 통해 자체 백본 모델을 학습하는 것이 도움이 될 수 있습니다.\n","\n","NLP 모델은 일반적으로 언어 모델링 작업을 통해 사전 트레이닝되며,\n","이는 입력 문장에 보이는 단어를 기준으로 가려진 단어를 예측하는 방식입니다.\n","예를 들어, `\"The fox [MASK] over the [MASK] dog\"`라는 입력에서,\n","모델은 `[\"jumped\", \"lazy\"]`를 예측해야 합니다.\n","이 모델의 하위 레이어는 **백본**으로 패키징되어, 새로운 작업과 관련된 레이어와 결합됩니다.\n","\n","KerasNLP 라이브러리는 SoTA **백본**과 **토크나이저**를 프리셋 없이 처음부터 트레이닝할 수 있도록 지원합니다.\n","\n","이번 워크플로우에서는, IMDB 리뷰 텍스트를 사용하여 BERT **백본**을 사전 학습합니다.\n","데이터 처리 복잡성을 줄이기 위해, \"next sentence prediction\" (NSP) 손실을 생략하였으며,\n","이는 RoBERTa와 같은 이후 모델에서도 제외되었습니다.\n","자세한 내용은 원본 논문을 복제하는 단계별 가이드를 제공하는,\n","[Transformer 사전 트레이닝](https://codecompose7.github.io/keras-doc-kr.github.io/guides/keras_nlp/transformer_pretraining/#pretraining)을 참조하세요."]},{"cell_type":"markdown","metadata":{"id":"vSFwLbDxOSgj"},"source":["### 전처리"]},{"cell_type":"code","execution_count":14,"metadata":{"id":"Ak5mMHNIOSgj","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1727141042135,"user_tz":-540,"elapsed":3075,"user":{"displayName":"Tae Kyu Lee","userId":"00886399863979660459"}},"outputId":"49bd1e6c-c981-43c8-8013-156ff0e574ab"},"outputs":[{"output_type":"stream","name":"stderr","text":["Downloading from https://www.kaggle.com/api/v1/models/keras/bert/keras/bert_tiny_en_uncased/2/download/preprocessor.json...\n"]},{"output_type":"stream","name":"stdout","text":["({'token_ids': <tf.Tensor: shape=(256,), dtype=int32, numpy=\n","array([  101,  3532,  2097,  2052,  2022,  5291,  2058,  1999,  2010,\n","        6542,   103,  2002,  2071,  2023,   103,  7570,   103,  7028,\n","        2446,  1011,  2694, 15581,   103,  2239,  1997,  2010,  4438,\n","        2377,  1012,  2009,  1005,   103,   103,   103,  2200,  2210,\n","         103,  2001,  2985,  2006,  2009,   103,  1037,  2754,  4125,\n","        2099,  1010,  1037,  4937,   103,  1998,   103, 18154,  2872,\n","         103,  3413,  2125,   103,   103,   103,   103,  1996,  3185,\n","        2001,  1999,   103,   103,   103,  2046,  2394,  1010,  2007,\n","         103,  2394,  2376,  5889,  5681, 12954,  9709,  2037,  3210,\n","        1012,   103,  2878,  2537,  2018,  2019,   103,  2601,  1998,\n","       25596, 14644,  2100,  2514,   103,  2009,  1012,  1998,  2074,\n","        2073,  2001, 15489,  2121, 10024,   103,  1999,   103,  3185,\n","        4312,  1029,  5796,   103,   103,  2243,  2435,  2023,  3374,\n","       20969,  1996,  3949,   103,  2074,  2135, 10849,  1012,  1026,\n","        7987,  1013,  1028,  1026,  7987,  1013,  1028,  2000,  2022,\n","         103,  2025,   103,  2022,  1029,  1045,  4299,  2023,  3185,\n","        2196,  2001,  1999,  1996, 11954,  2173,   103,   102,     0,\n","           0,     0,     0,     0,     0,     0,     0,     0,     0,\n","           0,     0,     0,     0,     0,     0,     0,     0,     0,\n","           0,     0,     0,     0,     0,     0,     0,     0,     0,\n","           0,     0,     0,     0,     0,     0,     0,     0,     0,\n","           0,     0,     0,     0,     0,     0,     0,     0,     0,\n","           0,     0,     0,     0,     0,     0,     0,     0,     0,\n","           0,     0,     0,     0,     0,     0,     0,     0,     0,\n","           0,     0,     0,     0,     0,     0,     0,     0,     0,\n","           0,     0,     0,     0,     0,     0,     0,     0,     0,\n","           0,     0,     0,     0,     0,     0,     0,     0,     0,\n","           0,     0,     0,     0,     0,     0,     0,     0,     0,\n","           0,     0,     0,     0], dtype=int32)>, 'segment_ids': <tf.Tensor: shape=(256,), dtype=int32, numpy=\n","array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], dtype=int32)>, 'padding_mask': <tf.Tensor: shape=(256,), dtype=bool, numpy=\n","array([ True,  True,  True,  True,  True,  True,  True,  True,  True,\n","        True,  True,  True,  True,  True,  True,  True,  True,  True,\n","        True,  True,  True,  True,  True,  True,  True,  True,  True,\n","        True,  True,  True,  True,  True,  True,  True,  True,  True,\n","        True,  True,  True,  True,  True,  True,  True,  True,  True,\n","        True,  True,  True,  True,  True,  True,  True,  True,  True,\n","        True,  True,  True,  True,  True,  True,  True,  True,  True,\n","        True,  True,  True,  True,  True,  True,  True,  True,  True,\n","        True,  True,  True,  True,  True,  True,  True,  True,  True,\n","        True,  True,  True,  True,  True,  True,  True,  True,  True,\n","        True,  True,  True,  True,  True,  True,  True,  True,  True,\n","        True,  True,  True,  True,  True,  True,  True,  True,  True,\n","        True,  True,  True,  True,  True,  True,  True,  True,  True,\n","        True,  True,  True,  True,  True,  True,  True,  True,  True,\n","        True,  True,  True,  True,  True,  True,  True,  True,  True,\n","        True,  True,  True,  True,  True,  True,  True,  True,  True,\n","        True,  True,  True,  True,  True,  True,  True,  True, False,\n","       False, False, False, False, False, False, False, False, False,\n","       False, False, False, False, False, False, False, False, False,\n","       False, False, False, False, False, False, False, False, False,\n","       False, False, False, False, False, False, False, False, False,\n","       False, False, False, False, False, False, False, False, False,\n","       False, False, False, False, False, False, False, False, False,\n","       False, False, False, False, False, False, False, False, False,\n","       False, False, False, False, False, False, False, False, False,\n","       False, False, False, False, False, False, False, False, False,\n","       False, False, False, False, False, False, False, False, False,\n","       False, False, False, False, False, False, False, False, False,\n","       False, False, False, False])>, 'mask_positions': <tf.Tensor: shape=(64,), dtype=int64, numpy=\n","array([ 10,  14,  16,  22,  31,  32,  33,  36,  37,  41,  49,  51,  54,\n","        57,  58,  59,  60,  65,  66,  67,  71,  72,  82,  87,  90,  94,\n","       100, 104, 106, 107, 111, 112, 117, 120, 135, 137, 148, 150,   0,\n","         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n","         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0])>}, <tf.Tensor: shape=(64,), dtype=int32, numpy=\n","array([ 2065,  2023,  3089,  4886,  1055,  5793,  2008,  2769,  2001,\n","        1012, 17122,  2070,  7753,  2004,  1037,  2275,  1012, 23606,\n","        2135,  9188,  2007,  1996,  1996, 11757,  2852,  2000,  2001,\n","        2015,  2023,  3185,  2102,  2509,  2537,  2009,  2030,  2000,\n","        2034,  1012,     0,     0,     0,     0,     0,     0,     0,\n","           0,     0,     0,     0,     0,     0,     0,     0,     0,\n","           0,     0,     0,     0,     0,     0,     0,     0,     0,\n","           0], dtype=int32)>, <tf.Tensor: shape=(64,), dtype=float16, numpy=\n","array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n","       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n","       1., 1., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], dtype=float16)>)\n"]}],"source":["# 모든 BERT `en` 모델들은 동일한 어휘집을 사용하므로,\n","# \"bert_tiny_en_uncased\"의 전처리기를 재사용합니다.\n","preprocessor = keras_nlp.models.BertPreprocessor.from_preset(\n","    \"bert_tiny_en_uncased\",\n","    sequence_length=256,\n",")\n","packer = preprocessor.packer\n","tokenizer = preprocessor.tokenizer\n","\n","# 일부 입력 토큰을 \"[MASK]\" 토큰으로 교체하는 keras.Layer\n","masker = keras_nlp.layers.MaskedLMMaskGenerator(\n","    vocabulary_size=tokenizer.vocabulary_size(),\n","    mask_selection_rate=0.25,\n","    mask_selection_length=64,\n","    mask_token_id=tokenizer.token_to_id(\"[MASK]\"),\n","    unselectable_token_ids=[\n","        tokenizer.token_to_id(x) for x in [\"[CLS]\", \"[PAD]\", \"[SEP]\"]\n","    ],\n",")\n","\n","\n","def preprocess(inputs, label):\n","    inputs = preprocessor(inputs)\n","    masked_inputs = masker(inputs[\"token_ids\"])\n","    # 마스킹 레이어 출력을 (features, labels, weights)로 분리하여\n","    # keras.Model.fit()에서 사용할 수 있도록 합니다.\n","    features = {\n","        \"token_ids\": masked_inputs[\"token_ids\"],\n","        \"segment_ids\": inputs[\"segment_ids\"],\n","        \"padding_mask\": inputs[\"padding_mask\"],\n","        \"mask_positions\": masked_inputs[\"mask_positions\"],\n","    }\n","    labels = masked_inputs[\"mask_ids\"]\n","    weights = masked_inputs[\"mask_weights\"]\n","    return features, labels, weights\n","\n","\n","pretrain_ds = imdb_train.map(preprocess, num_parallel_calls=tf.data.AUTOTUNE).prefetch(\n","    tf.data.AUTOTUNE\n",")\n","pretrain_val_ds = imdb_test.map(\n","    preprocess, num_parallel_calls=tf.data.AUTOTUNE\n",").prefetch(tf.data.AUTOTUNE)\n","\n","# ID 103은 \"masked\"된 토큰입니다.\n","print(pretrain_ds.unbatch().take(1).get_single_element())"]},{"cell_type":"markdown","metadata":{"id":"69rXOrkrOSgj"},"source":["### 사전 트레이닝 모델"]},{"cell_type":"code","execution_count":19,"metadata":{"id":"tXq8zEEoOSgj","colab":{"base_uri":"https://localhost:8080/","height":905},"executionInfo":{"status":"error","timestamp":1727141316382,"user_tz":-540,"elapsed":569,"user":{"displayName":"Tae Kyu Lee","userId":"00886399863979660459"}},"outputId":"c256e6fe-cff7-452f-c26d-75b3405bb886"},"outputs":[{"output_type":"display_data","data":{"text/plain":["\u001b[1mModel: \"functional_2\"\u001b[0m\n"],"text/html":["<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_2\"</span>\n","</pre>\n"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n","┃\u001b[1m \u001b[0m\u001b[1mLayer (type)             \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m       Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to          \u001b[0m\u001b[1m \u001b[0m┃\n","┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n","│ token_ids (\u001b[38;5;33mInputLayer\u001b[0m)    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m)           │              \u001b[38;5;34m0\u001b[0m │ -                      │\n","├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n","│ segment_ids (\u001b[38;5;33mInputLayer\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m)           │              \u001b[38;5;34m0\u001b[0m │ -                      │\n","├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n","│ padding_mask (\u001b[38;5;33mInputLayer\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m)           │              \u001b[38;5;34m0\u001b[0m │ -                      │\n","├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n","│ bert_backbone_4           │ [(\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m), (\u001b[38;5;45mNone\u001b[0m,   │      \u001b[38;5;34m4,385,920\u001b[0m │ token_ids[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],       │\n","│ (\u001b[38;5;33mBertBackbone\u001b[0m)            │ \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)]            │                │ segment_ids[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],     │\n","│                           │                        │                │ padding_mask[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     │\n","├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n","│ mask_positions            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m)           │              \u001b[38;5;34m0\u001b[0m │ -                      │\n","│ (\u001b[38;5;33mInputLayer\u001b[0m)              │                        │                │                        │\n","├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n","│ masked_lm_head_4          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m30522\u001b[0m)    │      \u001b[38;5;34m3,954,106\u001b[0m │ bert_backbone_4[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m1\u001b[0m], │\n","│ (\u001b[38;5;33mMaskedLMHead\u001b[0m)            │                        │                │ mask_positions[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n","└───────────────────────────┴────────────────────────┴────────────────┴────────────────────────┘\n"],"text/html":["<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n","┃<span style=\"font-weight: bold\"> Layer (type)              </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">        Param # </span>┃<span style=\"font-weight: bold\"> Connected to           </span>┃\n","┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n","│ token_ids (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>)           │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                      │\n","├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n","│ segment_ids (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>)           │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                      │\n","├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n","│ padding_mask (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>)           │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                      │\n","├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n","│ bert_backbone_4           │ [(<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>), (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>,   │      <span style=\"color: #00af00; text-decoration-color: #00af00\">4,385,920</span> │ token_ids[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],       │\n","│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BertBackbone</span>)            │ <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)]            │                │ segment_ids[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],     │\n","│                           │                        │                │ padding_mask[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     │\n","├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n","│ mask_positions            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>)           │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                      │\n","│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)              │                        │                │                        │\n","├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n","│ masked_lm_head_4          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30522</span>)    │      <span style=\"color: #00af00; text-decoration-color: #00af00\">3,954,106</span> │ bert_backbone_4[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>], │\n","│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaskedLMHead</span>)            │                        │                │ mask_positions[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n","└───────────────────────────┴────────────────────────┴────────────────┴────────────────────────┘\n","</pre>\n"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["\u001b[1m Total params: \u001b[0m\u001b[38;5;34m4,433,210\u001b[0m (16.91 MB)\n"],"text/html":["<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">4,433,210</span> (16.91 MB)\n","</pre>\n"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m4,433,210\u001b[0m (16.91 MB)\n"],"text/html":["<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">4,433,210</span> (16.91 MB)\n","</pre>\n"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"],"text/html":["<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n","</pre>\n"]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Epoch 1/3\n"]},{"output_type":"error","ename":"ValueError","evalue":"Exception encountered when calling Softmax.call().\n\n\u001b[1mDimensions must be equal, but are 256 and 64 for '{{node functional_2_1/bert_backbone_4_1/transformer_layer_0_1/self_attention_layer_1/softmax_18_1/add}} = AddV2[T=DT_HALF](functional_2_1/bert_backbone_4_1/transformer_layer_0_1/self_attention_layer_1/transpose_2, functional_2_1/bert_backbone_4_1/transformer_layer_0_1/self_attention_layer_1/softmax_18_1/mul)' with input shapes: [?,2,256,256], [?,1,1,64].\u001b[0m\n\nArguments received by Softmax.call():\n  • inputs=tf.Tensor(shape=(None, 2, 256, 256), dtype=float16)\n  • mask=tf.Tensor(shape=(None, 1, 1, 64), dtype=int32)","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)","\u001b[0;32m<ipython-input-19-1806eaf32630>\u001b[0m in \u001b[0;36m<cell line: 47>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     45\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m \u001b[0;31m# IMDB 데이터셋으로 사전 트레이닝 진행\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 47\u001b[0;31m pretraining_model.fit(\n\u001b[0m\u001b[1;32m     48\u001b[0m     \u001b[0mpretrain_ds\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m     \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpretrain_val_ds\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    120\u001b[0m             \u001b[0;31m# To get the full stack trace, call:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    121\u001b[0m             \u001b[0;31m# `keras.config.disable_traceback_filtering()`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 122\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    123\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    124\u001b[0m             \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras_nlp/src/layers/modeling/transformer_encoder.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, inputs, padding_mask, attention_mask, training)\u001b[0m\n\u001b[1;32m    215\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnormalize_first\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    216\u001b[0m             \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_self_attention_layer_norm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 217\u001b[0;31m         x = self._self_attention_layer(\n\u001b[0m\u001b[1;32m    218\u001b[0m             \u001b[0mquery\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    219\u001b[0m             \u001b[0mvalue\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mValueError\u001b[0m: Exception encountered when calling Softmax.call().\n\n\u001b[1mDimensions must be equal, but are 256 and 64 for '{{node functional_2_1/bert_backbone_4_1/transformer_layer_0_1/self_attention_layer_1/softmax_18_1/add}} = AddV2[T=DT_HALF](functional_2_1/bert_backbone_4_1/transformer_layer_0_1/self_attention_layer_1/transpose_2, functional_2_1/bert_backbone_4_1/transformer_layer_0_1/self_attention_layer_1/softmax_18_1/mul)' with input shapes: [?,2,256,256], [?,1,1,64].\u001b[0m\n\nArguments received by Softmax.call():\n  • inputs=tf.Tensor(shape=(None, 2, 256, 256), dtype=float16)\n  • mask=tf.Tensor(shape=(None, 1, 1, 64), dtype=int32)"]}],"source":["# BERT 백본 모델 생성\n","backbone = keras_nlp.models.BertBackbone(\n","    vocabulary_size=tokenizer.vocabulary_size(),\n","    num_layers=2,\n","    num_heads=2,\n","    hidden_dim=128,\n","    intermediate_dim=512,\n",")\n","\n","# 언어 모델링 헤드 생성\n","mlm_head = keras_nlp.layers.MaskedLMHead(\n","    token_embedding=backbone.token_embedding,\n",")\n","\n","# inputs = {\n","#     \"token_ids\": keras.Input(shape=(None,), dtype=tf.int32, name=\"token_ids\"),\n","#     \"segment_ids\": keras.Input(shape=(None,), dtype=tf.int32, name=\"segment_ids\"),\n","#     \"padding_mask\": keras.Input(shape=(None,), dtype=tf.int32, name=\"padding_mask\"),\n","#     \"mask_positions\": keras.Input(shape=(None,), dtype=tf.int32, name=\"mask_positions\"),\n","# }\n","inputs = [\n","    keras.Input(shape=(None,), dtype=tf.int32, name=\"token_ids\"),\n","    keras.Input(shape=(None,), dtype=tf.int32, name=\"segment_ids\"),\n","    keras.Input(shape=(None,), dtype=tf.int32, name=\"padding_mask\"),\n","]\n","\n","# 인코딩된 토큰 시퀀스\n","sequence = backbone(inputs)[\"sequence_output\"]\n","\n","# 각 마스킹된 입력 토큰에 대해 출력 단어 예측.\n","# 입력 토큰 임베딩을 사용해 인코딩된 벡터에서 어휘 로짓으로 프로젝션합니다.\n","# 이는 트레이닝 효율성을 향상시키는 것으로 알려져 있습니다.\n","# outputs = mlm_head(sequence, mask_positions=inputs[\"mask_positions\"])\n","outputs = mlm_head(sequence, mask_positions=keras.Input(shape=(None,), dtype=tf.int32, name=\"mask_positions\"))\n","\n","# 사전 트레이닝 모델 정의 및 컴파일\n","pretraining_model = keras.Model(inputs, outputs)\n","pretraining_model.summary()\n","pretraining_model.compile(\n","    loss=keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n","    optimizer=keras.optimizers.AdamW(learning_rate=5e-4),\n","    weighted_metrics=[keras.metrics.SparseCategoricalAccuracy()],\n","    jit_compile=True,\n",")\n","\n","# IMDB 데이터셋으로 사전 트레이닝 진행\n","pretraining_model.fit(\n","    pretrain_ds,\n","    validation_data=pretrain_val_ds,\n","    epochs=3,  # 더 높은 정확도를 위해 6으로 증가 가능\n",")"]},{"cell_type":"markdown","metadata":{"id":"d2DwFttGOSgj"},"source":["사전 트레이닝 후, `backbone` 서브모델을 저장하여 새로운 작업에 사용하세요!"]},{"cell_type":"markdown","source":["## 처음부터 직접 트랜스포머 빌드 및 트레이닝"],"metadata":{"id":"v-XO51ehdGos"}},{"cell_type":"markdown","metadata":{"id":"zoulIgljOSgj"},"source":["<img src=\"https://storage.googleapis.com/keras-nlp/getting_started_guide/prof_keras_expert.png\" height=\"250\" alt=\"drawing\" />\n","\n","새로운 트랜스포머 아키텍처를 구현하고 싶으신가요?\n","KerasNLP 라이브러리는 SoTA(최첨단) 아키텍처를 구축하는 데 사용되는,\n","모든 낮은 레벨 모듈을 `models` API에 제공합니다.\n","여기에는 `keras_nlp.tokenizers` API가 포함되어 있어,\n","`WordPieceTokenizer`, `BytePairTokenizer`, 또는 `SentencePieceTokenizer`를 사용하여,\n","직접 서브워드 토크나이저를 트레이닝할 수 있습니다.\n","\n","이 워크플로우에서는, IMDB 데이터에 대해 커스텀 토크나이저를 트레이닝하고,\n","커스텀 트랜스포머 아키텍처로 백본을 설계합니다.\n","간단하게 하기 위해, 바로 분류 작업에 대해 트레이닝을 진행합니다.\n","더 자세한 내용이 궁금하신가요?\n","커스텀 트랜스포머를 프리트레이닝하고 파인튜닝하는 전체 가이드를,\n","[keras.io](https://codecompose7.github.io/keras-doc-kr.github.io/guides/keras_nlp/transformer_pretraining/)에서 작성했습니다."]},{"cell_type":"markdown","metadata":{"id":"BJy1AIYYOSgj"},"source":["### IMDB 데이터에서 커스텀 어휘 트레이닝"]},{"cell_type":"code","execution_count":20,"metadata":{"id":"p4A7IkO3OSgk","executionInfo":{"status":"ok","timestamp":1727141436399,"user_tz":-540,"elapsed":92966,"user":{"displayName":"Tae Kyu Lee","userId":"00886399863979660459"}}},"outputs":[],"source":["vocab = keras_nlp.tokenizers.compute_word_piece_vocabulary(\n","    imdb_train.map(lambda x, y: x),\n","    vocabulary_size=20_000,\n","    lowercase=True,\n","    strip_accents=True,\n","    reserved_tokens=[\"[PAD]\", \"[START]\", \"[END]\", \"[MASK]\", \"[UNK]\"],\n",")\n","tokenizer = keras_nlp.tokenizers.WordPieceTokenizer(\n","    vocabulary=vocab,\n","    lowercase=True,\n","    strip_accents=True,\n","    oov_token=\"[UNK]\",\n",")"]},{"cell_type":"markdown","metadata":{"id":"7bmJ6IFDOSgk"},"source":["### 커스텀 토크나이저로 데이터 전처리"]},{"cell_type":"code","execution_count":21,"metadata":{"id":"N7uY_C2ROSgk","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1727141437083,"user_tz":-540,"elapsed":682,"user":{"displayName":"Tae Kyu Lee","userId":"00886399863979660459"}},"outputId":"ff569c2a-1643-486a-a103-22fd330b7ddd"},"outputs":[{"output_type":"stream","name":"stdout","text":["(<tf.Tensor: shape=(512,), dtype=int32, numpy=\n","array([    1,   141,   116,   146,   190,   105,  4794,     7,   451,\n","        7718,     7,  3026,    20,  7712,    17,   116,   146, 19109,\n","        4794,   327,    19,   114,   156,   116,   279,   102,    36,\n","          52,   215,   118,   265,    44,   272,   134,   102,  3499,\n","         155,  2915,   178,    19,    52,  1537,   141,   116,   233,\n","         178,   105,   112,   461,  5807,  7761,  1513,   116,   174,\n","         123,  7176,    13,    44,  1161,  1397,    12,    62,  3182,\n","          19,    14,   114,   111,   155,   373,    52,    12,    47,\n","         133,    44,   211,   236,   147,    17,   147,  1216,    17,\n","         147,   824,    19,   147,    19,    52,   326,   133,    52,\n","          12,    56,  7264,   111,    50, 12198,  1767,    37,    99,\n","        2179,   101,    99,  1369,    19,    99,  9646,   286,    99,\n","        7103,    19,   114,   119,   137,   482,    12,    63,  1627,\n","          19,     2,     0,     0,     0,     0,     0,     0,     0,\n","           0,     0,     0,     0,     0,     0,     0,     0,     0,\n","           0,     0,     0,     0,     0,     0,     0,     0,     0,\n","           0,     0,     0,     0,     0,     0,     0,     0,     0,\n","           0,     0,     0,     0,     0,     0,     0,     0,     0,\n","           0,     0,     0,     0,     0,     0,     0,     0,     0,\n","           0,     0,     0,     0,     0,     0,     0,     0,     0,\n","           0,     0,     0,     0,     0,     0,     0,     0,     0,\n","           0,     0,     0,     0,     0,     0,     0,     0,     0,\n","           0,     0,     0,     0,     0,     0,     0,     0,     0,\n","           0,     0,     0,     0,     0,     0,     0,     0,     0,\n","           0,     0,     0,     0,     0,     0,     0,     0,     0,\n","           0,     0,     0,     0,     0,     0,     0,     0,     0,\n","           0,     0,     0,     0,     0,     0,     0,     0,     0,\n","           0,     0,     0,     0,     0,     0,     0,     0,     0,\n","           0,     0,     0,     0,     0,     0,     0,     0,     0,\n","           0,     0,     0,     0,     0,     0,     0,     0,     0,\n","           0,     0,     0,     0,     0,     0,     0,     0,     0,\n","           0,     0,     0,     0,     0,     0,     0,     0,     0,\n","           0,     0,     0,     0,     0,     0,     0,     0,     0,\n","           0,     0,     0,     0,     0,     0,     0,     0,     0,\n","           0,     0,     0,     0,     0,     0,     0,     0,     0,\n","           0,     0,     0,     0,     0,     0,     0,     0,     0,\n","           0,     0,     0,     0,     0,     0,     0,     0,     0,\n","           0,     0,     0,     0,     0,     0,     0,     0,     0,\n","           0,     0,     0,     0,     0,     0,     0,     0,     0,\n","           0,     0,     0,     0,     0,     0,     0,     0,     0,\n","           0,     0,     0,     0,     0,     0,     0,     0,     0,\n","           0,     0,     0,     0,     0,     0,     0,     0,     0,\n","           0,     0,     0,     0,     0,     0,     0,     0,     0,\n","           0,     0,     0,     0,     0,     0,     0,     0,     0,\n","           0,     0,     0,     0,     0,     0,     0,     0,     0,\n","           0,     0,     0,     0,     0,     0,     0,     0,     0,\n","           0,     0,     0,     0,     0,     0,     0,     0,     0,\n","           0,     0,     0,     0,     0,     0,     0,     0,     0,\n","           0,     0,     0,     0,     0,     0,     0,     0,     0,\n","           0,     0,     0,     0,     0,     0,     0,     0,     0,\n","           0,     0,     0,     0,     0,     0,     0,     0,     0,\n","           0,     0,     0,     0,     0,     0,     0,     0,     0,\n","           0,     0,     0,     0,     0,     0,     0,     0,     0,\n","           0,     0,     0,     0,     0,     0,     0,     0,     0,\n","           0,     0,     0,     0,     0,     0,     0,     0,     0,\n","           0,     0,     0,     0,     0,     0,     0,     0,     0,\n","           0,     0,     0,     0,     0,     0,     0,     0],\n","      dtype=int32)>, <tf.Tensor: shape=(), dtype=int32, numpy=0>)\n"]}],"source":["packer = keras_nlp.layers.StartEndPacker(\n","    start_value=tokenizer.token_to_id(\"[START]\"),\n","    end_value=tokenizer.token_to_id(\"[END]\"),\n","    pad_value=tokenizer.token_to_id(\"[PAD]\"),\n","    sequence_length=512,\n",")\n","\n","\n","def preprocess(x, y):\n","    token_ids = packer(tokenizer(x))\n","    return token_ids, y\n","\n","\n","imdb_preproc_train_ds = imdb_train.map(\n","    preprocess, num_parallel_calls=tf.data.AUTOTUNE\n",").prefetch(tf.data.AUTOTUNE)\n","imdb_preproc_val_ds = imdb_test.map(\n","    preprocess, num_parallel_calls=tf.data.AUTOTUNE\n",").prefetch(tf.data.AUTOTUNE)\n","\n","print(imdb_preproc_train_ds.unbatch().take(1).get_single_element())"]},{"cell_type":"markdown","metadata":{"id":"UaL0OpNWOSgk"},"source":["### 작은 트랜스포머 설계"]},{"cell_type":"code","execution_count":22,"metadata":{"id":"3f_yTwP_OSgk","colab":{"base_uri":"https://localhost:8080/","height":331},"executionInfo":{"status":"ok","timestamp":1727141437137,"user_tz":-540,"elapsed":55,"user":{"displayName":"Tae Kyu Lee","userId":"00886399863979660459"}},"outputId":"fe55f1ea-0c27-4f11-ad24-2db60b89fdc4"},"outputs":[{"output_type":"display_data","data":{"text/plain":["\u001b[1mModel: \"functional_3\"\u001b[0m\n"],"text/html":["<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_3\"</span>\n","</pre>\n"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n","┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n","┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n","│ token_ids (\u001b[38;5;33mInputLayer\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m)                │               \u001b[38;5;34m0\u001b[0m │\n","├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n","│ token_and_position_embedding         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)            │       \u001b[38;5;34m1,260,544\u001b[0m │\n","│ (\u001b[38;5;33mTokenAndPositionEmbedding\u001b[0m)          │                             │                 │\n","├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n","│ transformer_encoder_2                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)            │          \u001b[38;5;34m33,472\u001b[0m │\n","│ (\u001b[38;5;33mTransformerEncoder\u001b[0m)                 │                             │                 │\n","├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n","│ get_item_10 (\u001b[38;5;33mGetItem\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)                  │               \u001b[38;5;34m0\u001b[0m │\n","├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n","│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2\u001b[0m)                   │             \u001b[38;5;34m130\u001b[0m │\n","└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"],"text/html":["<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n","┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n","┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n","│ token_ids (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>)                │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n","├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n","│ token_and_position_embedding         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)            │       <span style=\"color: #00af00; text-decoration-color: #00af00\">1,260,544</span> │\n","│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">TokenAndPositionEmbedding</span>)          │                             │                 │\n","├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n","│ transformer_encoder_2                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)            │          <span style=\"color: #00af00; text-decoration-color: #00af00\">33,472</span> │\n","│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">TransformerEncoder</span>)                 │                             │                 │\n","├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n","│ get_item_10 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GetItem</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)                  │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n","├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n","│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>)                   │             <span style=\"color: #00af00; text-decoration-color: #00af00\">130</span> │\n","└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n","</pre>\n"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["\u001b[1m Total params: \u001b[0m\u001b[38;5;34m1,294,146\u001b[0m (4.94 MB)\n"],"text/html":["<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,294,146</span> (4.94 MB)\n","</pre>\n"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m1,294,146\u001b[0m (4.94 MB)\n"],"text/html":["<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,294,146</span> (4.94 MB)\n","</pre>\n"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"],"text/html":["<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n","</pre>\n"]},"metadata":{}}],"source":["token_id_input = keras.Input(\n","    shape=(None,),\n","    dtype=\"int32\",\n","    name=\"token_ids\",\n",")\n","outputs = keras_nlp.layers.TokenAndPositionEmbedding(\n","    vocabulary_size=len(vocab),\n","    sequence_length=packer.sequence_length,\n","    embedding_dim=64,\n",")(token_id_input)\n","outputs = keras_nlp.layers.TransformerEncoder(\n","    num_heads=2,\n","    intermediate_dim=128,\n","    dropout=0.1,\n",")(outputs)\n","# \"[START]\" 토큰을 사용하여 분류\n","outputs = keras.layers.Dense(2)(outputs[:, 0, :])\n","model = keras.Model(\n","    inputs=token_id_input,\n","    outputs=outputs,\n",")\n","\n","model.summary()"]},{"cell_type":"markdown","metadata":{"id":"BvDBZnPjOSgk"},"source":["### 트랜스포머를 직접 분류 목표(objective)에 맞춰 트레이닝"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ZHdEv_UAOSgn","colab":{"base_uri":"https://localhost:8080/"},"outputId":"f83e3bd3-b412-4875-be86-beff45b4727e"},"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/3\n","\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 9ms/step - loss: 0.7218 - sparse_categorical_accuracy: 0.5222 - val_loss: 0.5311 - val_sparse_categorical_accuracy: 0.7583\n","Epoch 2/3\n","\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - loss: 0.4649 - sparse_categorical_accuracy: 0.7785 - val_loss: 0.4911 - val_sparse_categorical_accuracy: 0.7610\n","Epoch 3/3\n","\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.3220 - sparse_categorical_accuracy: 0.8685"]}],"source":["model.compile(\n","    loss=keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n","    optimizer=keras.optimizers.AdamW(5e-5),\n","    metrics=[keras.metrics.SparseCategoricalAccuracy()],\n","    jit_compile=True,\n",")\n","model.fit(\n","    imdb_preproc_train_ds,\n","    validation_data=imdb_preproc_val_ds,\n","    epochs=3,\n",")"]},{"cell_type":"markdown","metadata":{"id":"0eCKsx6kOSgp"},"source":["흥미롭게도, 우리가 설계한 커스텀 분류기는 `\"bert_tiny_en_uncased\"`를 미세 조정한 성능과 비슷합니다!\n","90% 이상의 정확도를 달성하고,\n","사전 트레이닝의 장점을 보기 위해서는 `\"bert_base_en_uncased\"`와 같은,\n","더 큰 **프리셋**을 사용해야 합니다.\n"]}],"metadata":{"accelerator":"GPU","colab":{"provenance":[{"file_id":"https://github.com/keras-team/keras-io/blob/master/guides/ipynb/keras_nlp/getting_started.ipynb","timestamp":1727134249342}],"toc_visible":true},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.0"}},"nbformat":4,"nbformat_minor":0}